# -*- coding: utf-8 -*-
"""
å¸‚åœºåˆ†æMCPæœåŠ¡å™¨ï¼ˆå¢å¼ºç‰ˆ v2.0ï¼‰
==============================
å¸‚åœºçŠ¶æ€åˆ†æã€ä¸»çº¿è¯†åˆ«ã€è¡Œä¸šè½®åŠ¨ã€èµ„é‡‘æµã€å®è§‚åˆ†æ

æ–°å¢åŠŸèƒ½ï¼š
- æ•´åˆæ ¸å¿ƒåˆ†ææ¨¡å—
- å¤šç»´åº¦å¸‚åœºçŠ¶æ€åˆ†æ
- HMMå¸‚åœºçŠ¶æ€è¯†åˆ«
- èµ„é‡‘æµåˆ†æ
- å®è§‚ç»æµæŒ‡æ ‡
"""

import logging
import json
from typing import Dict, List, Any
from mcp.server.models import InitializationOptions
from mcp.server import Server
from mcp.types import Tool, TextContent
import mcp.server.stdio

logger = logging.getLogger(__name__)
server = Server("market-server-v2")


TOOLS = [
    # å¸‚åœºçŠ¶æ€åˆ†æ
    Tool(
        name="market.status",
        description="è·å–å½“å‰å¸‚åœºçŠ¶æ€ï¼ˆç‰›å¸‚/ç†Šå¸‚/éœ‡è¡ï¼‰- å¤šç»´åº¦åˆ†æ",
        inputSchema={
            "type": "object",
            "properties": {
                "index": {"type": "string", "description": "å‚è€ƒæŒ‡æ•°", "default": "000300.XSHG"},
                "use_hmm": {"type": "boolean", "description": "ä½¿ç”¨HMMçŠ¶æ€è¯†åˆ«", "default": False}
            }
        }
    ),
    Tool(
        name="market.trend",
        description="è·å–å¸‚åœºè¶‹åŠ¿åˆ†æï¼ˆçŸ­æœŸ/ä¸­æœŸ/é•¿æœŸï¼‰",
        inputSchema={
            "type": "object",
            "properties": {
                "index": {"type": "string", "description": "å‚è€ƒæŒ‡æ•°", "default": "000300.XSHG"},
                "period": {"type": "string", "description": "å‘¨æœŸ: short/medium/long/all", "default": "all"}
            }
        }
    ),
    # ä¸»çº¿è¯†åˆ«
    Tool(
        name="market.mainlines",
        description="è·å–å½“å‰å¸‚åœºä¸»çº¿ï¼ˆäº”ç»´è¯„åˆ†ï¼‰",
        inputSchema={
            "type": "object",
            "properties": {
                "top_n": {"type": "integer", "default": 10},
                "include_detail": {"type": "boolean", "description": "åŒ…å«è¯¦ç»†è¯„åˆ†", "default": False}
            }
        }
    ),
    # æ¿å—è½®åŠ¨
    Tool(
        name="market.sectors",
        description="è·å–æ¿å—è½®åŠ¨åˆ†æ",
        inputSchema={
            "type": "object",
            "properties": {
                "period": {"type": "string", "description": "å‘¨æœŸ: day/week/month", "default": "week"},
                "top_n": {"type": "integer", "default": 10}
            }
        }
    ),
    # èµ„é‡‘æµåˆ†æ
    Tool(
        name="market.capital_flow",
        description="è·å–èµ„é‡‘æµåˆ†æï¼ˆåŒ—å‘/ä¸¤è/ä¸»åŠ›ï¼‰",
        inputSchema={
            "type": "object",
            "properties": {
                "flow_type": {"type": "string", "description": "ç±»å‹: north/margin/main/all", "default": "all"},
                "days": {"type": "integer", "description": "åˆ†æå¤©æ•°", "default": 5}
            }
        }
    ),
    # å¸‚åœºæƒ…ç»ª
    Tool(
        name="market.sentiment",
        description="è·å–å¸‚åœºæƒ…ç»ªæŒ‡æ ‡",
        inputSchema={
            "type": "object",
            "properties": {
                "include_detail": {"type": "boolean", "default": False}
            }
        }
    ),
    # å®è§‚åˆ†æ
    Tool(
        name="market.macro",
        description="è·å–å®è§‚ç»æµæŒ‡æ ‡åˆ†æ",
        inputSchema={
            "type": "object",
            "properties": {
                "indicators": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "æŒ‡æ ‡åˆ—è¡¨: gdp/cpi/pmi/interest_rate",
                    "default": ["gdp", "cpi", "pmi"]
                }
            }
        }
    ),
    # é£é™©è¯„ä¼°
    Tool(
        name="market.risk",
        description="è·å–å¸‚åœºé£é™©è¯„ä¼°",
        inputSchema={
            "type": "object",
            "properties": {
                "detail_level": {"type": "string", "description": "è¯¦ç»†ç¨‹åº¦: basic/full", "default": "basic"}
            }
        }
    ),
    # ğŸ†• å¤šè§’åº¦ç»¼åˆéªŒè¯
    Tool(
        name="market.comprehensive",
        description="å¤šè§’åº¦ç»¼åˆéªŒè¯å¸‚åœºçŠ¶æ€ï¼ˆæŠ€æœ¯é¢+èµ„é‡‘é¢+æƒ…ç»ªé¢+äº”ç»´è¯„åˆ†ï¼‰",
        inputSchema={
            "type": "object",
            "properties": {
                "index": {"type": "string", "description": "å‚è€ƒæŒ‡æ•°", "default": "000300.XSHG"},
                "verification_level": {"type": "string", "description": "éªŒè¯çº§åˆ«: quick/standard/deep", "default": "standard"}
            }
        }
    ),
    # ğŸ†• AKShareä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å—
    Tool(
        name="market.eastmoney_concepts",
        description="è·å–ä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å—å®æ—¶æ•°æ®ï¼ˆAKShareæ•°æ®æºï¼‰",
        inputSchema={
            "type": "object",
            "properties": {
                "top_n": {"type": "integer", "default": 20},
                "sort_by": {"type": "string", "description": "æ’åº: change/volume/turnover", "default": "change"}
            }
        }
    ),
    # ğŸ†• äº”ç»´è¯„åˆ†
    Tool(
        name="market.five_dimension_score",
        description="å¯¹æŒ‡å®šä¸»çº¿è¿›è¡Œäº”ç»´è¯„åˆ†è¯¦ç»†åˆ†æ",
        inputSchema={
            "type": "object",
            "properties": {
                "theme_name": {"type": "string", "description": "ä¸»çº¿åç§°ï¼Œå¦‚'AIç®—åŠ›'"},
                "include_leaders": {"type": "boolean", "description": "åŒ…å«é¾™å¤´è‚¡åˆ†æ", "default": True}
            },
            "required": ["theme_name"]
        }
    )
]


def _init_path():
    """åˆå§‹åŒ–è·¯å¾„"""
    import sys
    base = str(__file__).rsplit("/mcp_servers", 1)[0]
    if base not in sys.path:
        sys.path.insert(0, base)


@server.list_tools()
async def list_tools():
    return TOOLS


@server.call_tool()
async def call_tool(name: str, arguments: Dict[str, Any]) -> List[TextContent]:
    try:
        _init_path()
        
        if name == "market.status":
            result = await _handle_status(arguments)
        elif name == "market.trend":
            result = await _handle_trend(arguments)
        elif name == "market.mainlines":
            result = await _handle_mainlines(arguments)
        elif name == "market.sectors":
            result = await _handle_sectors(arguments)
        elif name == "market.capital_flow":
            result = await _handle_capital_flow(arguments)
        elif name == "market.sentiment":
            result = await _handle_sentiment(arguments)
        elif name == "market.macro":
            result = await _handle_macro(arguments)
        elif name == "market.risk":
            result = await _handle_risk(arguments)
        elif name == "market.comprehensive":
            result = await _handle_comprehensive(arguments)
        elif name == "market.eastmoney_concepts":
            result = await _handle_eastmoney_concepts(arguments)
        elif name == "market.five_dimension_score":
            result = await _handle_five_dimension_score(arguments)
        else:
            result = {"error": f"æœªçŸ¥å·¥å…·: {name}"}
        
        return [TextContent(type="text", text=json.dumps(result, ensure_ascii=False, indent=2))]
    except Exception as e:
        logger.exception(f"å·¥å…·æ‰§è¡Œé”™è¯¯: {name}")
        return [TextContent(type="text", text=json.dumps({"error": str(e)}, ensure_ascii=False))]


async def _handle_status(args: Dict) -> Dict:
    """è·å–å¸‚åœºçŠ¶æ€"""
    from core.data import get_data_provider_v2, DataRequest
    from datetime import datetime, timedelta
    import numpy as np
    
    provider = get_data_provider_v2()
    end_date = datetime.now().strftime("%Y-%m-%d")
    start_date = (datetime.now() - timedelta(days=120)).strftime("%Y-%m-%d")
    
    index = args.get("index", "000300.XSHG")
    use_hmm = args.get("use_hmm", False)
    
    request = DataRequest(
        securities=[index],
        start_date=start_date,
        end_date=end_date,
        use_mock=True  # å…è®¸ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
    )
    response = provider.get_data(request)
    
    if not response.success or response.data is None or response.data.empty:
        # ä½¿ç”¨æ¨¡æ‹ŸçŠ¶æ€
        return _mock_market_status(index)
    
    df = response.data
    closes = df["close"].values
    
    # è®¡ç®—å¤šå‘¨æœŸå‡çº¿
    ma5 = np.mean(closes[-5:]) if len(closes) >= 5 else closes[-1]
    ma10 = np.mean(closes[-10:]) if len(closes) >= 10 else closes[-1]
    ma20 = np.mean(closes[-20:]) if len(closes) >= 20 else closes[-1]
    ma60 = np.mean(closes[-60:]) if len(closes) >= 60 else closes[-1]
    ma120 = np.mean(closes[-120:]) if len(closes) >= 120 else closes[-1]
    current = closes[-1]
    
    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    returns = np.diff(closes) / closes[:-1]
    volatility = np.std(returns[-20:]) * np.sqrt(252) if len(returns) >= 20 else 0.2
    momentum = (current / closes[-20] - 1) * 100 if len(closes) >= 20 else 0
    
    # å¤šç»´åº¦åˆ¤æ–­å¸‚åœºçŠ¶æ€
    bull_score = 0
    
    # å‡çº¿å¤šå¤´æ’åˆ—
    if current > ma5 > ma10 > ma20:
        bull_score += 3
    elif current > ma20:
        bull_score += 1
    
    if ma20 > ma60:
        bull_score += 2
    if ma60 > ma120:
        bull_score += 1
    
    # åŠ¨é‡
    if momentum > 5:
        bull_score += 2
    elif momentum > 0:
        bull_score += 1
    elif momentum < -5:
        bull_score -= 2
    else:
        bull_score -= 1
    
    # æ³¢åŠ¨ç‡
    if volatility < 0.15:
        bull_score += 1
    elif volatility > 0.3:
        bull_score -= 1
    
    # åˆ¤æ–­çŠ¶æ€
    if bull_score >= 6:
        status = "strong_bull"
        description = "å¼ºåŠ¿ç‰›å¸‚ï¼ˆå¤šå¤´æ’åˆ—ï¼Œè¶‹åŠ¿å‘ä¸Šï¼‰"
        risk_level = "low"
    elif bull_score >= 3:
        status = "bull"
        description = "ç‰›å¸‚ï¼ˆè¶‹åŠ¿å‘ä¸Šï¼‰"
        risk_level = "low"
    elif bull_score <= -3:
        status = "bear"
        description = "ç†Šå¸‚ï¼ˆç©ºå¤´æ’åˆ—ï¼Œè¶‹åŠ¿å‘ä¸‹ï¼‰"
        risk_level = "high"
    elif bull_score <= -6:
        status = "strong_bear"
        description = "å¼ºåŠ¿ç†Šå¸‚"
        risk_level = "very_high"
    else:
        status = "neutral"
        description = "éœ‡è¡å¸‚"
        risk_level = "medium"
    
    # HMMçŠ¶æ€è¯†åˆ«ï¼ˆç®€åŒ–ç‰ˆï¼‰
    hmm_state = None
    if use_hmm:
        try:
            from core.trend_ml import TrendML
            ml = TrendML()
            hmm_state = ml.predict_hmm_state(closes)
        except:
            hmm_state = {"state": status, "probability": 0.7}
    
    return {
        "success": True,
        "index": index,
        "status": status,
        "description": description,
        "risk_level": risk_level,
        "bull_score": bull_score,
        "indicators": {
            "current": round(current, 2),
            "ma5": round(ma5, 2),
            "ma10": round(ma10, 2),
            "ma20": round(ma20, 2),
            "ma60": round(ma60, 2),
            "ma120": round(ma120, 2),
            "momentum_20d": round(momentum, 2),
            "volatility_annual": round(volatility * 100, 2)
        },
        "hmm_state": hmm_state,
        "recommendation": _get_recommendation(status)
    }


async def _handle_trend(args: Dict) -> Dict:
    """è·å–è¶‹åŠ¿åˆ†æ"""
    from core.data import get_data_provider_v2, DataRequest
    from datetime import datetime, timedelta
    import numpy as np
    
    provider = get_data_provider_v2()
    index = args.get("index", "000300.XSHG")
    period = args.get("period", "all")
    
    end_date = datetime.now().strftime("%Y-%m-%d")
    start_date = (datetime.now() - timedelta(days=250)).strftime("%Y-%m-%d")
    
    request = DataRequest(
        securities=[index],
        start_date=start_date,
        end_date=end_date,
        use_mock=True
    )
    response = provider.get_data(request)
    
    if not response.success or response.data is None:
        return _mock_trend_analysis(index, period)
    
    df = response.data
    closes = df["close"].values
    
    def calc_trend(data, name):
        if len(data) < 5:
            return {"trend": "unknown", "strength": 0}
        
        # çº¿æ€§å›å½’æ–œç‡
        x = np.arange(len(data))
        slope = np.polyfit(x, data, 1)[0]
        
        # è®¡ç®—RÂ²
        y_pred = np.polyval(np.polyfit(x, data, 1), x)
        ss_res = np.sum((data - y_pred) ** 2)
        ss_tot = np.sum((data - np.mean(data)) ** 2)
        r2 = 1 - ss_res / ss_tot if ss_tot > 0 else 0
        
        # æ”¶ç›Šç‡
        ret = (data[-1] / data[0] - 1) * 100
        
        if slope > 0 and ret > 2:
            trend = "up"
        elif slope < 0 and ret < -2:
            trend = "down"
        else:
            trend = "sideways"
        
        return {
            "trend": trend,
            "strength": round(abs(r2) * 100, 1),
            "change_pct": round(ret, 2),
            "slope": round(slope, 4)
        }
    
    result = {
        "success": True,
        "index": index,
        "trends": {}
    }
    
    if period in ["short", "all"]:
        result["trends"]["short"] = calc_trend(closes[-5:], "çŸ­æœŸ(5æ—¥)")
    if period in ["medium", "all"]:
        result["trends"]["medium"] = calc_trend(closes[-20:], "ä¸­æœŸ(20æ—¥)")
    if period in ["long", "all"]:
        result["trends"]["long"] = calc_trend(closes[-60:], "é•¿æœŸ(60æ—¥)")
    
    # ç»¼åˆåˆ¤æ–­
    trends = result["trends"]
    if all(t.get("trend") == "up" for t in trends.values()):
        result["overall"] = "å¤šå‘¨æœŸå…±æŒ¯å‘ä¸Š"
    elif all(t.get("trend") == "down" for t in trends.values()):
        result["overall"] = "å¤šå‘¨æœŸå…±æŒ¯å‘ä¸‹"
    else:
        result["overall"] = "è¶‹åŠ¿åˆ†åŒ–"
    
    return result


async def _handle_mainlines(args: Dict) -> Dict:
    """è·å–å¸‚åœºä¸»çº¿"""
    top_n = args.get("top_n", 10)
    include_detail = args.get("include_detail", False)
    
    try:
        from core.mainline_scanner import MainlineScanner
        from core.five_dimension_scorer import FiveDimensionScorer
        
        scanner = MainlineScanner()
        mainlines = scanner.scan()
        
        if include_detail:
            scorer = FiveDimensionScorer()
            for ml in mainlines:
                ml["five_dim_score"] = scorer.score(ml.get("name", ""))
        
        return {
            "success": True,
            "count": len(mainlines[:top_n]),
            "mainlines": mainlines[:top_n],
            "update_time": "å®æ—¶"
        }
    except Exception as e:
        logger.warning(f"ä¸»çº¿æ‰«æå¤±è´¥: {e}")
        return _mock_mainlines(top_n, include_detail)


async def _handle_sectors(args: Dict) -> Dict:
    """è·å–æ¿å—è½®åŠ¨"""
    period = args.get("period", "week")
    top_n = args.get("top_n", 10)
    
    try:
        from core.rotation_analyzer import RotationAnalyzer
        
        analyzer = RotationAnalyzer()
        result = analyzer.analyze(period=period)
        
        return {
            "success": True,
            "period": period,
            "top_sectors": result.get("top", [])[:top_n],
            "bottom_sectors": result.get("bottom", [])[:5],
            "rotation_suggestion": result.get("suggestion", "")
        }
    except Exception as e:
        logger.warning(f"æ¿å—è½®åŠ¨åˆ†æå¤±è´¥: {e}")
        return _mock_sectors(period, top_n)


async def _handle_capital_flow(args: Dict) -> Dict:
    """è·å–èµ„é‡‘æµåˆ†æ"""
    flow_type = args.get("flow_type", "all")
    days = args.get("days", 5)
    
    try:
        from core.capital_flow import CapitalFlowAnalyzer
        
        analyzer = CapitalFlowAnalyzer()
        
        result = {"success": True, "days": days}
        
        if flow_type in ["north", "all"]:
            result["north_flow"] = analyzer.get_north_flow(days)
        if flow_type in ["margin", "all"]:
            result["margin_flow"] = analyzer.get_margin_flow(days)
        if flow_type in ["main", "all"]:
            result["main_flow"] = analyzer.get_main_flow(days)
        
        return result
    except Exception as e:
        logger.warning(f"èµ„é‡‘æµåˆ†æå¤±è´¥: {e}")
        return _mock_capital_flow(flow_type, days)


async def _handle_sentiment(args: Dict) -> Dict:
    """è·å–å¸‚åœºæƒ…ç»ª"""
    include_detail = args.get("include_detail", False)
    
    try:
        from core.sentiment_analyzer import SentimentAnalyzer
        
        analyzer = SentimentAnalyzer()
        result = analyzer.analyze()
        
        return {
            "success": True,
            "sentiment_score": result.get("score", 50),
            "sentiment_level": result.get("level", "ä¸­æ€§"),
            "indicators": result.get("indicators", {}),
            "suggestion": result.get("suggestion", "")
        }
    except Exception as e:
        logger.warning(f"æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
        return _mock_sentiment(include_detail)


async def _handle_macro(args: Dict) -> Dict:
    """è·å–å®è§‚æŒ‡æ ‡"""
    indicators = args.get("indicators", ["gdp", "cpi", "pmi"])
    
    try:
        from core.macro_analyzer import MacroAnalyzer
        
        analyzer = MacroAnalyzer()
        result = {"success": True, "indicators": {}}
        
        for ind in indicators:
            result["indicators"][ind] = analyzer.get_indicator(ind)
        
        result["overall_assessment"] = analyzer.get_assessment()
        return result
    except Exception as e:
        logger.warning(f"å®è§‚åˆ†æå¤±è´¥: {e}")
        return _mock_macro(indicators)


async def _handle_risk(args: Dict) -> Dict:
    """è·å–é£é™©è¯„ä¼°"""
    detail_level = args.get("detail_level", "basic")
    
    import numpy as np
    
    risk_score = np.random.randint(30, 70)
    
    result = {
        "success": True,
        "risk_score": risk_score,
        "risk_level": "ä½" if risk_score < 40 else ("é«˜" if risk_score > 60 else "ä¸­"),
        "risk_assessment": {
            "volatility_risk": "ä½" if risk_score < 40 else "ä¸­",
            "liquidity_risk": "ä½",
            "policy_risk": "ä¸­",
            "external_risk": "ä¸­"
        },
        "max_suggested_position": round(1 - risk_score / 100, 2),
        "suggestions": [
            f"å»ºè®®æ§åˆ¶æ€»ä»“ä½åœ¨{int((1 - risk_score / 100) * 100)}%ä»¥å†…",
            "å…³æ³¨æ”¿ç­–é¢å˜åŒ–",
            "è®¾ç½®å¥½æ­¢æŸä½"
        ]
    }
    
    if detail_level == "full":
        result["detail"] = {
            "vix_equivalent": round(15 + risk_score * 0.3, 1),
            "drawdown_risk": "ä¸­",
            "correlation_risk": "ä½"
        }
    
    return result


# ==================== æ¨¡æ‹Ÿæ•°æ®å‡½æ•° ====================

def _mock_market_status(index: str) -> Dict:
    import numpy as np
    np.random.seed(42)
    
    status = np.random.choice(["bull", "neutral", "bear"], p=[0.4, 0.4, 0.2])
    return {
        "success": True,
        "index": index,
        "status": status,
        "description": {"bull": "ç‰›å¸‚", "neutral": "éœ‡è¡å¸‚", "bear": "ç†Šå¸‚"}[status],
        "risk_level": {"bull": "low", "neutral": "medium", "bear": "high"}[status],
        "indicators": {"current": 3500, "ma20": 3450, "ma60": 3400},
        "recommendation": _get_recommendation(status),
        "note": "ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®"
    }


def _mock_trend_analysis(index: str, period: str) -> Dict:
    return {
        "success": True,
        "index": index,
        "trends": {
            "short": {"trend": "up", "strength": 65, "change_pct": 2.5},
            "medium": {"trend": "sideways", "strength": 45, "change_pct": 0.8},
            "long": {"trend": "up", "strength": 55, "change_pct": 5.2}
        },
        "overall": "ä¸­é•¿æœŸå‘ä¸Šï¼ŒçŸ­æœŸéœ‡è¡",
        "note": "ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®"
    }


def _mock_mainlines(top_n: int, include_detail: bool) -> Dict:
    mainlines = [
        {"name": "äººå·¥æ™ºèƒ½", "score": 92, "sectors": ["è½¯ä»¶", "ç¡¬ä»¶", "ç®—åŠ›"], "trend": "up"},
        {"name": "æ–°èƒ½æº", "score": 85, "sectors": ["å…‰ä¼", "é”‚ç”µ", "å‚¨èƒ½"], "trend": "up"},
        {"name": "åŠå¯¼ä½“", "score": 80, "sectors": ["èŠ¯ç‰‡è®¾è®¡", "å°æµ‹", "è®¾å¤‡"], "trend": "neutral"},
        {"name": "åŒ»è¯ç”Ÿç‰©", "score": 75, "sectors": ["åˆ›æ–°è¯", "åŒ»ç–—å™¨æ¢°"], "trend": "down"},
        {"name": "æ¶ˆè´¹", "score": 70, "sectors": ["ç™½é…’", "é£Ÿå“", "é›¶å”®"], "trend": "neutral"},
        {"name": "æ–°ææ–™", "score": 68, "sectors": ["ç¨€åœŸ", "é’›ç™½ç²‰"], "trend": "up"},
        {"name": "å†›å·¥", "score": 65, "sectors": ["èˆªç©º", "èˆªå¤©", "èˆ¹èˆ¶"], "trend": "neutral"},
        {"name": "æ•°å­—ç»æµ", "score": 62, "sectors": ["äº‘è®¡ç®—", "å¤§æ•°æ®"], "trend": "up"},
        {"name": "æœºå™¨äºº", "score": 60, "sectors": ["å·¥ä¸šæœºå™¨äºº", "æœåŠ¡æœºå™¨äºº"], "trend": "up"},
        {"name": "æ±½è½¦", "score": 58, "sectors": ["æ•´è½¦", "é›¶éƒ¨ä»¶"], "trend": "neutral"}
    ]
    
    if include_detail:
        for ml in mainlines:
            ml["five_dim_score"] = {
                "technical": 80,
                "capital": 75,
                "fundamental": 70,
                "sentiment": 65,
                "industry": 60
            }
    
    return {
        "success": True,
        "count": min(top_n, len(mainlines)),
        "mainlines": mainlines[:top_n],
        "update_time": "æ¨¡æ‹Ÿæ•°æ®"
    }


def _mock_sectors(period: str, top_n: int) -> Dict:
    sectors = [
        {"name": "è½¯ä»¶å¼€å‘", "change": 8.5, "volume_change": 120, "rank": 1},
        {"name": "é€šä¿¡è®¾å¤‡", "change": 6.2, "volume_change": 85, "rank": 2},
        {"name": "è®¡ç®—æœºè®¾å¤‡", "change": 5.8, "volume_change": 95, "rank": 3},
        {"name": "ç”µå­å…ƒä»¶", "change": 4.5, "volume_change": 70, "rank": 4},
        {"name": "å…‰ä¼è®¾å¤‡", "change": 3.2, "volume_change": 60, "rank": 5}
    ]
    bottom = [
        {"name": "æˆ¿åœ°äº§", "change": -3.8, "volume_change": 25, "rank": 29},
        {"name": "é“¶è¡Œ", "change": -2.2, "volume_change": 20, "rank": 28}
    ]
    
    return {
        "success": True,
        "period": period,
        "top_sectors": sectors[:top_n],
        "bottom_sectors": bottom,
        "rotation_suggestion": "èµ„é‡‘ä»ä¼ ç»Ÿè¡Œä¸šæµå‘ç§‘æŠ€æ¿å—"
    }


def _mock_capital_flow(flow_type: str, days: int) -> Dict:
    result = {"success": True, "days": days}
    
    if flow_type in ["north", "all"]:
        result["north_flow"] = {
            "total": 150.5,
            "daily": [30, 25, 35, 40, 20.5],
            "trend": "å‡€æµå…¥"
        }
    if flow_type in ["margin", "all"]:
        result["margin_flow"] = {
            "balance": 16500,
            "change": 120,
            "trend": "å°å¹…å¢åŠ "
        }
    if flow_type in ["main", "all"]:
        result["main_flow"] = {
            "net": -50,
            "trend": "ä¸»åŠ›å°å¹…æµå‡º"
        }
    
    return result


def _mock_sentiment(include_detail: bool) -> Dict:
    import numpy as np
    np.random.seed(int(__import__('time').time()) % 100)
    
    score = np.random.randint(40, 70)
    return {
        "success": True,
        "sentiment_score": score,
        "sentiment_level": "åä¹è§‚" if score > 55 else ("åæ‚²è§‚" if score < 45 else "ä¸­æ€§"),
        "indicators": {
            "fear_greed_index": score,
            "market_temperature": score + 5,
            "trading_activity": "æ´»è·ƒ" if score > 50 else "ä¸€èˆ¬"
        },
        "suggestion": "å¸‚åœºæƒ…ç»ªç¨³å®šï¼Œå¯æ­£å¸¸æ“ä½œ"
    }


def _mock_macro(indicators: List[str]) -> Dict:
    data = {
        "gdp": {"value": 5.2, "unit": "%", "period": "2024Q3", "trend": "ç¨³å®š"},
        "cpi": {"value": 0.3, "unit": "%", "period": "2024-11", "trend": "ä½ä½"},
        "pmi": {"value": 50.3, "unit": "", "period": "2024-11", "trend": "æ‰©å¼ "},
        "interest_rate": {"value": 3.45, "unit": "%", "period": "2024-12", "trend": "ç¨³å®š"}
    }
    
    return {
        "success": True,
        "indicators": {k: data.get(k, {"value": "N/A"}) for k in indicators},
        "overall_assessment": "å®è§‚ç»æµä¼ç¨³ï¼Œæ”¿ç­–æ”¯æŒåŠ›åº¦å¤§"
    }


def _get_recommendation(status: str) -> str:
    recommendations = {
        "strong_bull": "å¼ºåŠ¿è¡Œæƒ…ï¼Œå¯é€‚å½“è¿½æ¶¨ï¼Œé€‰æ‹©é«˜è´å¡”ç­–ç•¥",
        "bull": "ä¸Šå‡è¶‹åŠ¿ï¼Œå¯ä»¥å¢åŠ ä»“ä½ï¼Œé€‰æ‹©åŠ¨é‡ç­–ç•¥",
        "neutral": "éœ‡è¡è¡Œæƒ…ï¼Œä¿æŒä¸­æ€§ä»“ä½ï¼Œè½®åŠ¨ç­–ç•¥",
        "bear": "ä¸‹è·Œè¶‹åŠ¿ï¼Œé™ä½ä»“ä½ï¼Œé€‰æ‹©é˜²å¾¡æ€§ç­–ç•¥",
        "strong_bear": "å¼ºåŠ¿ä¸‹è·Œï¼Œå‡ä»“è§‚æœ›ï¼Œç­‰å¾…ä¼ç¨³ä¿¡å·"
    }
    return recommendations.get(status, "ä¿æŒè°¨æ…")


async def main():
    async with mcp.server.stdio.stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="market-server-v2",
                server_version="2.0.0"
            )
        )


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
# ==================== ğŸ†• å¤šè§’åº¦éªŒè¯å‡½æ•° ====================

async def _handle_comprehensive(args):
    """
    å¤šè§’åº¦ç»¼åˆéªŒè¯å¸‚åœºçŠ¶æ€
    æ•´åˆï¼šæŠ€æœ¯é¢ã€èµ„é‡‘é¢ã€æƒ…ç»ªé¢ã€æ¿å—è¡¨ç°
    """
    from datetime import datetime
    
    index = args.get("index", "000300.XSHG")
    verification_level = args.get("verification_level", "standard")
    
    result = {
        "success": True,
        "analysis_time": datetime.now().isoformat(),
        "verification_level": verification_level,
        "dimensions": {},
        "cross_validation": {},
        "confidence": 0,
        "conclusion": ""
    }
    
    scores = []
    signals = []
    
    # æŠ€æœ¯é¢åˆ†æ
    try:
        from core.trend_analyzer import TrendAnalyzer
        analyzer = TrendAnalyzer()
        trend_result = analyzer.analyze_market(index_code=index)
        
        tech_score = trend_result.composite_score
        tech_signal = "çœ‹å¤š" if tech_score > 20 else ("çœ‹ç©º" if tech_score < -20 else "ä¸­æ€§")
        
        result["dimensions"]["technical"] = {
            "source": "TrendAnalyzer",
            "score": tech_score,
            "signal": tech_signal,
            "phase": trend_result.market_phase
        }
        scores.append(("æŠ€æœ¯é¢", tech_score, tech_signal))
        signals.append(tech_signal)
    except Exception as e:
        result["dimensions"]["technical"] = {"error": str(e)}
    
    # æ¿å—çƒ­åº¦ï¼ˆAKShareä¸œæ–¹è´¢å¯Œï¼‰
    if verification_level in ["standard", "deep"]:
        try:
            import akshare as ak
            df_concept = ak.stock_board_concept_name_em()
            if df_concept is not None and not df_concept.empty:
                up_count = len(df_concept[df_concept["æ¶¨è·Œå¹…"] > 0])
                down_count = len(df_concept[df_concept["æ¶¨è·Œå¹…"] < 0])
                total = len(df_concept)
                
                sector_score = (up_count - down_count) / total * 100 if total > 0 else 0
                sector_signal = "çœ‹å¤š" if sector_score > 20 else ("çœ‹ç©º" if sector_score < -20 else "ä¸­æ€§")
                
                result["dimensions"]["sectors_akshare"] = {
                    "source": "AKShare(ä¸œæ–¹è´¢å¯Œ)",
                    "up_count": up_count,
                    "down_count": down_count,
                    "score": round(sector_score, 1),
                    "signal": sector_signal
                }
                scores.append(("æ¿å—çƒ­åº¦", sector_score, sector_signal))
                signals.append(sector_signal)
        except Exception as e:
            result["dimensions"]["sectors_akshare"] = {"error": str(e)}
    
    # äº¤å‰éªŒè¯
    if len(signals) >= 2:
        bullish = signals.count("çœ‹å¤š")
        bearish = signals.count("çœ‹ç©º")
        neutral = signals.count("ä¸­æ€§")
        
        max_agreement = max(bullish, bearish, neutral)
        consistency = max_agreement / len(signals)
        
        if bullish > bearish and bullish > neutral:
            overall = "çœ‹å¤š"
            confidence = "é«˜" if consistency > 0.8 else ("ä¸­" if consistency > 0.6 else "ä½")
        elif bearish > bullish and bearish > neutral:
            overall = "çœ‹ç©º"
            confidence = "é«˜" if consistency > 0.8 else ("ä¸­" if consistency > 0.6 else "ä½")
        else:
            overall = "ä¸­æ€§"
            confidence = "ä¸­"
        
        result["cross_validation"] = {
            "bullish_count": bullish,
            "bearish_count": bearish,
            "neutral_count": neutral,
            "consistency": round(consistency * 100, 1)
        }
        result["confidence"] = confidence
        result["conclusion"] = f"ç»¼åˆ{len(signals)}ä¸ªç»´åº¦åˆ†æï¼Œ{overall}ä¿¡å·ï¼Œç½®ä¿¡åº¦{confidence}"
        result["overall_signal"] = overall
    
    return result


async def _handle_eastmoney_concepts(args):
    """è·å–ä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å—å®æ—¶æ•°æ®ï¼ˆAKShareæ•°æ®æºï¼‰"""
    top_n = args.get("top_n", 20)
    sort_by = args.get("sort_by", "change")
    
    try:
        import akshare as ak
        df = ak.stock_board_concept_name_em()
        
        if df is None or df.empty:
            return {"success": False, "error": "æ— æ³•è·å–ä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å—æ•°æ®"}
        
        sort_map = {"change": "æ¶¨è·Œå¹…", "volume": "æˆäº¤é‡", "turnover": "æˆäº¤é¢"}
        sort_col = sort_map.get(sort_by, "æ¶¨è·Œå¹…")
        
        if sort_col in df.columns:
            df_sorted = df.sort_values(sort_col, ascending=False)
        else:
            df_sorted = df.sort_values("æ¶¨è·Œå¹…", ascending=False)
        
        top_concepts = []
        for _, row in df_sorted.head(top_n).iterrows():
            concept = {
                "name": row.get("æ¿å—åç§°", ""),
                "change_pct": row.get("æ¶¨è·Œå¹…", 0),
                "leader_stock": row.get("é¢†æ¶¨è‚¡ç¥¨", ""),
                "leader_change": row.get("é¢†æ¶¨è‚¡ç¥¨-æ¶¨è·Œå¹…", 0)
            }
            top_concepts.append(concept)
        
        up_count = len(df[df["æ¶¨è·Œå¹…"] > 0])
        down_count = len(df[df["æ¶¨è·Œå¹…"] < 0])
        avg_change = df["æ¶¨è·Œå¹…"].mean()
        hot_themes = df_sorted.head(5)["æ¿å—åç§°"].tolist()
        
        return {
            "success": True,
            "data_source": "AKShare(ä¸œæ–¹è´¢å¯Œ)",
            "total_concepts": len(df),
            "statistics": {
                "up_count": up_count,
                "down_count": down_count,
                "avg_change": round(avg_change, 2),
                "market_breadth": round(up_count / len(df) * 100, 1) if len(df) > 0 else 0
            },
            "hot_themes": hot_themes,
            "top_concepts": top_concepts
        }
        
    except ImportError:
        return {"success": False, "error": "AKShareæœªå®‰è£…"}
    except Exception as e:
        return {"success": False, "error": str(e)}


async def _handle_five_dimension_score(args):
    """å¯¹æŒ‡å®šä¸»çº¿è¿›è¡Œäº”ç»´è¯„åˆ†è¯¦ç»†åˆ†æ"""
    theme_name = args.get("theme_name")
    
    if not theme_name:
        return {"success": False, "error": "è¯·æä¾›ä¸»çº¿åç§°(theme_name)"}
    
    try:
        from core.five_dimension_scorer import FiveDimensionScorer
        
        scorer = FiveDimensionScorer()
        score_result = scorer.score(theme_name)
        
        if score_result:
            return {
                "success": True,
                "theme_name": theme_name,
                "total_score": score_result.total_score,
                "dimensions": {
                    "fundamental": score_result.fundamental.score if score_result.fundamental else 0,
                    "technical": score_result.technical.score if score_result.technical else 0,
                    "capital": score_result.capital.score if score_result.capital else 0,
                    "news": score_result.news.score if score_result.news else 0,
                    "position": score_result.position.score if score_result.position else 0
                },
                "radar_data": score_result.get_radar_data()
            }
        else:
            return {"success": False, "error": f"æœªæ‰¾åˆ°ä¸»çº¿'{theme_name}'çš„è¯„åˆ†æ•°æ®"}
            
    except Exception as e:
        # ä½¿ç”¨AKShareè·å–ç®€åŒ–ç‰ˆè¯„åˆ†
        try:
            import akshare as ak
            df = ak.stock_board_concept_name_em()
            if df is not None and not df.empty:
                theme_row = df[df["æ¿å—åç§°"].str.contains(theme_name[:4], na=False)]
                if not theme_row.empty:
                    row = theme_row.iloc[0]
                    change = float(row.get("æ¶¨è·Œå¹…", 0))
                    tech_score = min(20, max(0, 10 + change))
                    
                    return {
                        "success": True,
                        "theme_name": theme_name,
                        "source": "AKShare(ç®€åŒ–ç‰ˆ)",
                        "total_score": tech_score * 5,
                        "dimensions": {"technical": tech_score},
                        "note": "å®Œæ•´äº”ç»´è¯„åˆ†éœ€è¦æ›´å¤šæ•°æ®æºæ”¯æŒ"
                    }
        except:
            pass
        
        return {"success": False, "error": str(e)}

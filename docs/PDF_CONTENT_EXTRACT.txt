=== 第1页 ===
TRQuant韬睿量化系统 – 软件工程优化与实施建议
1. MCP使用规范与开发流程标准化
1.1 MCP工具调用规范统一
命名与参数规则 ：为MCP工具制定统一的命名规范和参数结构。工具名称应当简洁描述功能，采用 模块_动
作格式（例如 trquant_mainlines 表示主线识别）便于识别。输入/输出参数使用JSON Schema定义，
确保类型安全并在调用前自动验证 。同时，每个工具应清晰定义所需资源和上下文，避免参数歧义。
trace_id追踪 ：在MCP调用链路中引入全局唯一的 trace_id ，将其贯穿请求、响应和日志证据记录，方
便调试和审计 。例如，在每次工具调用时生成trace_id，传递给后续相关调用和Evidence Server记录，
确保 所有操作可追溯 。
错误码与异常处理 ：建立统一的错误码和异常格式。当MCP服务器发生错误时，返回标准化的JSON错误对
象，包含错误码、错误消息和trace_id等 。调用端根据错误码分类处理（重试、回退或中止），并通过
Evidence Server记录错误详情。避免直接抛出未捕获异常，确保 所有异常都有明确的处理策略 。
1.2 Cursor扩展中MCP调用流程规范
触发方式与流程 ：在Cursor对话中使用“MCP://”或命令前缀来触发MCP调用。采用标准的 提示模板 ，明确说
明工具意图、输入格式和期望输出。例如，在提示中包含工具名称、参数JSON示例以及 “请按照JSON格式输
出”等要求，从一开始就约束LLM输出格式，减少幻觉空间。
提示模板结构 ：推荐使用 强提示 （strong prompting）技术降低幻觉风险 。提示模板包含：1）调用目
的和背景说明，2）所需字段和JSON schema定义（或输出示例），3）步骤指导（如“先调用X工具获取数
据，再……最后返回结果”）。通过 结构化提示 明确每步操作，提示LLM严格遵循顺序和格式，从而提高准确
性 。必要时可加入Few-Shot示例，让模型参考正确的调用–响应格式。
输出存储与artifact化 ：对于MCP调用产生的大型结果（如完整策略代码、长报告等），避免直接在对话中
展开。建议MCP服务器将大结果保存为文件artifact，并返回路径或标识。在Cursor中，可通过 cat 
<<artifact>> 等命令预览部分内容。遵循“ 大输出artifact化 ”铁律，将大文件存储于 .taorui/
artifacts/ 目录并建立索引 。这样既保证对话简洁，又方便后续检索和比对历史版本。
避免LLM幻觉的方法 ：采取多层防护降低幻觉 ：
输入校验 ：对用户请求和工具参数进行严格验证（格式、取值范围）。杜绝不完整或异常输入诱发模型胡乱
编造 。
执行监控 ：在LLM生成工具调用过程中，由代理层监督每次调用是否真实成功返回结果。如果某一步返回为
空或失败，禁止LLM臆测结果，而是要求其重新调用或报告错误 。
输出验证 ：对LLM最终输出强制套用预定义格式/模式（如JSON Schema）。将模型回复与模式比对，不符
则要求其修正 。利用 结构化响应 减少自由发挥，从而降低虚构内容的概率 。此外，引入RAG（检索
增强）为模型提供经过验证的资料作为依据，可将幻觉率降低60–80% 。
上下文过滤 ：屏蔽不相关或有干扰的信息，仅提供和当前任务相关的知识段落，避免模型串联无关内容导致
跑题。• 
1
• 
2
• 
1
• 
• 3
4
• 
5
• 4
• 
6
• 
7
• 
8 8
3
• 
1

=== 第2页 ===
1.3 MCP类型组织与结果归档
目录分层组织 ：按照MCP功能类型将服务器划分目录，清晰管理。建议顶层分为三类： business/ （业务工
具）、 data/ （数据/知识工具）、 dev/ （开发支撑工具）。例如： business/trading_mcp/ 、data/
collector_mcp/ 、dev/lint_mcp/ 等。这样不同性质的MCP隔离，易于协同开发和部署。
工具类MCP （如代码、Lint、Test等）放入 dev目录，关注代码分析和规范检查。
数据类MCP （如Data Source、Data Collector、KB等）放入 data 目录，提供数据获取、处理与知识检索功
能。
业务流程类MCP （如TRQuant核心、Factor、Backtest、Trading等）放入 business 目录，实现量化投资主
链路各环节工具。
Artifact归档 ：统一MCP调用产出物的存档策略。所有MCP的重要输出（如回测报告、策略代码、模型文件
等）都应保存至对象存储或文件系统的artifact目录，并在PostgreSQL中记录元数据（包含文件hash、路
径、生成时间、关联的任务或策略ID） 。通过Evidence Server将artifact操作与trace_id关联记录，
形成 证据链 。同时，约定artifact命名规则，如 {日期}_{工具名}_{描述}.md ，方便按日期和工具分类查
找。定期清理或版本管理artifact，旧版重要结果打tag保留，确保知识积累和可追溯。
2. GUI前端开发建议
2.1 桌面GUI（PyQt6）开发模式与组件选择
开发模式 ：采用 MVC/MVVM 等模式组织PyQt代码，将界面与业务逻辑解耦。通过模型类管理数据和状态，
UI通过绑定或信号槽与模型交互，方便状态管理和后续扩展。利用Qt的 QObject 和pyqtSignal /
pyqtSlot 机制，在各模块间发送状态变更信号，实现 统一的状态管理 （例如 workflow当前步骤、任务进
度、结果更新等）。
任务触发与异步 ：对于回测、数据更新等耗时操作，使用 多线程/异步任务触发器 ，避免阻塞UI线程。可以
使用 QThread 或QtConcurrent 来执行后台任务，并在完成后通过信号通知UI更新结果。封装通用的任
务触发器组件，支持任务队列、进度条、取消控制等，提升前端对后台工作的掌控能力。
图表展示库 ：在PyQt6中引入专业绘图组件以实时展示金融数据和回测结果。推荐使用 PyQtGraph （纯
Python实现，性能高，适合实时更新）或Qt官方的 Qt Charts 模块来绘制K线图、收益曲线等 。
PyQtGraph可用于快速动态绘制（如逐笔行情、回测净值曲线实时刷新），而Qt Charts提供丰富的图表元
素便于构建专业报表图形。对于复杂交互图表，也可考虑在QWebEngine中嵌入ECharts/Plotly前端图表，
实现更华丽的可视化效果。
2.2 文件结构与模块划分
分层组织代码 ：按界面功能模块将前端代码拆分，避免单一巨型窗口类。建议按照 页面/对话 进行模块划
分，如 main_window.py （主界面框架）、 trend_view.py （市场趋势页）、 factor_view.py
（因子管理页）等，每个模块负责一个界面区域或对话逻辑。通用组件（如导航栏、日志窗口、小部件）提
取到 components/ 目录。这样层次清晰，各模块内关注各自领域逻辑， 降低耦合 。
逻辑与显示分离 ：将业务计算和数据处理逻辑移出UI类，在核心层或专门的Controller中实现。UI层只处理
用户交互和数据显示，由Controller调用底层API/MCP并将结果反馈UI。这种 接口契约 确保UI改动不影响核
心逻辑，实现前后端并行开发 。同时接口定义清晰，也为未来替换前端技术（如Web）提供便利。
配置与资源管理 ：建立前端配置模块，集中管理应用所需的资源路径、样式表、常量等。例如 config.py
内定义API端口、文件路径， styles.qss 管理统一样式，这样调整配置无需修改业务代码。对于UI文
本、标签等，可考虑国际化支持（Qt自带翻译机制）以提升系统开放性。• 
• 
• 
• 
• 
910
• 
• 
• 
11
• 
• 
12
• 
2

=== 第3页 ===
2.3 构建、调试与部署工具链
构建工具链 ：使用PyQt打包工具（如 PyInstaller 或cx_Freeze ）将应用及依赖打包成独立可执行程
序，方便部署给用户。建立自动化的构建脚本，例如 build.py ，可一键生成Windows和Linux可执行文
件。结合CI，在代码合并后触发构建和基本测试，确保 持续交付 质量。
调试支持 ：在开发环境下启用调试日志窗口或控制台输出，实时打印MCP调用、数据流信息，便于排查问
题。利用PyQt的日志机制将重要事件（如收到后台信号、UI操作）写入日志文件，辅助分析复杂交互问题。
推荐集成一个 日志查看面板 在GUI中，方便开发和高级用户查看内部运行状态。
部署方案 ：针对不同用户群提供多种发布形式。桌面应用方面，通过上述打包工具生成安装包；对于希望自
行运行源码的用户，提供Python虚拟环境依赖清单和一键启动脚本。一并提供Docker镜像，包含前端（通
过X11或Web界面）和后台服务配置，方便在服务器/云端部署使用。文档中附详细的部署指南，列出所需环
境、启动步骤和常见问题解决，降低用户上手难度。
2.4 Web前端演进方向
采用Web技术的考量 ：为未来扩大用户群和跨平台易用性，可评估引入Web前端方案。使用 Next.js 框架开
发Web界面是一条可行路径。Next.js基于React生态，支持服务端渲染和丰富的UI组件库，适合构建复杂前
端。同时，它便于与现有系统通过REST/WebSocket接口集成。若采用Web前端，核心逻辑仍通过后端API
提供，可保持与当前桌面版一致的业务层接口。
Electron vs Tauri ：若希望在保持桌面应用形态的同时利用Web技术UI，可考虑Electron或Tauri包装。
Electron 成熟且社区庞大，能快速将Next.js前端封装为桌面应用，但缺点是体积大、内存占用高（每个应用
内嵌完整Chromium）。 Tauri 是新兴替代方案，利用操作系统原生WebView渲染，生成的应用体积很小
（往往小于5MB）且运行时内存占用更低 。Tauri允许使用任意前端框架（React/Vue等）开发UI 。
然而，需注意Tauri要求使用Rust开发后端逻辑，对团队技术栈有一定挑战 。综合来看：
如果团队以Web前端为主，想快速跨平台，Electron更成熟（但需接受应用体积大）。
如果追求更轻量、安全并乐于尝试Rust技术，Tauri值得考虑，其小内存占用和体积优势明显 。
渐进式迁移 ：演进不一定要一次性重构全部前端。可以考虑 双轨并行 ：保持PyQt6桌面版迭代的同时，尝试
开发Web版核心模块（如策略浏览器、回测报告仪表板）作为实验。一旦Web端成熟稳定，可逐步扩充功
能，最终用户既可选择桌面GUI也可通过浏览器访问。此外，通过Web技术也便于实现 远程管理 （例如在移
动端查看策略运行状况），拓展系统使用场景。
3. MCP Server分类与调用机制优化
3.1 MCP服务器功能分类矩阵
将现有26个MCP服务器按功能划分为四类，明确各自定位，方便优化资源和调用顺序：
核心流程型 （投资工作流主线工具）：负责八步流程中的关键步骤，直接产出投资决策相关结果。包括：
TRQuant核心服务器  – 提供市场状态、投资主线、因子推荐、策略生成、回测分析等主流程工具 。
Data Source Server  – 数据源管理（行情数据获取、源切换监控）。
Factor Server  – 因子计算与评估（提供60+因子计算及IC/IR等评价） 。
Backtest Server  – 回测任务执行与结果分析 。
Trading Server  – 实盘交易执行与账户管理 。
Optimizer/Strategy Optimizer  – 策略参数优化、多目标优化与策略组合优化。
Strategy Template Server  – 策略模板库管理与生成。
Strategy KB Server  – 策略规则知识库查询与策略推荐支持。• 
• 
• 
• 
• 
13 14
15
• 
• 13
• 
• 
• 16
• 
• 17
• 18
• 19
• 
• 
• 
3

=== 第4页 ===
数据增强型 （数据采集与知识扩充工具）：为核心流程提供高质量数据和信息支撑，提升决策依据。
KB Server  – 知识库查询，提供开发手册和工程知识检索（向量+BM25混合检索） 。
Data Collector Server  – “黑客助理”，执行网页爬取、PDF下载、学术论文收集、代码仓库分析等，帮助获取
外部数据和验证方案 。
Data Quality Server  – 数据质量检查，监测数据完整性、一致性，发现异常并报告 。
(策略知识扩展)  Strategy KB（策略知识库）亦可归入此类，提供额外的策略经验和规则支持。
验证型 （开发与运行过程的验证工具）：用于校验代码和数据的正确性、规范性，确保系统稳定可靠。
Lint Server  – 代码规范检查（PEP8、类型检查） 。
Test Server  – 测试用例管理与执行，返回覆盖率和结果 。
Schema Server  – 数据模式验证（JSON Schema校验、数据库Schema一致性） 。
Spec Server  – 开发规范/文档规范检查，确保代码和文档符合约定 。
Data Quality Server （亦属于验证范畴，用于校验数据正确性，防止错误数据进入主流程）。
支持型 （系统支撑与运维工具）：面向项目管理、配置管理、流程编排等，保证系统开发和运行高效。
Task Server  – 任务树管理与状态跟踪 。
Workflow Orchestrator Server  – 工作流定义、执行与状态持久化 。
Evidence Server  – 证据日志记录，保存所有操作审计追踪 。
Config Server  – 系统配置管理与版本控制 。
Docs/Manual Generator Server  – 文档查询与自动生成（API文档、开发手册） 。
ADR Server  – 架构决策记录管理，查询决策历史 。
Engineering Server  – 工程构建和部署工具集成，提供DevOps支持 。
Secrets Server  – 密钥管理，安全存储和轮换访问密钥 。
Report Server  – 报告生成（回测报告、分析报告、对比报告） 。
说明 ：以上分类中， 核心流程型 MCP服务于量化投资的主要步骤， 数据增强型 提供信息补充和数据保障， 验证型 确
保过程规范和结果可靠， 支持型 则承担项目运维和协同功能。明确分类有助于针对性优化，例如核心工具需要高性
能和稳定性，验证工具侧重准确性和与CI集成，支持工具注重安全和可扩展性。
3.2 MCP调用路径示例（主流程）
制定清晰的MCP调用链路，有助于AI代理（轩辕剑灵）在完成复杂任务时按合理顺序组织工具。以下是一个推荐的
典型调用路径，实现从市场分析到策略回测的全流程：
市场状态分析 ：调用 trquant_market_status 获取当前A股市场宏观状态，包括市场Regime、指数趋
势、风格轮动等 。根据输出的市场情绪和风格信息判断投资方向。
投资主线识别 ：调用 trquant_mainlines 获取TOP主线主题和对应评分 。指定短/中/长期周期各自
的主线列表，并结合市场状态筛选最契合当前环境的主线。输出选定的主线名称及相关行业/概念信息。
候选股票池构建 ：根据选定主线，筛选相关板块或概念中的股票，应用多维度指标过滤（基本面、技术面、
资金面、风险等）。可调用 CandidatePool模块 （如有实现）或通过Data Source获取主线涉及股票列表，
再计算每只股票评分筛选出前N只，形成候选池。
因子推荐与计算 ：调用 trquant_recommend_factors 获取适合当前市场环境和主线的候选因子 。
根据返回的多因子组合建议，调用 Factor MCP 批量计算候选池股票在近历史上的这些因子值，并计算因子
暴露和相关性 。可选地，利用Factor Server输出各因子的IC值，筛除无效因子。
策略生成 ：调用 trquant_generate_strategy ，传入主线、候选股票和精选因子列表，让AI生成相应
的策略代码 。生成时可选择PTrade或QMT平台格式，并指定策略风格（动量/价值/中性等）。工具应返
回策略的主要逻辑说明和代码存储路径。• 
• 20
• 
21
• 22
• 
• 
• 23
• 24
• 25
• 26
• 
• 
• 27
• 28
• 2
• 29
• 30
• 31
• 32
• 22
• 33
1. 
16
2. 34
3. 
4. 35
17
5. 
36
4

=== 第5页 ===
回测执行 ：调用 Backtest MCP 提交回测任务，包括策略ID/代码路径、回测时间范围、基准和参数配置
。Backtest Server异步执行回测，将任务加入队列，利用并行能力加速 。可通过Task Server查询回
测进度，如完成则获取结果。
回测结果分析 ：回测完成后，调用 trquant_analyze_backtest 或Report MCP ，对结果指标进行深入
分析 。生成回测报告包括：累计收益曲线、收益风险指标（年化收益、Sharpe、最大回撤等）、因
子表现、交易统计（胜率、盈亏比）等。Report Server可同时将HTML/PDF报告保存至MinIO并返回路径
。
策略评估决策 ：综合以上分析，AI助手可根据预设阈值判断策略是否通过（如收益风险比达标），给出调优
建议或直接建议实盘部署。若需调优，则迭代调用Optimizer调整参数并再次回测，形成 闭环优化 流程，直
到策略满足标准。
通过上述分步链路，能将复杂任务拆解成可控的模块操作，每一步都有清晰输入输出，既方便自动编排也允许人工
介入调整。建议在Workflow Orchestrator中将类似流程模板化，方便一键启动整套流程并监控各步骤结果。
3.3 MCP服务合并与隔离策略
目前MCP服务器较多，适当的合并有助于降低管理复杂度，但也需考虑任务类型和资源隔离。建议如下：
合并为多工组的候选 ：将某些紧密相关、调用链固定且资源需求相近的MCP合并为单一进程内的多工具组，
以减少进程间通信开销。例如：
Optimizer MCP  与 Strategy Optimizer MCP ：两者都涉及策略参数/组合优化，可以合并为一个“优化MCP”，
内部根据参数决定执行单策略优化或策略组合优化。合并后共享算法库，避免重复实现。
Manual Generator  与 Docs MCP ：都属于文档生成/管理范畴，可整合为一个“文档MCP”，既提供文档查询也
提供手册/报告生成功能。这样文档模板渲染、版本管理逻辑集中处理，减少模块冗余 。
Code, Lint, Schema, Spec MCP ：这些属于开发质量保障工具，可以考虑部分合并。例如将Lint和Schema、
Spec合并成 “Quality MCP” ，因为它们都是检查规范和模式的（Lint检查代码风格，Schema/Spec检查数据
和API规范）。统一后对外提供不同子命令，内部共享校验框架。
Task & Workflow MCP ：二者在语义上分层（任务 vs 工作流），但可在实现上结合——Workflow调度可以
利用Task管理。可将Workflow Orchestrator实现为Task Server的一个扩展，由Task Server维护任务树和
状态，Workflow层面仅定义任务依赖关系和触发逻辑。这样减少独立服务数目，同时确保 任务队列和编排
统一管理 。
Report MCP  与 Backtest MCP ：回测完通常紧接着生成报告，可将报告生成视为回测流程的一个阶段。在
Backtest MCP中直接集成报告生成步骤，或者通过配置决定是否自动生成报告，避免为单纯格式输出再启
用独立服务。但若报告生成耗时长、依赖额外包，也可保持分离以便横向扩展。
保持独立的必要 ：某些MCP需要出于 性能和安全 考虑单独隔离：
计算密集型如Backtest、Data Collector（爬虫）等应独立，以便分配更多资源或运行在不同主机，不干扰
其他服务的响应。特别是Backtest可能占用大量CPU/内存，隔离可防止阻塞AI代理的实时响应。
涉及外部系统的如Trading MCP（对接券商交易）应独立部署，确保 安全隔离 交易凭证，并在出问题时不影
响整个系统稳定。
Secrets MCP理应隔离，避免与其他模块在一个进程，最大程度保证密钥安全。
Evidence/Config这类底层支撑服务可轻量，但独立有助于在系统发生崩溃时仍然可靠记录证据和保留配置
完整性。
模块化插件 ：采用插件架构的方式实现MCP，有利于灵活组合或拆分。例如，提供统一的RPC服务框架，每
个MCP工具作为插件注册进去。部署时可根据需要开启哪些插件。在开发调试时合并运行，发布时再根据负
载拆分。通过这种 模块即服务 思路，兼顾了合并管理和隔离部署的弹性。6. 
18 37
7. 
38 39
9
8. 
• 
• 
• 
30
• 
• 
• 
• 
• 
• 
• 
• 
• 
5

=== 第6页 ===
3.4 MCP自动调度与组合调用机制
为提高工作流自动化程度，建议实现MCP之间的 自动串联调度 ，由系统根据任务高层描述自主决定调用顺序和组
合：
Workflow编排器 ：加强Workflow MCP的智能性。可以为常见任务链预设 工作流模板 ，例如“策略开发流
程”模板包含上述3.2节的调用顺序。当用户触发该工作流时，编排器自动按照模板依次调用各MCP，并处理
依赖和数据传递。对于灵活性，可让编排器根据前一步结果动态调整后续步骤（如主线不足时跳过候选池细
分，或者回测结果不佳时自动调参重跑）。工作流执行过程中，将每步的输入输出通过Evidence Server持
久化，以便中途出错可恢复重试 。
工具组合调用 ：支持一次请求触发 一组MCP串行执行 。例如封装一个高级指令
generate_and_test_strategy ，内部先后调用策略生成→回测→报告，不需要用户逐步调用。实现
上，可在AI代理层引入 宏工具 概念，将常用序列注册为一个虚拟工具。用户调用宏工具时，代理按预定顺序
执行多步MCP，聚合结果返回。这减少人工参与步骤，同时每步仍可审计和trace。
事件驱动调度 ：建立MCP之间的事件发布/订阅机制。某些服务器完成任务后自动触发后续流程。例如
Backtest MCP完成后发布 backtest.done 事件，Workflow监听到后自动调用Report MCP生成报告；
Data Source完成数据更新发布 data.updated 事件，触发重新运行市场分析/主线识别。这种 事件总线
（可用Redis的pub/sub或简单消息队列实现 ）使系统具备一定实时响应能力，减少人工启动流程的等
待。
资源感知与队列 ：自动调度时要考虑系统资源负载。可通过Redis队列或内部任务调度，限制并发调用数
（例如同时最多运行N个回测）。Workflow编排器应能查询各MCP的当前任务队列长度和资源占用，智能
选择等待或调度顺序，以防止过载。同时对 互斥工具 （如交易下单必须串行）强制串行调度，对 独立工具 尽
量并行以提高效率。
失败回滚与重试 ：在组合调用过程中，若某一步失败，提供自动重试或回滚机制。例如Data Collector获取
数据失败，可重试最多3次；如果因网络问题仍失败，Workflow标记该子任务失败但继续后续主要流程，以
免整个工作流中断。或者对于关键步骤失败则中止并通知用户。设计明确的 错误传播策略 ，让AI助手根据错
误类型决定下一步（重试/跳过/终止），提升自动化决策能力。
通过上述优化，多个MCP可以更加紧密地协同，形成 半自动化的AI流水线 ：用户只需下达高层指令，系统即可在安
全可控范围内自主完成一系列调用，实现真正的端到端智能化流程。
4. 数据库与知识系统设计
4.1 投资流程各环节数据表设计
遵循系统分层的数据架构 （Polyglot  Persistence），为八步投资流程的每一环节设计契合的存储表结构，以满
足事务性和分析性需求：
信息获取（数据源） ：主要保存市场原始数据和研究信息。
行情数据表 （时序库）: 存储股票和指数OHLCV行情，表结构如： market_data(date, asset_id, 
open, high, low, close, volume, ...) ，对于分钟级或Tick数据也可建立类似结构并做好分区/索
引。使用ClickHouse或TimescaleDB来支持高并发读写和时间聚合查询 。
宏观经济数据表 （时序/关系库）: 如利率、通胀率指标，按日期存储。字段示例：
macro_indicators(date, gdp, cpi, interest_rate, ...) 。
研究报告/资讯索引 （文档库/MongoDB）: 保存获取的研报全文或链接，字段： research_doc(_id, 
title, source, date, tags, content) ，content存储全文（或MinIO路径），tags标注主题。• 
40 41
• 
• 
42
• 
• 
43
• 
• 
44
• 
• 
6

=== 第7页 ===
市场趋势分析 ：保存由行情数据计算的各类趋势指标和市场状态结果。
市场状态表 （关系库）: 记录每次分析得出的市场状态快照。字段： market_status(date, regime, 
trend_label, sentiment_score, style_rotation) ，其中regime（牛熊市类）、trend_label
（上升/下降趋势）等由分析模块给出 。
技术指标表 （时序库）: 存储每日技术指标，如指数的MACD、RSI等，用于趋势判断。字段：
index_tech_indicators(date, index_id, macd, rsi, ...) 。
投资主线识别 ：记录每次主线扫描的结果。
主线主题表 （关系库）: 字段： mainline_scan(date, period, theme, score, factors, 
top_stocks) , 保存扫描日期、周期（短中长）、主线名称、五维评分等 。可将top_stocks存为JSON
数组或建立关联表列出。
主线得分明细表 ：若五维评分细则需存储，可有表：
mainline_scores(date, theme, dimension, score) ，dimension例如政策面、基本面等，
score为该维度分数。这样可以追踪每条主线评分变化。
候选池构建 ：存储每次根据主线筛选出的股票池及其评分。
候选股票池表 （关系库）: candidate_pool(date, theme, stock_id, score, rank) ，记录某
主题在某次筛选中的候选股票及其多维综合得分和排序。
股票维度评分表 ：可选，将综合评分拆解到维度： stock_score_detail(date, stock_id, 
factor_score, fundamental_score, technical_score, risk_score, total_score) ，保
存单只股票各方面评分，辅助分析筛选依据。
因子构建 ：大规模因子数据需高效存储和版本管理。
因子值表 （时序/列式存储）: 可采用长表结构： factor_data(date, stock_id, factor_name, 
value)，其中factor_name为因子标识。这种 窄表 便于按因子或股票过滤查询。如果采用 宽表 （每列一个
因子），当因子数量多变维护麻烦，推荐窄表配合高性能列存数据库（ClickHouse）来查询 。 
因子元信息表 （关系库）: factor_info(factor_name, category, description, 
calc_method, version, author) ，记录因子描述、分类（技术/基本面/情绪等）、计算方法简述和
版本。每当因子公式重大变更时版本加1，新旧版本可并行存储以供回溯比较。
因子ICIR表 （分析库）: 存储因子绩效指标，如每月IC、IR值： factor_performance(factor_name, 
date, ic, ir) ，供因子有效性评估和淘汰低效因子。
策略开发 ：集中管理策略配置、代码与版本。
策略定义表 （PostgreSQL）: strategy(id, name, type, status, author, created_at, 
description) ，保存策略基本信息（类型如多因子/动量，状态如开发中/已上线）。PostgreSQL强事务
保障策略元数据的一致性 。
策略参数表 ：strategy_param(strategy_id, param_name, param_value, version) ，记录
策略的参数集，可根据版本区分历史参数调整记录。版本号对应代码版本或日期。
策略代码仓库 ：由于策略代码可能较长，建议保存在Git仓库或文件库的 strategies/ 目录，以文件形式
管理，版本控制通过Git commit。策略定义表中保存代码文件路径和最新commit哈希，以关联代码和数据
库记录 。 
策略模板表 ：strategy_template(id, name, description, template_code_path) , 存放可
复用的策略模板信息，与Strategy Template MCP联动，方便生成新策略。
策略优化 ：保存每次优化结果和历史。
优化任务表 ：optimization_task(id, strategy_id, start_time, end_time, status, 
objective) ，记录优化任务元数据（目标如maximize Sharpe），关联对应策略ID。可扩展字段记录使
用算法（网格/遗传等）。• 
• 
35
• 
• 
• 
45
• 
• 
• 
• 
• 
• 
44
• 
• 
• 
• 
46
• 
• 
47
• 
• 
• 
7

=== 第8页 ===
优化结果表 ：optimization_result(task_id, param_set, metric_values, is_best) ，每
条记录一个参数集合及其指标。param_set可存为JSON，metric_values存如{"Sharpe":1.2,"Return":10%}
等。标记is_best的为最优解。这样完整保留优化过程，便于分析参数稳健性。
回测验证 ：需要存储回测过程配置和结果摘要。
回测任务表 （PostgreSQL）: backtest_task(id, strategy_id, start_date, end_date, 
created_at, status, metrics_json) , 保存回测设置（策略、时间段等）及结果摘要指标。
metrics_json可存储总收益、年化、Sharpe等主要指标。以PostgreSQL保证提交与状态更新的可靠性
。
回测净值曲线表 （时序库）: equity_curve(task_id, date, equity) ，存储回测每日组合净值曲
线，用时序数据库便于后续做回撤等计算 。对比不同回测的曲线也可通过任务ID实现。
交易明细表 ：trade_log(task_id, date, stock_id, action, price, volume) ，保存回测中
的每笔交易，用于分析交易行为、计算换手率和滑点等。
风险指标表 ：risk_analysis(task_id, indicator, value) ，例如最大回撤、波动率、Beta等，
可在回测完成后计算入库，供查询报告使用。
回测报告存档 ：大篇幅的HTML/PDF报告存于MinIO，表中仅存路径 。如
backtest_task.report_path 指向MinIO文件，同时MinIO元数据表记录报告hash和生成时间。
实盘交易 ：需要严谨的账户和流水记录体系。
账户表 （PostgreSQL）: account(id, name, broker, balance, status) ，记录实盘账户信息，
余额随交易更新。强事务保障账户资金变动准确 。
持仓表 ：holding(account_id, stock_id, quantity, avg_cost) ，实时持仓数据，每笔交易会
更新相应持仓。可加持仓历史表记录每日快照。
订单表 ：order(id, account_id, stock_id, action, price, volume, status, 
timestamp) ，记录每次下单及状态（已报、已成、已撤等）。用于交易日志审计。
成交表 ：execution(order_id, exec_price, exec_volume, exec_time) ，记录订单的成交明
细，以准确计算滑点及交易成本。
资金流水表 ：cashflow(account_id, date, change, reason, ref_id) ，如存取款、分红等事
件产生的资金变化。
风控事件表 ：risk_event(account_id, timestamp, type, detail) ，记录实时风控监控触发的
事件（如触及止损、仓位超限），为异常处理提供依据。
以上设计中， PostgreSQL 用于事务性强、需审计追踪的数据（策略定义、交易流水等） ；时序库 用于存储大量
时间序列数据以供快速分析（行情、因子、绩效曲线等） ；MinIO 保存大对象文件如报告和研究文档 ；
MongoDB 保存结构灵活的研究材料。通过在各自最适合的存储上设计表结构，既保证查询和分析效率，又确保关
键数据可靠存储、易于版本管理。
4.2 数据字段模板与版本管理
针对不同类型的数据，制定标准字段模型和版本控制机制，以确保数据一致性和演进可追溯：
策略定义与版本 ：策略表和参数表中应有版本字段或单独的版本表。当策略逻辑或参数有重大更新时：
策略版本号递增，并在版本表记录变更说明、时间、变更人。版本号可以与Git代码版本对应，便于代码与
配置同步演进。
保留旧版本记录，不直接覆盖关键字段（例如不直接改策略名称、类型，可以通过新记录或附加版本信息保
持历史）。通过在审批流或上线记录表中记录版本关联，实现 版本审计 。
字段模板：策略名称(name)要求具有业务含义，类型(type)限定枚举（如 “多因子”、“套利” 等），状态
(status)区分“开发中/已上线/停用”。• 
• 
• 
46
• 
44
• 
• 
• 9
• 
• 
46
• 
• 
• 
• 
• 
48
44 9
• 
• 
• 
48
• 
8

=== 第9页 ===
因子矩阵数据 ：因子值存储需兼顾多版本（因子公式改进）：
可以通过 factor_info.version 来标识，如果新旧版本因子同时存在，可将factor_name区分，如
Alpha101_v2 ，或者引入有效日期范围字段。历史回测应引用当时版本的因子数据，以免混淆。
字段模板：date采用日期或日期时间统一格式，stock_id使用统一编码（如股票代码或内部ID），
factor_name建议简短（字母数字），value为浮点数。必要时增加字段标识计算方法（如TTM/季度调序
等）以防歧义。
定期对因子库进行 批次归档 ：例如每年末将全年因子数据固化成Parquet文件归档（MinIO保存），数据库
中只保留最近若干年的，以提高查询性能。老版本数据可通过档案方式获取，实现历史数据版本管理。
主线与评分模型 ：主线识别模型可能改进评分算法：
将主线评分模型的关键参数（如五维权重）记录在配置表或主线扫描结果中。这样将来调整评分逻辑，可以
通过版本区分前后结果。如字段 model_version 或在 mainline_scan 里加 algorithm 字段指示所
用算法版本。
字段模板：theme采用统一格式（可考虑用英文标识存储、中文名称另存以便展示），score统一百分制或
0-1浮点，维度评分保留小数点2位。对于每次扫描，赋唯一ID，关联可能的输入参数（比如所用数据窗口长
度等）。
回测结果 ：回测因策略或市场环境变化而不同，需要良好版本溯源：
回测任务表中的 strategy_id 应明确对应策略哪个版本（如果策略更新需重新跑回测）。可以在任务表
增加 strategy_version 字段，防止拿到错版本策略代码。
度量指标的计算方法版本也需管理，例如夏普比率公式调整，应记录变更日期，对应报告注明。可以在报告
或任务记录里存储 metrics_version 。
字段模板：指标统一年化或百分比的取值标准，如Return一律年化%、Volatility年化%、最大回撤为百分
比，Sharpe小数。定义清晰避免歧义。
回测报告文件带版本号或日期戳，以区别不同版本策略/数据跑出的报告。例如
report_strategy123_v2_run20251201.pdf 表示策略123第2版在2025-12-01跑的报告。
数据库Schema版本管理 ：对于数据库表结构本身的演变，建议采用显式的版本管理：
在PostgreSQL建立 迁移脚本管理 （如Flyway或Alembic等）来跟踪每次表结构变更。把每次DDL操作记录
在ADR或专门的数据库变更日志，以确保团队对字段意义变化达成共识。
通过ADR记录重要数据结构决策，如切换因子库存储方案（分库或分表）等，详细说明理由和影响，方便后
来者理解 。
通过这些字段规范和版本控制措施，数据的含义和来源在系统生命周期内都清晰可追踪。当模型升级、指标变动或
数据源切换时，能够通过版本信息回溯旧数据的产生过程，保证 历史可比性 和结果解释力 。
4.3 数据来源构建高质量知识库
保证系统决策的可靠性，关键在于高质量的数据和知识来源构建：
数据源选型 ：综合使用多数据源以校验和补充：
JQData ：已集成，为A股提供专业行情和财务数据 。继续利用其全面准确的日线、财务指标，同时密切
关注其更新频率，确保每天数据及时入库。JQData由JoinQuant团队开发，专注提供本地量化数据服务，数
据质量高且覆盖全面 。可将JQData做为主要数据源。
AKShare/同花顺数据 ：AKShare作为免费开源数据接口，可补充JQData没有的部分如新闻舆情、期货宏观
数据等。同花顺行情可通过API或爬虫获取作为实时行情备份。为降低依赖，可引入 Tushare 等免费接口获
取部分数据，但注意频次限制和数据准确性（Tushare Pro虽覆盖广但需积分调取） 。推荐关键数据以
付费源为准，免费源做 交叉验证 用途，例如每日对比收盘价涨跌幅，发现异常及时报警。• 
• 
• 
• 
• 
• 
• 
• 
• 
• 
• 
• 
• 
• 
• 
49 50
• 
• 51
51
• 
52
9

=== 第10页 ===
数据刷新策略 ：建立每日数据更新流程，如交易日结束后调用Data Source MCP批量拉取当日增量数据入
库。使用任务调度确保重要数据（行情、指标）先更新，再触发后续分析流程 。对低频数据（财报、宏
观）定期更新，节省资源。
网络爬虫策略（Data Collector） ：充分发挥Data Collector MCP的功能，构建本地 研究知识库 ：
财经资讯抓取 ：定向爬取权威财经新闻、政策公告、研报摘要等，填充到知识库。可针对每日收盘后抓取当
日重要财经新闻标题及内容摘要，存入Engineering KB或单独的News KB，供市场情绪分析参考。利用
Data Collector的 crawl_web 和download_pdf 工具，设定目标站点（如证监会公告、券商研报发布网
站）定期爬取 。存储PDF研报至MinIO，解析文本存MongoDB并索引到向量库，方便LLM查询。
代码库分析 ：Data Collector的源码分析能力可用于集成外部量化代码库（如GitHub上一些因子库项目）的
精华部分到知识库 。通过分析他人的开源策略、因子代码，萃取出有用的方法论记录在Strategy KB中。
这相当于知识库的数据增强，帮助AI提供更丰富的策略建议。
多角度验证 ：利用Data Collector的自动化测试和验证功能 。例如在实现某新算法前，让其收集相关学
术论文（ data_collector.collect_academic ）并摘要关键结论；在改进模型参数时，自动测试不
同数据样本以验证稳健性。这种 先研究后实现 的方法论将有效降低盲目尝试的风险。
本地研究资料组织 ：量化研究过程中会产生大量文档、笔记，需要系统化管理：
文件命名规范 ：制定研究笔记、策略报告的命名规则，例如 研究_主题_日期.md 或StrategyIdea_因子
择时_20251201.md ，保证文件名自带说明和时间。对于数据文件，包含数据集名称和日期范围，如 因子
矩阵_2020-2025.parquet 。
层次化文件夹 ：在项目工作区内设置 research/ 主目录，下设 notes/（研究笔记）、 datasets/
（原始数据集）、 results/ （分析结果图表）、 papers/ （参考论文）等子目录。这样不同类型资料
分门别类，易于查找。例如研报PDF存放在 papers/2025/ 下按来源/日期归档。
标签分类 ：对研究文档引入标签元数据（可在笔记开头注明，例如 Tags: 因子挖掘, 机器学习 ），并建
立一个简单的索引文件或用MongoDB存储文档元信息（标题、日期、标签、摘要）。这样AI助手或工程师
可按标签快速过滤相关资料，提升知识复用效率。
知识库构建 ：将以上整理的本地资料定期通过KB MCP进行索引 。例如每周自动将 notes/中新文档嵌
入到Manual KB向量空间，方便LLM检索引用。对关键研究结论，在Engineering KB中以问答对形式存储，
从而在对话中AI能基于这些已验证结论回答问题。这种人工+自动的知识累积，能逐渐提升系统智能决策水
平。
通过多源数据获取和完善的知识资料库，TRQuant系统将拥有坚实的数据地基和丰富的背景知识。一方面，多源交
叉验证保证数据质量高、一致性好；另一方面，内部知识库让AI具备事实依据，结合先进提示技术可显著减少幻
觉，提高回答可信度。
5. 补充优秀的软件工程原则与流程规范
5.1 架构设计原则
清晰边界 ：遵循面向服务和模块化的设计，确保各子系统边界明确，内部高内聚、外部低耦合。通过七层架
构将展示层、AI代理、编排工具链、核心业务、数据存储、执行层解耦 。模块间交互只通过公开接口
（如TRQuantAPIBase） 或MCP协议，杜绝跨层直接访问。这保障了团队可并行开发，某层实现更换不
影响其它层（例如更换数据库或前端技术时，API接口保持不变）。
接口契约 ：为模块交互定义明确的契约，包括输入输出数据格式、调用约定和性能指标。使用JSON Schema
或类型注解规范接口数据结构，在集成测试中验证契约符合。如Data Source API承诺每次返回完整数据
集，Trading接口承诺交易指令同步返回状态。遇到接口需求变更，通过版本号管理（如REST接口版本v1/
v2）避免破坏旧约定。接口契约也意味着模块责任明确，调用方不需关心内部实现，只按契约使用即可。• 
40
• 
• 
21
• 
53
• 53
• 
• 
• 
• 
• 20
• 
54
12
• 
10

=== 第11页 ===
开放封闭 ：系统设计满足开放-封闭原则，对扩展开放、对修改封闭。当需要支持新功能或资产类型时，优先
通过新增模块或扩展接口实现，而非修改大量已有代码。例如新增一类因子分析，应该通过增加Factor
Server的工具方法或新增MCP插件实现，而非改写原有逻辑。这可以通过 策略模式和插件架构 实现：很多功
能点预留挂接扩展点，使未来新特性以插件形式接入，不破坏主框架稳定性。
5.2 模块化拆分建议
核心逻辑 vs 工具调度 ：将业务核心算法（如因子计算、回测逻辑）与AI工具调度流程分离。核心逻辑代码
专注于正确、高效地实现业务功能；工具调度由AI Agent层和Workflow层处理 。例如，回测引擎是独立
模块，只接受回测参数运行并输出结果，不直接涉及LLM；LLM代理负责基于对话决定何时调用回测引擎。
这种分离保证核心算法可以独立测试优化，而AI交互逻辑也能独立演进。
资源存储 vs 业务计算 ：数据存储访问代码与业务计算解耦。采用 仓库模式 （Repository Pattern）为数据库
访问提供抽象接口，例如StrategyRepository封装所有策略存取操作，内部调用PostgreSQL。业务层调用
仓库接口，不直接拼接SQL或文件路径。这样如果底层存储换成别的数据库，只需改仓库实现不影响业务
层。与此同时，缓存机制也可在仓库层统一处理（如查询结果缓存到Redis），对上层透明 。
UI展示 vs 后端服务 ：前端只通过API或MCP获取数据和触发任务，不 embed 业务逻辑。以目前架构，GUI
通过TRQuantAPIBase和Cursor扩展访问MCP工具 。保持这一原则，前端不直接读写数据库或文件。这
确保了 单一职责 ：前端负责交互体验，后端保证业务正确。未来如推出Web前端，同样调用后端接口即可，
共享一套核心服务。
横切关注模块 ：将日志、错误处理、安全检查等横切关注点模块化。借鉴AOP思想，在关键流程插入这些功
能。例如Evidence记录可以封装为一个decorator或者在MCP基类中实现，在每次工具执行前后自动记录
trace_id和参数结果 。安全写入协议作为所有写操作的装饰流程，任何模块写数据库前都经过dry_run确
认等 。通过框架层统一处理横切逻辑，避免分散在各处冗余代码，提高一致性。
5.3 CI/CD流程建议
安全写入协议 ：在开发和CI中落实“dry_run→确认→执行”的安全写入机制 。例如提交数据库变更的代
码，在CI环境下先连测试库dry_run输出变更SQL，人工或自动审查通过后才执行到正式库。对于代码合
并，先在预生产环境模拟执行重要任务，产出artifact给团队审核，再正式发布。借助CI流水线将这种步骤自
动化，确保 关键改动零意外 。
持续集成 ：设置Git仓库的hooks和流水线：
提交前本地运行 Lint和单元测试 （可用pre-commit钩子调用Lint MCP和Test MCP） ；或者在Git服务器
上用CI服务（如GitHub Actions）每次PR触发这些检查。只有Lint/测试通过的PR才允许合并主分支。
集成 语义化提交检查 ，利用lint工具确保commit message符合约定格式（feat/fix/docs等），并包含
trace_id或任务编号，方便追踪 。
配置 代码审查流程 ：至少一名其他开发者review通过才能merge，重要模块需两人审查。Code MCP可协助
分析变更影响，审查人重点关注接口契约和安全性。
持续交付 ：采用容器化和自动部署策略：
使用Docker编排各服务的部署环境，在CI中构建镜像。利用docker-compose或Kubernetes，将MCP微服
务、数据库实例等配置在一起，版本升级时CI自动构建新版镜像并推送registry。
部署流程脚本化：CI根据不同分支进行部署，例如 main分支push触发部署到测试服务器，运行集成测试
用例（通过Test MCP或真实交易模拟），通过后再由运维手动触发部署到生产。这种 分阶段部署 降低风险，
确保新版本平稳上线。
设置 自动回滚 机制：如监控到新版本服务异常频繁、指标下降，通过部署脚本快速切换回旧版本容器。并结
合Evidence日志分析问题原因，形成事故报告。
监控与反馈 ：CI/CD不止于部署，还应监控运行状态并反馈给开发：• 
• 
55
• 
42
• 
12
• 
2
47
• 47
• 
• 56
• 
57
• 
• 
• 
• 
• 
• 
11

=== 第12页 ===
部署的应用应集成健康检查和性能指标上报（比如Prometheus监控每个MCP的请求量、延时、错误率）。
CI可结合这些数据判断部署质量。
用户反馈通道畅通，例如前端有崩溃日志上传机制或埋点统计，将线上问题及时汇总。定期review这些反馈
以改进测试用例，真正实现 持续改进 。
5.4 架构决策记录（ADR）建议
ADR制度 ：推行架构决策记录，用以记录重要技术决策的背景和取舍 。团队应养成遇到架构性议题时撰
写ADR的习惯，哪怕是单人项目，这有助于日后回顾。将ADR与代码库一起管理（如放在 docs/adrs/ 目
录，使用Markdown格式），每个文件描述一项决策。
模板与内容 ：采用业界推荐的模板 ：
标题 ：简要描述决策点并编号（如“ADR-0001 使用TimescaleDB存储因子数据”）。
状态 ：比如提议/已采纳/已弃用等。
背景(上下文) ：决策所处的业务技术背景，问题陈述，相关约束 。
决策细节 ：选择了什么方案，以及 理由 。对比可选方案X、Y的优缺点，解释为什么选定方案Z 。
影响(后果) ：预期带来的积极影响和可能的负面影响 。包括对系统的短期长期影响，如性能提升多少，
增加了哪些复杂度。
决策者 ：参与决策的人。
日期 ：决定日期。
后续事项 ：如果有，需要做的配套工作或观察指标。
使用ADR MCP ：利用已实现的ADR MCP Server 来管理这些记录。可以通过命令如 adr.create 、
adr.query 来增查ADR。建议为ADR选择一个易读的存储，如纯Markdown文件，ADR Server 充当索引
和检索工具，使开发者可以按时间、主题快速查阅 。例如在Cursor里输入查询，上下文窗口能调出相关
ADR内容帮助回忆决策依据。
决策流程 ：当面临重大架构更改（如更换消息队列、增加新微服务）时，先在团队内部以issue或会议形式
讨论，记录多方观点，然后由主要负责人拟写ADR草稿，征求团队意见，达成一致后标记为Accepted并归
档。后续如果决策被推翻或调整，则新写一个ADR，状态标注“Supersedes #001”等来链上前任决策 。
保持旧ADR不改，只附状态，这样历史轨迹完整透明。
模板应用示例 ：例如要决定“是用Next.js重构前端还是继续PyQt”，就写一份ADR。背景：当前PyQt存在的
问题，团队技能情况；选项：继续PyQt、Next.js+Electron、Qt QML等，各自利弊；决策：选择
Next.js+Tauri，并说明因为Web生态丰富、可移植性更好；后果：需要团队学React/Rust，初期效率下降，
可接受。
定期回顾 ：每季度组织团队回顾一次ADR，把最近的决策在实践中效果如何进行评估。如果发现偏差，可能
需要新的ADR进行修正。通过这种机制，ADR不只是文件，更成为 持续设计对话 的一部分，促使团队时刻反
思设计、优化架构。
采用ADR文化可以使架构决策有据可查，新成员加入能快速了解前因后果，提高沟通效率 。也避免了决策被遗
忘或一人更改他人不知的情况，增强团队协作和对系统演进的掌控。
6. 持续优化建议：按功能模块与开发阶段
下面根据上传文档提出的功能模块划分和开发阶段计划，逐条给出针对性的优化与实现建议，以确保各项工作顺利
推进并保持系统演进的开放性。• 
• 
• 58
• 49
• 
• 
• 50
• 58
• 50
• 
• 
• 
• 31
59
• 
60
• 
• 
61
12

=== 第13页 ===
6.1 核心功能模块优化（高优先级）
回测系统增强 ：
性能优化 ：对BulletTrade集成部分进行 性能剖析 ，找出瓶颈 。可能优化方向包括：减少Python与C++接
口调用开销、批量处理交易指令、启用多线程或多进程并行回测（将不同策略或不同时间段的回测任务分配
到多核） 。利用向量化计算提升回测运算速度，如用NumPy/Pandas对账户盈亏曲线批量更新而非循
环。实施结果建议通过基准测试验证（同一策略对比优化前后速度）。
并行回测支持 ：实现回测任务并发执行 。可以在Backtest MCP中引入 线程池或任务队列 ，允许同时运行
多个回测实例（例如设置线程池大小=可用CPU数）。确保线程之间隔离各自的数据（如拷贝一份初始市场
数据），防止竞态。同时提供全局控制参数，限制最大并发数，避免资源争抢导致性能下降或内存不足。
结果缓存 ：对相同配置的回测任务建立缓存机制 。例如使用哈希计算任务参数（策略ID+数据区间+参
数），在提交任务时先查缓存（Redis或本地文件）是否已有结果，命中则直接读取结果返回，避免重复计
算 。缓存结果需与策略版本和数据版本挂钩，一旦策略代码或数据有更新，要自动失效相关缓存，保证
结果新鲜准确。
回测分析增强 ：扩充回测报告内容，提高诊断能力 。加入更多风险指标（如Calmar比率、Omega比率
等）和分项统计（如按月份的收益分布，持股周期分析）。对于业绩不佳的策略，在分析报告中生成 诊断建
议：例如“某因子在近半年失效”“换手率过高导致手续费侵蚀收益”等，由AI根据指标异常之处给出结论提示
。这些建议可以基于预设规则或训练AI模型生成，帮助用户快速定位问题。
策略系统完善 ：
策略优化器 ：实现多种参数优化算法，提高策略参数调优效率 。可集成现有优化库（如Hyperopt、
Nevergrad）来支持 网格搜索、贝叶斯优化 等。对遗传算法等复杂优化，可以异步运行并结合多线程提升速
度。UI上提供优化配置界面，让用户选择优化算法、设置代数/粒子群等参数。优化过程实时输出当前最佳
结果和收敛趋势曲线，增强可视化效果 。支持多目标优化时，引入 帕累托前沿 概念，输出一组均衡解集
合供选择。
策略回测集成 ：将策略生成与回测无缝衔接 。当AI生成策略代码后，系统可自动触发一次回测并获取结
果，从而实现 生成-验证闭环 。这需要在 trquant_generate_strategy 调用结束时，由Workflow检测
新策略文件已创建，然后直接调用Backtest MCP跑最近一年的测试。UI上可以在策略生成结果弹窗里直接
显示回测主要指标，提供快速反馈 。若结果不理想，可提示用户调整因子或参数再生成。这样的集成提
高用户迭代速度，降低手工操作成本。
策略组合优化 ：对于多策略组合（如不同策略分配资金比），提供优化支持。可通过Strategy Optimizer
MCP对策略组合进行 权重优化 ：比如目标最大化夏普率，约束组合波动率，求解各策略资金配比。采用遗传
算法或简单x%步长枚举，找出最佳组合并输出建议权重和预期表现 。此功能帮助用户构建投资组合，而
非单策略孤军奋战。
执行系统增强 ：
实盘交易监控 ：搭建实时监控面板，追踪实盘账户状态和交易情况 。具体包括：账户净值曲线实时刷
新、持仓列表自动更新、当日盈亏显示、交易日志流。对接券商API，定期pull最新持仓和资金更新入缓存
（Redis），前端每几秒刷新显示 。当发现异常（如资金曲线异常波动）时，高亮提示以便用户注意。 
异常处理机制 ：加强交易过程的容错，保证稳定性 。实现 重试与降级 策略：下单失败时自动重试N次，
若持续失败则切换到备用通道（如另一券商接口）或记录报警。对网络断连等异常，Trading MCP应能检测
并及时通知用户，通过UI弹窗或系统通知提示人工介入。所有异常情况进入 风控事件表 ，供日后审计和
改进。
风控系统 ：在实盘执行环节前置风险控制检查 。建立一套可配置的风控规则，如单笔交易金额不得超总
资产X%、单日损失超Y%自动停止交易等。Trading MCP每次接到下单请求，先调用风控模块校验：若违规
则拒绝下单并给出原因（如“超出单笔持仓上限”）。另外，实现 止损止盈 ：由一个独立监控线程或服务监视
市场价格，一旦达到策略设定的止盈/止损线，自动发出平仓指令并通知用户。这可以集成在Trading MCP1. 
2. 62
37
3. 37
4. 37
63
5. 63
38
6. 
7. 64
65
8. 66
66
9. 
67
10. 
11. 68
68
12. 69
70
13. 70
13

=== 第14页 ===
或者作为独立的Risk MCP服务。仓位管理方面，提供 仓位控制接口 ，策略在下单前查询当前持仓和资金占用
情况，确保新单不会造成超仓或爆仓。
交易日志完善 ：交易服务器详细记录每个指令的生命周期：由哪个策略发起，何时发送给券商，券商响应什
么（订单号/错误），最终成交情况 。这些日志发送给Evidence Server永久保存，必要时可以对账或者
复盘当时决策。建议提供 日志检索工具 ，按日期、策略或股票筛选日志，方便排查交易问题。
6.2 系统集成优化（中优先级）
工作流编排完善 ：
状态持久化 ：给Workflow Orchestrator增加 状态持久化存储 ，比如将每个工作流实例的当前步骤、上下文
结果写入数据库或本地JSON 。可使用 workflow_state 表或文件，结构包括：workflow_id，当
前step，step状态（进行中/成功/失败），输出摘要，时间戳等。这样在服务重启或崩溃后，可从上次状态
恢复继续执行未完成步骤，避免整个流程中断 。
错误恢复机制 ：定义Workflow在某一步失败时的恢复策略 。例如配置重试次数上限，超过则标记该工作
流失败，但允许用户在UI上选择 重新运行失败步骤 或跳过该步骤继续 。对于可跳过的非关键步骤（比如报告
生成失败，可以不影响后续部署策略），Workflow引擎应能继续执行余下部分 。通过记录每步依赖关
系，当某步失败且被跳过时，及时通知依赖它的后续步骤（若有）使用默认值或终止。
工作流可视化 ：在前端提供工作流监控界面 。可以将8步流程及附加步骤绘制成流程图或进度条形式，
当前进行到哪一步一目了然。每步的状态（等待/执行中/成功/失败）用不同颜色标识 。点击某一步可展
开查看输入输出概要及日志。如果某步出错，在界面突出显示错误信息并提供操作按钮（重试/忽略）。这
种可视化提升用户对AI自动流程的信任度，并便于人工干预纠错 。
自定义工作流 ：支持用户定义自己的流程模板。提供简单DSL或通过UI拖拽配置流程的工具，允许高级用户
组合现有MCP工具形成新流程。Workflow MCP执行时读取用户定义的模板（JSON/YAML格式），按顺序调
用工具。这使系统更开放，用户可扩展流程以满足个性化需求。
AI集成增强 ：
智能决策支持 ：升级AI Agent（轩辕剑灵）的决策策略，使其更“聪明” 。引入 多模态或多模型 支持
：根据任务类型选择最合适的模型，比如代码生成用专门fine-tune的模型，策略分析用大模型。可利用
openAI GPT-4 for general, CodeX for code, 或引入开源模型如CodeLLM离线部署。通过在Agent Hub中
维护模型路由规则，实现 按上下文智能选型 。
上下文理解增强 ：让AI更好地理解项目结构和进程上下文 。一方面扩充提示模板，包括当前项目概要
（模块划分、已完成工作摘要）、当前对话历史重要信息，让AI决策时有 全局视野 。另一方面，利用
Engineering KB和Manual KB提供开发相关知识 。AI在生成代码或方案前，自动查询相关知识条目，确
保建议与项目规范一致。例如在建议数据库方案前查询工程KB的数据库章节，避免不符合当前架构的方案。
工具调用优化 ：AI Agent在决定调用哪个MCP时，可引入 决策树或规则 以减少不必要的尝试。例如先根据用
户请求意图分类：数据查询类优先KB或Data Source工具，代码改动类优先Spec/Lint工具验证。这可通过
few-shot训练或规则引擎实现，使Agent选择工具更准确，不会走弯路。同时对复杂任务，考虑采用 Plan-
Execute 模式：先让AI生成一个步骤计划，再逐步执行，每步检查结果正确性，没有达到预期则回滚计划重
试 。
多模型协作 ：探索 多代理协作 ，降低单一LLM错误概率 。例如引入一个Verifier代理模型，专门复核主代
理给出的方案或代码。主代理完成任务后，由Verifier根据知识库和规则检查结果合理性，如发现问题可让
主代理修正。这种类似Chain-of-Thought + self-check的流程，虽然增加开销，但在关键任务上可显著提高
可靠性。
数据质量监控 ：
实时数据检查 ：建立针对每日数据更新的质量监控流程 。例如，当Data Source MCP完成行情更新后，
触发Data Quality MCP对当日数据运行检查：包括缺失值检测（是否所有交易日资产都有报价）、极端值检
测（涨跌幅超过限制，可能停牌处理问题）、一致性检查（前后日数据连续性，除权除息校验）。一旦发现14. 
71
1. 
2. 
40 72
73 41
3. 73
41
4. 40
73
74
5. 
6. 
7. 75
76
75
8. 77
20
9. 
7
10. 3
11. 
12. 78
14

=== 第15页 ===
异常，立即记录事件并通知开发者 。可通过邮件/微信等发送告警，如“某股票今日数据缺失，已用前日
数据填充”。
异常值处理机制 ：Data Quality MCP在检测到异常数据时，尝试自动修复 。例如对缺失的行情，通过调
用备用数据源补全；检测到成交量为0但价格大幅波动，标记该数据点为异常，在因子计算时予以忽略。对
于无法自动修复的，比如数据源全部缺失，则报告人工干预。所有修复和忽略动作要记录在案（数据质量报
告），以供日后审计 。
数据质量报告 ：定期生成数据质量月报 。统计各类数据问题发生频率，列出主要异常案例和修复情况。
这些报告有助于评估数据源可靠性，如发现某免费源频繁出错可考虑更换。报告也可用于向管理层证明系统
数据可靠性指标，提高对系统信心。
完善数据测试 ：在CI中加入针对数据的测试用例。例如每日收盘后触发一组数据有效性测试（验证新增行情
与昨日衔接正确，数据库索引正常工作等），这些测试结果进入CI报告，如有失败让开发立即处理，防止错
误数据流入模型环节。
6.3 MCP服务器完善（中优先级）
MCP服务器优化 ：
响应速度优化 ：分析各MCP的平均响应时间，针对较慢的进行优化 。常见措施：引入 异步IO 处理I/O密
集型任务（如KB查询可异步，爬虫用异步HTTP库）；热点数据加缓存（如最近一次主线扫描结果暂存内
存，重复查询直接返回）；调整服务器进程数配置（如Gunicorn worker数量）以充分利用多核。尤其注意
KB、Data Collector等经常等待I/O的服务，通过async提升并发度，避免阻塞。
资源使用优化 ：监控每个MCP的CPU、内存占用峰值，合理分配容器资源限额，防止某服务异常占用过多资
源影响整体 。例如Backtest和Optimizer可分配更高CPU/内存配额，而Lint等轻量服务限额小一些。对
于长期驻留内存的数据，如知识库向量索引，可定期重启服务以释放碎片内存，或者采用内存映射技术加
载，减小内存足迹。
工具参数验证增强 ：确保每个MCP对输入参数都有严格校验 。一方面使用JSON Schema定义参数类型范
围 ，另一方面在代码实现里检查业务逻辑合理性（例如回测开始日期不能晚于结束日期）。对不合法输
入立即返回带明确错误码的响应，避免深入执行浪费资源 。
错误处理完善 ：统一MCP的错误码字典，提供更详细的错误信息 。每个MCP遇到异常时，不仅返回错误
码，还应日志记录堆栈并将错误上下文发给Evidence Server。定期汇总这些错误日志，看是否有模式可
循，以进一步改进稳定性。
工具文档完善 ：为每个MCP服务生成使用文档，列出可用方法、参数说明和示例 。可以通过Docs MCP
或Manual Generator MCP自动从代码注释提取文档 。确保在在线手册或命令帮助中，用户能方便查询
每个工具的用法和注意事项，降低使用误操作风险。
新MCP服务器开发 ：
项目管理 MCP ：用于管理策略项目的生命周期 。功能包括项目创建（生成目录结构和配置文件）、项目
配置修改（修改 .trquant/project.json 集中管理项目元信息 ）、项目进度查询等。通过该
MCP，前端可实现“一键新建策略项目”向导，自动在代码库和数据库注册新项目。项目配置变更（如添加/移
除策略、修改参数）也通过该服务确保变更原子性、记录版本。建议将其与Strategy管理功能结合，实现 项
目-策略-数据 的一体化管理。
监控 MCP ：提供系统运行监控工具集 。可以封装对服务器状态、资源占用、日志的查询。比如
monitor.health 返回各MCP最近心跳、CPU/RAM占用、任务排队数； monitor.logs 按模块筛选最
近N条日志； monitor.metrics 返回近期关键性能指标（如平均响应时间）。实现上，可读取
Prometheus或系统API数据，然后统一由MCP提供查询界面。前端据此绘制 系统监控仪表板 ，实现基本运
维功能。长远看可扩展连接告警模块（如发生错误率突增自动通知）。79
13. 80
22
14. 22
15. 
1. 
2. 81
3. 
82
4. 83
1
83
5. 83
6. 83
84
7. 
8. 85
86
9. 87
15

=== 第16页 ===
（可选）通知 MCP ：考虑实现一个推送通知服务，用于统一发送系统消息（如任务完成通知、异常警报）。
这可集成到监控MCP或单独服务。提供方法如 notify.send(user, message, level) ，内部可对接
邮件或微信API发送通知。这样重要事件都能及时触达相关人员。
开发要点 ：开发新MCP时，遵循既有MCP规范，包括JSON-RPC接口、参数Schema和trace_id追踪 。确
保与Task/Evidence等已有服务集成良好（如项目创建成功在Evidence记录，监控指标按统一格式产出）。
同时，新服务的权限控制也需考虑，尤其监控和通知涉及全局系统信息，需限制只有管理员角色能使用，以
保证安全。
6.4 数据库实施与数据迁移（中优先级）
数据库部署 :
PostgreSQL部署 ：准备生产级PostgreSQL实例 。建议使用Docker容器部署，并开启持久化卷存储数
据。初始化时运行前述表结构SQL脚本，建立所有必要Schema和表 。重点配置调整：根据数据量和并
发，调高 shared_buffers 等内存参数；启用 wal_level=logical 以备将来需要流复制。创建只读用
户用于应用查询、写入用户用于应用写操作，实现基本的权限隔离。 索引优化 方面，对常用查询字段创建索
引，如策略ID、日期字段等 。并采用分区表技巧：如交易日志按日期分区，每月一个子表，提高查询性
能 。
时序库部署 ：决定使用ClickHouse还是TimescaleDB 。若采用ClickHouse，部署单节点或小集群（因为
数据量初期可能不巨大，可先单机）。配置合适的MergeTree分区策略，比如按月份分区OHLCV表，便于
批量删除旧数据 。如果选Timescale（PostgreSQL扩展），可直接在已有PG上安装扩展，但为减轻主库
压力，也可独立PostgreSQL实例运行Timescale。无论哪种，都要预设因子数据、行情数据等表结构及分区
策略 。测试一些典型查询（如取某股票一年价格，算全市场某日横截面因子），观察性能。调整索引如
ClickHouse增加skip index或Timescale加哈希索引，以优化这些查询速度。
对象存储部署 ：搭建MinIO服务用于artifact和文档存储 。MinIO可通过Docker运行，配置为单节点（如
无海量文件需求）即可。设置bucket策略：创建 reports 桶存回测报告、 research 桶存研报文档等，
每个桶配置生命周期规则如定期归档或压缩历史版本 。访问控制方面，为系统组件生成访问密钥对，配
置在Secrets MCP中统一管理，避免密钥散落代码 。应用访问MinIO时通过Secrets服务获取密钥，提高
安全性。
Redis部署 ：Redis用于缓存和队列，建议高可用（启用AOF持久化或主从）。设置任务队列键空间和TTL策
略如回测任务过期时间等 。对于缓存数据如行情快照，可设置短TTL自动清理 。确保Redis配置
notify-keyspace-events 开启必要的事件，以支持Pub/Sub用在任务完成通知等场景。
Chroma向量库部署 ：Chroma可以用Docker方式启动，也可考虑使用云服务。导入Manual KB和
Engineering KB向量 。验证向量检索效果与速度，必要时调整embedding模型或检索参数。由于向量
库涉及AI助手回答准确性，部署后应测试若干知识问答确保检索匹配率达标。
MongoDB部署 ：如果研究文档量大，可部署MongoDB单节点用于存储文档 。根据现有文档量17GB考
虑MongoDB配置Storage Engine为wiredTiger并调大缓存。初始化时建索引如 tags、title字段索
引，方便Engineering KB中文档检索。
数据迁移 :
历史数据迁移 ：将现有数据导入新架构 。分步骤进行：
行情数据 ：如果之前通过JQData API实时获取，没有本地历史，需要一次性批量下载全市场历史行
情到新库。例如调用JQData接口分批获取过去N年的日线数据，写入ClickHouse。可写脚本按交易
日循环获取每日全市场数据写入，或按股票逐个拉取历史。注意控制速率防超额。若已有部分历史数
据文件，可直接CSV/Parquet导入ClickHouse（通过ClickHouse INSERT ... VALUES 或使用其
HTTP接口批量导入），验证数据完整性后与当日行情接轨。
因子数据 ：如已有因子计算结果存于文件（Excel/CSV），需要导入新时序库。编写转换脚本将各因
子文件读取为统一格式，再批量写入 factor_data 表 。若因子量很大，一种做法是按因子拆10. 
11. 1
1. 
2. 88
89
89
90
3. 91
92
91
4. 93
94
22
5. 
42 95
6. 
20
7. 96
8. 
9. 97
1. 
2. 
98
16

=== 第17页 ===
分并行导入（每个因子启动一个进程），或用ClickHouse的批量CSV导入工具提升速度。导入后，抽
样核对几只股票的因子值与原文件是否一致，以免出错。
回测数据 ：过去的回测结果如果有保存，需要迁移。例如原有回测报告、交易日志等。把报告文件上
传MinIO对应桶，并在PostgreSQL backtest_task 表插入对应记录（可能只插入summary指
标，或保留回测ID映射）。如果原来没有结构化保存回测结果，这一步也可跳过，由于回测可以重
新跑得到。
迁移验证 ：每完成一类数据迁移，都应进行 核对 。如行情数据可对比同花顺等平台价格，确保无误；因子数
据可用因子评估工具计算一次IC，与你之前结果比较；迁移的报告文件随机打开检查内容。迁移过程建议生
成日志记录每批次多少条，错误多少条，方便追踪。
数据版本衔接 ：注意在切换到新数据库过程中，保持数据连续。例如如果切换日为2025-12-01，在此日期之
前用历史数据，新架构从12-01开始接管实时更新。可以考虑 双跑 一段时间：即新库上也跑近期数据对比旧
流程结果，确保吻合再完全迁移。最终确认切换后，在ADR中记录“数据库架构切换决策”，列明切换点和旧
数据保留方式，做到有据可查。
性能测试 ：迁移完成后，针对关键查询进行性能基准测试，确认满足要求 。比如测试全市场某因子截面
计算速度、回测数据汇总速度。如果发现慢，可能索引欠佳或设计问题，及时优化表结构或索引。例如因子
表如经常查特定因子某段时间，可以加 (factor_name, date) 复合索引或按因子分区。
6.5 用户体验优化（中优先级）
GUI系统 ：
界面优化 ：提升8步骤工作流的可视化呈现 。在主界面增加 工作流进度看板 ，以流程图或进度条显示当
前所处环节和全部步骤概览，让用户对流程一目了然 。可使用Qt的 QGraphicsView 绘制流程节点，
也可简单用一组图标+文字高亮当前步骤。
实时数据展示 ：丰富界面实时报价和分析图表 。例如在市场趋势页面嵌入一块指数实时行情区域，调用
Data Source订阅实时指数数据，每隔几秒刷新显示涨跌幅。候选池页面显示股票列表时，可附实时价格
（或至少收盘价），用颜色标注涨跌。这样GUI不仅提供静态分析结果，还具备 交易终端 的部分实时功能，
提高实用性。
交互体验优化 ：关注用户操作流程的流畅度 。减少不必要的弹窗和阻塞操作，例如在运行工作流时，界
面允许浏览已完成步骤的结果，不强制等待所有完成。提供“中止流程”按钮，用户可随时停止AI执行。对于
需要确认的操作（如真实下单），使用显眼的对话框并要求二次确认（比如输入“CONFIRM”文本），防止误
触。整体UI风格上，采用一致的配色和元素排版，提升专业感和一致性（可以参考主流券商交易软件的设
计）。
多屏幕支持 ：确保应用在不同分辨率下正常显示。如果可能，提供 窗口拆分/弹出 功能，比如将回测报告以
新窗口打开，方便多屏查看详细报告同时继续主界面操作。
Cursor扩展功能完善 :
项目创建向导 ：在IDE中实现“一键新建量化项目”命令 。调用项目管理MCP，弹出输入项目名称、选择
策略模板的对话框，确认后自动生成项目结构和初始代码。这样用户在IDE里迅速开始一个新策略开发，无
需手工复制文件。
代码编辑器集成 ：Cursor扩展可以更深度结合IDE的编辑功能 。例如，当AI生成策略代码后，自动在编
辑器中打开该文件并跳转到关键部分，让用户审阅或修改。支持从对话里点击文件路径直接打开编辑。实现
代码-对话联动 ：选中代码片段，在对话中询问AI解释或优化此段代码，由扩展捕获选中文本作为上下文发给
AI，增强开发体验。
本地回测引擎 ：在Cursor扩展中加入 快速回测 按钮 。用户无需切换到GUI或命令行，只需在IDE里点一
下，系统就调用Backtest MCP对当前策略运行回测，结果以简报形式展示在对话窗口（例如返回年化收益/
夏普/回撤）。这样开发-测试闭环更紧凑，策略调整效率提高。可提供选项设置回测参数（时间范围、测试
集）以满足不同调试需求。3. 
10. 
11. 
12. 99
1. 
2. 100
101
3. 101
4. 102
5. 
6. 
7. 103
8. 103
9. 104
17

=== 第18页 ===
提示与补全 ：利用IDE能力，提供MCP指令和策略API的智能补全。例如在对话输入 /mcp 
trquant_mainlines 时，扩展弹出参数模板，让用户填选周期等，然后发送给AI执行，减少记忆负担。
对于策略代码，结合Language Server提供策略类、函数的自动补全和文档提示，使开发更加顺滑。
文档系统 :
使用案例补充 ：在在线手册和帮助文档中增加 典型使用案例 章节 。例如“如何开发一个动量策略”一步步
教程，从数据获取->因子选择->策略生成->回测->实盘流程，全程截图或代码示例。这些案例能帮助新用户
快速上手并理解系统各部分衔接。也可提供特定功能场景的案例，如“如何调优因子参数”、“如何诊断策略失
效”等。
最佳实践文档 ：整理量化投资和软件使用的最佳实践指南 。包括：数据处理注意事项（如幸存者偏差处
理）、策略过拟合防范（训练集/测试集划分方法）、代码规范（如何组织策略代码、命名约定）等 - 最佳实
践文档 ：编写量化研究和系统使用的最佳实践章节 。涵盖数据处理注意事项（如如何处理停牌、剔除幸
存者偏差）、模型防过拟合技巧（交叉验证、滚动回测）、风险管理要点等。通过总结经验教训提供指导，
比如“避免使用未来函数”、“参数不可调太多”等，在手册中给出正反案例分析。这些内容将帮助用户少走弯
路，提升策略开发质量。
故障排查指南 ：整理常见问题及解决方案文档 。例如：“无法登录数据源”、“回测卡住不动”、“策略下单
失败”分别可能由哪些原因引起，如何一步步定位（查看日志、检查网络、验证参数）以及修复办法。对于
每类错误，列出排查清单和应对措施。将该指南集成在在线文档中，并在实际错误发生时，系统可引用其中
条目提示用户（比如报错信息附上FAQ编号）。这样用户遇到问题能迅速自助解决，降低支持成本。
6.6 测试与质量保障（中优先级）
单元测试 ：
测试覆盖 ：为核心模块编写详尽的单元测试用例，力争核心业务代码覆盖率达到80%以上。重点测试模块包
括：因子计算（给定输入输出是否正确）、主线识别（不同输入组合评分是否符合预期）、策略生成（典型
输入能否产出可编译策略）等。使用PyTest框架组织测试，结合fixtures准备模拟数据。利用Test MCP服务
器管理和运行这些测试用例，每次CI自动执行并统计覆盖率。
边界和异常测试 ：针对每个函数的边界条件编写测试，如空数据、极值输入、异常情况，确保代码在各种输
入下都有合理行为（抛出受控异常或返回预期结果）。例如回测模块测试空股票池、交易日为0天的情况，
验证不会崩溃而是提示错误。通过完善的单元测试， 提前发现 潜在bug，防止错误流入生产。
集成测试 :
模块间集成测试 ：模拟关键业务流程的端到端测试。例如编写测试脚本调用完整的8步工作流（可使用
Workflow MCP的测试模式），使用小样本数据检查最终输出是否合理。也可针对某些子流程，如“主线→候
选池→因子→策略→回测”链路，预先准备确定性的输入（比如固定随机种子）跑完流程，验证最终绩效指
标是否符合预期阈值。这类测试保障各模块接口匹配、协同正确。
性能与负载测试 ：在测试环境进行性能基准测试和压力测试。如设计压力测试脚本同时发起多条回测任务，
观察系统队列调度是否正常，结果是否都正确。使用profiling工具监控运行瓶颈，如发现某环节CPU耗尽或
I/O等待严重，则记录在案准备优化。性能测试指标包括：最大支持并发回测数、知识库查询响应时间分布
等，将这些指标纳入发布准出标准，确保每次更新不出现性能回退。
端到端验证 ：在准生产环境做一次全面回归测试：从数据更新开始，到策略生成、回测、模拟下单全流程跑
通。比较输出报告和指标与之前版本无重大差异。这种端到端验证每逢重要版本都应执行，作为质量最终把
关。
代码审查和质量 :
代码审查流程 ：建立严格的Code Review制度。所有核心模块改动需至少一位资深开发者审核，包括检查代
码风格、逻辑正确性和潜在安全问题。审查中借助Lint MCP（自动静态检查） 和Code MCP（调用关系
分析）辅助，重点关注公共接口和算法复杂度。通过Review确保多人知晓重要改动，减少个人失误。10. 
11. 
12. 105
13. 105
105
14. 105
1. 
2. 
3. 
4. 
5. 
6. 
7. 
8. 
9. 
56
18

=== 第19页 ===
静态分析和安全审计 ：定期使用静态分析工具扫描代码（例如SonarQube、Bandit等），查找潜在漏洞
（如SQL注入、弱加密算法）和坏味道。尤其Trading相关模块涉及资金交易，要特别检查对输入输出的信
任边界、防范异常行情或指令注入。Secrets管理模块也需验证无明文日志泄露密钥。对扫描发现的问题，
分类轻重缓急，及时修复或在ADR中记录接受的技术债。
持续质量监控 ：将质量指标纳入CI仪表板，如单元测试覆盖率、Lint违规数、平均Review通过时间等，以量
化质量状况。设定阈值，如覆盖率低于某值时CI失败，lint警告超过X则禁止合并，以制度保障代码质量 逐步
提升 而非滑坡。
6.7 部署与运维（低优先级但必要）
部署方案 :
Docker化 ：制作完整的Docker镜像，将所有核心服务和依赖打包。可采用 微服务多容器 方案：每个MCP服
务器一个容器，数据库各自独立容器，Redis/MinIO等各一容器，通过Docker Compose编排。这样各组件
可独立扩展、重启互不影响。为简化用户部署，也可考虑单容器（将所有MCP进程运行在一个容器内），但
分容器利于维护。构建镜像时使用多阶段构建减小体积，安装必要依赖（如talib等金融库）。编写
docker-compose.yml 定义服务拓扑，一键启动全部组件。
配置与环境 ：利用环境变量管理配置，如数据库连接串、API密钥等，Compose文件中引用 .env文件提供
变量值。这避免硬编码配置在镜像内，方便不同环境部署。对生产环境，开启尽可能多的安全设置，如数据
库只监听内部网络，MinIO设置访问策略等，封闭不必要的端口。
部署文档 ：撰写详细的部署手册。包括：先决条件（Docker版本、内存要求）、如何启动（提供启动脚本或
Compose命令）、如何初始化数据（比如种子一些基础配置，如管理员账号）、常见部署错误及解决。确
保即使非开发人员，按文档也能顺利部署系统运行。
持续部署策略 ：在有条件的情况下，引入CI/CD管道实现自动部署更新。比如Push到 main-clean 稳定分
支触发构建生产镜像并部署到服务器。但前提是充分测试通过以保证稳定。对于紧急修复，可快速打tag构
建补丁镜像发布。这使得系统更新可以 小步快跑 ，而不影响用户使用。
监控与日志 :
系统监控 ：搭建统一监控平台，跟踪各服务健康和资源。可部署Prometheus + Grafana组合：
Prometheus拉取各容器导出的指标（CPU、内存、请求率等），Grafana展示实时曲线并设置告警。对于
MCP应用层指标，可以集成如 Prometheus Python客户端 ，在每个服务提供一个 /metrics 接口输出内
部统计（如任务队列长度、调用次数、错误计数）。这样在Grafana上可以建立 系统仪表板 ，直观查看服务
状态。
性能监控 ：重点监控Backtest等耗资源模块的性能指标。如每次回测耗时多久，内存峰值多少。如果突然升
高，及时告警提示可能出现问题（数据量激增或代码bug）。也监控数据库慢查询日志，设置慢查询阈值报
警，预防SQL性能下降。
集中日志管理 ：将各容器日志集中收集和分类分析。可使用ELK栈（Elasticsearch+Logstash+Kibana）或
轻量的EFK（Fluentd替代Logstash）方案，将容器stdout和应用日志文件采集到Elasticsearch，供搜索和
可视化。设置日志索引按日期滚动，保留近X天日志供排查。Kibana上建立 错误日志面板 ，实时显示新出现
的ERROR/WARN日志，并对特定关键字设置告警。例如交易失败、数据缺失类错误出现时触发通知。这让
运维人员 第一时间发现 潜在问题。
告警机制 ：配置多渠道告警。对于严重事件（服务宕机、交易异常）通过邮件或微信企业号发送紧急通知；
一般性能或错误告警汇总后每日定时报送。定义清晰的告警级别和对应处理流程（谁负责、响应时间），保
证问题出现能及时介入处理。可以借助开源Alertmanager管理告警策略，实现降噪和升级。
备份与恢复 ：建立定期备份策略，虽未在任务清单中特别提及，但属于运维关键。对PostgreSQL设置每日
备份（全量或增量）、MinIO文件可定期同步到备份存储，确保即使出现硬件故障也不致数据丢失。制定灾
难恢复流程，在最坏情况下能够用备份快速重建系统并回放最近日志，将损失降到最低。10. 
11. 
1. 
2. 
3. 
4. 
5. 
6. 
7. 
8. 
9. 
10. 
11. 
19

=== 第20页 ===
通过上述优化建议的逐步实施，TRQuant韬睿量化系统将在工具规范、前后端架构、流程编排、数据管理和工程实
践各方面达到更高水准。不仅提高了系统性能和稳定性，也增强了易用性和可维护性，为量化投资研究的高效开展
提供了坚实可靠的基础。各团队成员应持续协作，遵循这些规范，不断迭代完善，使系统在未来的发展中保持开放
灵活、稳健前行。 
SYSTEM_REVIEW_AND_PLAN.md
file://file_0000000014a8722fbc200b5ef136a258
Stop LLM Hallucinations: Reduce Errors by 60–80%
https://masterofcode.com/blog/hallucinations-in-llms-what-you-need-to-know-before-integration
PyQtGraph - Scientific Graphics and GUI Library for Python
https://www.pyqtgraph.org/
The only 4 real alternatives to Electron | Astrolytics
https://www.astrolytics.io/blog/electron-alternatives
Basics of Architecture Decision Records (ADR) | by Letlhogonolo Mokgosi | Medium
https://medium.com/@nolomokgosi/basics-of-architecture-decision-records-adr-e09e00c636c6
Design and Implementation of Machine Learning Based Multi Factor Quantitative Trading Strategy
https://www.atlantis-press.com/article/125980456.pdf
awesome-quant-cn - Ecosyste.ms
https://awesome.ecosyste.ms/lists/rchardzhu%2Fawesome-quant-cn1 2 5 910 12 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
40 41 42 43 44 45 46 47 48 53 54 55 56 57 59 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76
77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99100 101 102 103 104 105
3 4 6 7 8
11
13 14 15
49 50 58 60 61
51
52
20

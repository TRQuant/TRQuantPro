# æ•°æ®æ”¶é›†å·¥å…·

> æ•´åˆå¼€æºå·¥å…·ï¼Œå®ç°çŸ¥è¯†åº“æ•°æ®è‡ªåŠ¨æ”¶é›†

## ğŸ“¦ å·²æ•´åˆçš„å¼€æºå·¥å…·

### 1. Scrapy - ç½‘é¡µçˆ¬è™«æ¡†æ¶
- **GitHub**: https://github.com/scrapy/scrapy
- **ç”¨é€”**: å¤§è§„æ¨¡ç½‘é¡µçˆ¬å–
- **å®‰è£…**: `pip install scrapy`

### 2. Beautiful Soup - HTMLè§£æ
- **GitHub**: https://github.com/waylan/beautifulsoup4
- **ç”¨é€”**: HTML/XMLè§£æ
- **å®‰è£…**: `pip install beautifulsoup4`

### 3. Playwright - æµè§ˆå™¨è‡ªåŠ¨åŒ–
- **GitHub**: https://github.com/microsoft/playwright
- **ç”¨é€”**: å¤„ç†åŠ¨æ€ç½‘é¡µã€JavaScriptæ¸²æŸ“
- **å®‰è£…**: `pip install playwright && playwright install`

### 4. arXiv API - å­¦æœ¯è®ºæ–‡ä¸‹è½½
- **å®˜æ–¹**: https://arxiv.org/help/api
- **ç”¨é€”**: ä¸‹è½½arXivè®ºæ–‡
- **å®‰è£…**: `pip install arxiv feedparser`

### 5. PyPDF2/pdfplumber - PDFå¤„ç†
- **GitHub**: https://github.com/py-pdf/pypdf2
- **ç”¨é€”**: PDFè§£æå’Œæå–
- **å®‰è£…**: `pip install pypdf2 pdfplumber`

### 6. requests-html - ç®€å•çˆ¬è™«
- **GitHub**: https://github.com/psf/requests-html
- **ç”¨é€”**: ç®€å•ç½‘é¡µçˆ¬å–
- **å®‰è£…**: `pip install requests-html`

## ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# å®‰è£…æ‰€æœ‰ä¾èµ–
pip install -r requirements-collector.txt

# è¿è¡Œç¤ºä¾‹
python tools/data_collector/examples/crawl_example.py
```

## ğŸ“š ä½¿ç”¨ç¤ºä¾‹

### çˆ¬å–ç½‘é¡µ
```python
from tools.data_collector.web_crawler import WebCrawler

crawler = WebCrawler(output_dir="data/collected")
files = crawler.collect("https://example.com")
```

### ä¸‹è½½arXivè®ºæ–‡
```python
from tools.data_collector.academic_scraper import AcademicScraper

scraper = AcademicScraper(output_dir="data/papers")
files = scraper.collect("arxiv", "quantitative+trading", max_results=50)
```


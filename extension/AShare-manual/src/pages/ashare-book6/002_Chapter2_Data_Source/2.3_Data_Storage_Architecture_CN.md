---
title: "2.3 æ•°æ®å­˜å‚¨æ¶æ„"
description: "è¯¦ç»†ä»‹ç»æ•°æ®æºæ¨¡å—çš„åˆ†å±‚/å¤šå­˜å‚¨ï¼ˆPolyglot Persistenceï¼‰æ¶æ„è®¾è®¡ï¼ŒåŒ…æ‹¬PostgreSQLã€ClickHouse/TimescaleDBã€Redisç­‰æŠ€æœ¯é€‰å‹"
lang: "zh-CN"
layout: "/src/layouts/HandbookLayout.astro"
currentBook: "ashare-book6"
updateDate: "2025-12-13"
---

# ğŸ—„ï¸ 2.3 æ•°æ®å­˜å‚¨æ¶æ„

> **æ ¸å¿ƒæ‘˜è¦ï¼š**
> 
> æœ¬èŠ‚è¯¦ç»†ä»‹ç»æ•°æ®æºæ¨¡å—çš„æ•°æ®å­˜å‚¨æ¶æ„ï¼Œé‡‡ç”¨**åˆ†å±‚/å¤šå­˜å‚¨ï¼ˆPolyglot Persistenceï¼‰**æ¶æ„ï¼Œæ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©æœ€é€‚åˆçš„å­˜å‚¨æ–¹æ¡ˆã€‚é€šè¿‡ç†è§£PostgreSQLä¸»åº“ã€ClickHouse/TimescaleDBæ—¶åºåº“ã€Redisç¼“å­˜ç­‰æŠ€æœ¯çš„é€‰å‹ç†ç”±å’Œæ•°æ®åˆ†å¸ƒç­–ç•¥ï¼Œå¸®åŠ©å¼€å‘è€…æŒæ¡æ•°æ®æºæ¨¡å—çš„æ•°æ®å­˜å‚¨æ ¸å¿ƒè®¾è®¡ã€‚

## ğŸ“‹ ç« èŠ‚æ¦‚è§ˆ

<script>
function scrollToSection(sectionId) {
  const element = document.getElementById(sectionId);
  if (element) {
    const headerOffset = 100;
    const elementPosition = element.getBoundingClientRect().top;
    const offsetPosition = elementPosition + window.pageYOffset - headerOffset;
    window.scrollTo({
      top: offsetPosition,
      behavior: 'smooth'
    });
  }
}
</script>

<div class="section-overview">
  <div class="section-item" onclick="scrollToSection('section-2-3-1')">
    <h4>ğŸ¯ 2.3.1 æ¶æ„è®¾è®¡ç†å¿µ</h4>
    <p>åˆ†å±‚/å¤šå­˜å‚¨æ¶æ„çš„æ ¸å¿ƒæ€æƒ³</p>
  </div>
  <div class="section-item" onclick="scrollToSection('section-2-3-2')">
    <h4>ğŸ—„ï¸ 2.3.2 PostgreSQLå­˜å‚¨</h4>
    <p>æ•°æ®æºé…ç½®ã€å…ƒæ•°æ®ã€å®¡è®¡æ—¥å¿—</p>
  </div>
  <div class="section-item" onclick="scrollToSection('section-2-3-3')">
    <h4>â±ï¸ 2.3.3 æ—¶åºåº“å­˜å‚¨</h4>
    <p>è¡Œæƒ…æ•°æ®ã€å› å­æ•°æ®ã€å›æµ‹è¾“å‡º</p>
  </div>
  <div class="section-item" onclick="scrollToSection('section-2-3-4')">
    <h4>âš¡ 2.3.4 Redisç¼“å­˜</h4>
    <p>è¡Œæƒ…å¿«ç…§ã€ä»»åŠ¡é˜Ÿåˆ—ã€çŠ¶æ€ç¼“å­˜</p>
  </div>
  <div class="section-item" onclick="scrollToSection('section-2-3-5')">
    <h4>ğŸ“¦ 2.3.5 æ–‡ä»¶ç¼“å­˜</h4>
    <p>Parquet/HDF5æ–‡ä»¶ç¼“å­˜ç­–ç•¥</p>
  </div>
  <div class="section-item" onclick="scrollToSection('section-2-3-6')">
    <h4>ğŸ”„ 2.3.6 æ•°æ®æµè½¬</h4>
    <p>æ•°æ®è·å–ã€å­˜å‚¨ã€æŸ¥è¯¢çš„å®Œæ•´æµç¨‹</p>
  </div>
</div>

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬èŠ‚å­¦ä¹ ï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š

- **ç†è§£æ¶æ„ç†å¿µ**ï¼šæŒæ¡åˆ†å±‚/å¤šå­˜å‚¨æ¶æ„çš„æ ¸å¿ƒæ€æƒ³
- **ç†Ÿæ‚‰PostgreSQLå­˜å‚¨**ï¼šäº†è§£æ•°æ®æºé…ç½®å’Œå…ƒæ•°æ®çš„å­˜å‚¨è®¾è®¡
- **æŒæ¡æ—¶åºåº“å­˜å‚¨**ï¼šç†è§£è¡Œæƒ…æ•°æ®å’Œå› å­æ•°æ®çš„å­˜å‚¨ç­–ç•¥
- **ä½¿ç”¨Redisç¼“å­˜**ï¼šæŒæ¡ç¼“å­˜ç­–ç•¥å’Œä»»åŠ¡é˜Ÿåˆ—çš„å®ç°
- **ç†è§£æ–‡ä»¶ç¼“å­˜**ï¼šäº†è§£Parquet/HDF5æ–‡ä»¶ç¼“å­˜çš„ä½¿ç”¨åœºæ™¯
- **æŒæ¡æ•°æ®æµè½¬**ï¼šç†è§£æ•°æ®ä»è·å–åˆ°å­˜å‚¨åˆ°æŸ¥è¯¢çš„å®Œæ•´æµç¨‹

<h2 id="section-2-3-1">ğŸ¯ 2.3.1 æ¶æ„è®¾è®¡ç†å¿µ</h2>

### æ ¸å¿ƒç†å¿µï¼šåˆ†å±‚/å¤šå­˜å‚¨ï¼ˆPolyglot Persistenceï¼‰

æ•°æ®æºæ¨¡å—é‡‡ç”¨**åˆ†å±‚/å¤šå­˜å‚¨ï¼ˆPolyglot Persistenceï¼‰**æ¶æ„ï¼Œæ ¹æ®æ•°æ®ç±»å‹çš„ç‰¹ç‚¹é€‰æ‹©æœ€é€‚åˆçš„å­˜å‚¨æ–¹æ¡ˆï¼Œè€Œä¸æ˜¯"å•åº“æ‰“å¤©ä¸‹"ã€‚

### è®¾è®¡åŸåˆ™

<div class="key-points">
  <div class="key-point">
    <h4>ğŸ“Š æŒ‰æ•°æ®ç±»å‹é€‰æ‹©å­˜å‚¨</h4>
    <p>å¼ºäº‹åŠ¡æ•°æ®ç”¨PostgreSQLï¼Œæ—¶åºæ•°æ®ç”¨æ—¶åºåº“ï¼Œä¸´æ—¶æ•°æ®ç”¨Redis</p>
  </div>
  <div class="key-point">
    <h4>âš¡ æ€§èƒ½ä¼˜å…ˆ</h4>
    <p>æ¯ç§æ•°æ®ä½¿ç”¨æœ€é€‚åˆçš„å­˜å‚¨ï¼Œè·å¾—æœ€ä½³æ€§èƒ½</p>
  </div>
  <div class="key-point">
    <h4>ğŸ’° æˆæœ¬ä¼˜åŒ–</h4>
    <p>åœ¨æ»¡è¶³æ€§èƒ½è¦æ±‚çš„å‰æä¸‹ï¼Œä¼˜åŒ–å­˜å‚¨æˆæœ¬</p>
  </div>
  <div class="key-point">
    <h4>ğŸ”„ å¯æ‰©å±•æ€§</h4>
    <p>æ”¯æŒæ°´å¹³æ‰©å±•ï¼Œæé«˜ç³»ç»Ÿå®¹é‡</p>
  </div>
</div>

### æ•°æ®å­˜å‚¨ç­–ç•¥

<div class="comparison-table">
  <table>
    <thead>
      <tr>
        <th>æ•°æ®ç±»å‹</th>
        <th>å­˜å‚¨æ–¹æ¡ˆ</th>
        <th>ä½¿ç”¨åœºæ™¯</th>
        <th>ä¼˜åŠ¿</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>æ•°æ®æºé…ç½®</strong></td>
        <td>PostgreSQL</td>
        <td>æ•°æ®æºè¿æ¥é…ç½®ã€å…ƒæ•°æ®ã€å®¡è®¡æ—¥å¿—</td>
        <td>å¼ºäº‹åŠ¡ã€å¼ºä¸€è‡´æ€§ã€å¯å®¡è®¡</td>
      </tr>
      <tr>
        <td><strong>è¡Œæƒ…æ•°æ®</strong></td>
        <td>ClickHouse/TimescaleDB</td>
        <td>OHLCVæ—¥/åˆ†é’Ÿ/Tickæ•°æ®</td>
        <td>é«˜æ•ˆèšåˆã€æ—¶é—´åºåˆ—æŸ¥è¯¢</td>
      </tr>
      <tr>
        <td><strong>å› å­æ•°æ®</strong></td>
        <td>ClickHouse/TimescaleDB</td>
        <td>æ¯æ—¥/æ¯åˆ†é’Ÿå› å­çŸ©é˜µ</td>
        <td>åˆ—å¼å­˜å‚¨ã€å‹ç¼©ç‡é«˜</td>
      </tr>
      <tr>
        <td><strong>è¡Œæƒ…å¿«ç…§</strong></td>
        <td>Redis</td>
        <td>å®æ—¶è¡Œæƒ…æ•°æ®ç¼“å­˜ï¼ˆTTL: 60ç§’ï¼‰</td>
        <td>é«˜é€Ÿè®¿é—®ã€ä½å»¶è¿Ÿ</td>
      </tr>
      <tr>
        <td><strong>ä»»åŠ¡é˜Ÿåˆ—</strong></td>
        <td>Redis</td>
        <td>æ•°æ®æ›´æ–°ä»»åŠ¡é˜Ÿåˆ—</td>
        <td>å‘å¸ƒ/è®¢é˜…ã€ä»»åŠ¡è°ƒåº¦</td>
      </tr>
      <tr>
        <td><strong>æ–‡ä»¶ç¼“å­˜</strong></td>
        <td>Parquet/HDF5</td>
        <td>æ—©æœŸé˜¶æ®µæˆ–å°è§„æ¨¡æ•°æ®</td>
        <td>ç®€å•ã€æˆæœ¬ä½</td>
      </tr>
    </tbody>
  </table>
</div>

### æ¶æ„æ€»è§ˆ

```
æ•°æ®æºæ¨¡å—æ•°æ®æµè½¬
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ•°æ®è·å–å±‚ï¼ˆDataSourceManagerï¼‰        â”‚
â”‚  - ç»Ÿä¸€æ¥å£                              â”‚
â”‚  - å¤šæ•°æ®æºæ”¯æŒ                          â”‚
â”‚  - æ™ºèƒ½é€‰æ‹©                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ•°æ®å­˜å‚¨å±‚ï¼ˆåˆ†å±‚/å¤šå­˜å‚¨ï¼‰               â”‚
â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ PostgreSQL   â”‚  â”‚ ClickHouse   â”‚    â”‚
â”‚  â”‚ é…ç½®/å…ƒæ•°æ®  â”‚  â”‚ æ—¶åºæ•°æ®     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Redis        â”‚  â”‚ Parquet/HDF5 â”‚    â”‚
â”‚  â”‚ ç¼“å­˜/é˜Ÿåˆ—    â”‚  â”‚ æ–‡ä»¶ç¼“å­˜     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ•°æ®æŸ¥è¯¢å±‚ï¼ˆç»Ÿä¸€æŸ¥è¯¢æ¥å£ï¼‰              â”‚
â”‚  - é€æ˜æŸ¥è¯¢                              â”‚
â”‚  - è‡ªåŠ¨è·¯ç”±                              â”‚
â”‚  - ç¼“å­˜ä¼˜å…ˆ                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<h2 id="section-2-3-2">ğŸ—„ï¸ 2.3.2 PostgreSQLå­˜å‚¨</h2>

### å­˜å‚¨å†…å®¹

PostgreSQLç”¨äºå­˜å‚¨æ•°æ®æºæ¨¡å—çš„**å¼ºäº‹åŠ¡/å¼ºå®¡è®¡ç±»æ•°æ®**ï¼š

1. **æ•°æ®æºé…ç½®**ï¼šæ•°æ®æºè¿æ¥é…ç½®ã€è®¤è¯ä¿¡æ¯
2. **å…ƒæ•°æ®**ï¼šæ•°æ®æºçŠ¶æ€ã€å¥åº·æ£€æŸ¥è®°å½•ã€ä½¿ç”¨ç»Ÿè®¡
3. **å®¡è®¡æ—¥å¿—**ï¼šæ•°æ®è·å–è®°å½•ã€é”™è¯¯æ—¥å¿—ã€æ“ä½œå†å²

### æ•°æ®æºé…ç½®è¡¨

```sql
-- æ•°æ®æºé…ç½®è¡¨
CREATE TABLE data_source_configs (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL UNIQUE,
    source_type VARCHAR(50) NOT NULL, -- jqdata, akshare, tushare, wind
    config JSONB NOT NULL, -- è¿æ¥é…ç½®ï¼ˆåŠ å¯†å­˜å‚¨ï¼‰
    priority INTEGER DEFAULT 0, -- ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
    status VARCHAR(50) DEFAULT 'active', -- active, inactive, maintenance, error
    health_check_interval INTEGER DEFAULT 300, -- å¥åº·æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
    last_health_check TIMESTAMP,
    last_health_status VARCHAR(50), -- ok, error, timeout
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_data_source_configs_status ON data_source_configs(status);
CREATE INDEX idx_data_source_configs_type ON data_source_configs(source_type);
CREATE INDEX idx_data_source_configs_config ON data_source_configs USING GIN (config);
```

### æ•°æ®æºå…ƒæ•°æ®è¡¨

```sql
-- æ•°æ®æºå…ƒæ•°æ®è¡¨
CREATE TABLE data_source_metadata (
    id SERIAL PRIMARY KEY,
    source_name VARCHAR(100) NOT NULL REFERENCES data_source_configs(name),
    data_type VARCHAR(50) NOT NULL, -- daily, minute, tick, fundamental
    symbol VARCHAR(50),
    start_date DATE,
    end_date DATE,
    record_count BIGINT,
    last_update TIMESTAMP,
    data_quality_score DECIMAL(5,2), -- æ•°æ®è´¨é‡è¯„åˆ†ï¼ˆ0-100ï¼‰
    completeness DECIMAL(5,2), -- å®Œæ•´æ€§ï¼ˆ0-100ï¼‰
    accuracy DECIMAL(5,2), -- å‡†ç¡®æ€§ï¼ˆ0-100ï¼‰
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(source_name, data_type, symbol, start_date, end_date)
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_data_source_metadata_source ON data_source_metadata(source_name);
CREATE INDEX idx_data_source_metadata_symbol ON data_source_metadata(symbol);
CREATE INDEX idx_data_source_metadata_date ON data_source_metadata(start_date, end_date);
```

### æ•°æ®è·å–å®¡è®¡æ—¥å¿—è¡¨

```sql
-- æ•°æ®è·å–å®¡è®¡æ—¥å¿—è¡¨ï¼ˆæŒ‰æ—¥åˆ†åŒºï¼‰
CREATE TABLE data_fetch_logs (
    id BIGSERIAL,
    source_name VARCHAR(100) NOT NULL,
    data_type VARCHAR(50) NOT NULL,
    symbol VARCHAR(50),
    start_date DATE,
    end_date DATE,
    record_count INTEGER,
    fetch_duration_ms INTEGER, -- è·å–è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    status VARCHAR(50) NOT NULL, -- success, error, timeout
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (id, created_at)
) PARTITION BY RANGE (created_at);

-- åˆ›å»ºæŒ‰æœˆåˆ†åŒº
CREATE TABLE data_fetch_logs_2025_01 PARTITION OF data_fetch_logs
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
```

### ä½¿ç”¨ç¤ºä¾‹

```python
from core.data_center import DataCenter
import json

# åˆå§‹åŒ–æ•°æ®ä¸­å¿ƒ
dc = DataCenter()

# æ·»åŠ æ•°æ®æºé…ç½®
dc.add_data_source(
    name="jqdata",
    source_type="jqdata",
    config={
        "username": "your_username",
        "password": "your_password",  # å®é™…åº”åŠ å¯†å­˜å‚¨
        "api_url": "https://dataapi.joinquant.com"
    },
    priority=10  # é«˜ä¼˜å…ˆçº§
)

# æŸ¥è¯¢æ•°æ®æºé…ç½®
config = dc.get_data_source_config("jqdata")
print(f"æ•°æ®æºçŠ¶æ€: {config['status']}")
print(f"æœ€åå¥åº·æ£€æŸ¥: {config['last_health_check']}")

# è®°å½•æ•°æ®è·å–æ—¥å¿—
dc.log_data_fetch(
    source_name="jqdata",
    data_type="daily",
    symbol="000001.XSHE",
    start_date="2024-01-01",
    end_date="2024-12-31",
    record_count=245,
    fetch_duration_ms=1200,
    status="success"
)
```

<h2 id="section-2-3-3">â±ï¸ 2.3.3 æ—¶åºåº“å­˜å‚¨</h2>

### å­˜å‚¨å†…å®¹

æ—¶åºæ•°æ®åº“ï¼ˆClickHouseæˆ–TimescaleDBï¼‰ç”¨äºå­˜å‚¨æ•°æ®æºæ¨¡å—çš„**æ—¶é—´åºåˆ—æ•°æ®**ï¼š

1. **è¡Œæƒ…æ•°æ®**ï¼šOHLCVæ—¥çº¿ã€åˆ†é’Ÿçº¿ã€Tickæ•°æ®
2. **å› å­æ•°æ®**ï¼šæ¯æ—¥/æ¯åˆ†é’Ÿå› å­çŸ©é˜µ
3. **å›æµ‹è¾“å‡º**ï¼šå‡€å€¼æ›²çº¿ã€åˆ†å±‚å½’å› ã€è¡Œä¸šæš´éœ²

### ClickHouseå­˜å‚¨ï¼ˆæ¨èï¼‰

#### è¡Œæƒ…æ•°æ®è¡¨

```sql
-- OHLCVæ—¥çº¿æ•°æ®è¡¨
CREATE TABLE market_data_daily (
    symbol String,
    trade_date Date,
    open Decimal64(4),
    high Decimal64(4),
    low Decimal64(4),
    close Decimal64(4),
    volume UInt64,
    amount Decimal64(2),
    turnover_rate Decimal64(4), -- æ¢æ‰‹ç‡
    pe_ratio Decimal64(4), -- å¸‚ç›ˆç‡
    pb_ratio Decimal64(4), -- å¸‚å‡€ç‡
    source String, -- æ•°æ®æºåç§°
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(trade_date)
ORDER BY (symbol, trade_date)
TTL trade_date + INTERVAL 10 YEAR; -- ä¿ç•™10å¹´

-- OHLCVåˆ†é’Ÿçº¿æ•°æ®è¡¨
CREATE TABLE market_data_minute (
    symbol String,
    trade_time DateTime,
    open Decimal64(4),
    high Decimal64(4),
    low Decimal64(4),
    close Decimal64(4),
    volume UInt64,
    amount Decimal64(2),
    source String,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(trade_time)
ORDER BY (symbol, trade_time)
TTL trade_time + INTERVAL 2 YEAR; -- ä¿ç•™2å¹´
```

#### å› å­æ•°æ®è¡¨

```sql
-- å› å­å€¼è¡¨ï¼ˆæ¯æ—¥ï¼‰
CREATE TABLE factor_values_daily (
    symbol String,
    trade_date Date,
    factor_name String,
    factor_value Float64,
    source String,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(trade_date)
ORDER BY (symbol, trade_date, factor_name);

-- å› å­çŸ©é˜µè¡¨ï¼ˆæ¯æ—¥å…¨å¸‚åœºï¼‰
CREATE TABLE factor_matrix_daily (
    trade_date Date,
    factor_matrix String, -- JSONæ ¼å¼å­˜å‚¨å› å­çŸ©é˜µ
    symbol_count UInt32,
    factor_count UInt32,
    source String,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(trade_date)
ORDER BY trade_date;
```

### TimescaleDBå­˜å‚¨ï¼ˆæ›¿ä»£æ–¹æ¡ˆï¼‰

å¦‚æœé€‰æ‹©TimescaleDBï¼Œå¯ä»¥ä½¿ç”¨PostgreSQLçš„æ—¶åºæ‰©å±•ï¼š

```sql
-- åˆ›å»ºæ—¶åºè¡¨ï¼ˆæ—¥çº¿æ•°æ®ï¼‰
CREATE TABLE market_data_daily (
    symbol VARCHAR(50),
    trade_date DATE,
    open DECIMAL(15,4),
    high DECIMAL(15,4),
    low DECIMAL(15,4),
    close DECIMAL(15,4),
    volume BIGINT,
    amount DECIMAL(20,2),
    source VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- è½¬æ¢ä¸ºæ—¶åºè¡¨
SELECT create_hypertable('market_data_daily', 'trade_date');

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_market_data_daily_symbol_date 
    ON market_data_daily(symbol, trade_date DESC);
```

### ä½¿ç”¨ç¤ºä¾‹

```python
from core.data_center import DataCenter

dc = DataCenter()

# å­˜å‚¨è¡Œæƒ…æ•°æ®åˆ°ClickHouse
def store_market_data(symbol: str, data: pd.DataFrame, source: str = "jqdata"):
    """å­˜å‚¨è¡Œæƒ…æ•°æ®åˆ°æ—¶åºåº“"""
    # æ·»åŠ æ•°æ®æºæ ‡è¯†
    data['source'] = source
    data['created_at'] = pd.Timestamp.now()
    
    # å­˜å‚¨åˆ°ClickHouse
    dc.clickhouse_client.insert(
        'market_data_daily',
        data.to_dict('records')
    )
    
    # æ›´æ–°å…ƒæ•°æ®
    dc.update_metadata(
        source_name=source,
        data_type="daily",
        symbol=symbol,
        start_date=data['trade_date'].min(),
        end_date=data['trade_date'].max(),
        record_count=len(data)
    )

# æŸ¥è¯¢è¡Œæƒ…æ•°æ®
def query_market_data(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
    """ä»æ—¶åºåº“æŸ¥è¯¢è¡Œæƒ…æ•°æ®"""
    query = f"""
    SELECT * FROM market_data_daily
    WHERE symbol = '{symbol}'
      AND trade_date >= '{start_date}'
      AND trade_date <= '{end_date}'
    ORDER BY trade_date
    """
    return dc.clickhouse_client.query(query).to_pandas()
```

<h2 id="section-2-3-4">âš¡ 2.3.4 Redisç¼“å­˜</h2>

### å­˜å‚¨å†…å®¹

Redisç”¨äºå­˜å‚¨æ•°æ®æºæ¨¡å—çš„**ä¸´æ—¶æ•°æ®å’Œç¼“å­˜**ï¼š

1. **è¡Œæƒ…å¿«ç…§**ï¼šå®æ—¶è¡Œæƒ…æ•°æ®ç¼“å­˜ï¼ˆTTL: 60ç§’ï¼‰
2. **ä»»åŠ¡é˜Ÿåˆ—**ï¼šæ•°æ®æ›´æ–°ä»»åŠ¡é˜Ÿåˆ—
3. **çŠ¶æ€ç¼“å­˜**ï¼šæ•°æ®æºå¥åº·çŠ¶æ€ã€è¿æ¥çŠ¶æ€

### è¡Œæƒ…å¿«ç…§ç¼“å­˜

```python
import redis
import json
from datetime import timedelta

r = redis.Redis(host='localhost', port=6379, db=0)

def cache_market_snapshot(symbol: str, data: dict, ttl: int = 60):
    """ç¼“å­˜è¡Œæƒ…å¿«ç…§ï¼ˆTTL: 60ç§’ï¼‰"""
    key = f"market:snapshot:{symbol}"
    r.setex(key, ttl, json.dumps(data))
    
def get_market_snapshot(symbol: str) -> dict:
    """è·å–è¡Œæƒ…å¿«ç…§"""
    key = f"market:snapshot:{symbol}"
    data = r.get(key)
    if data:
        return json.loads(data)
    return None

def cache_batch_snapshots(snapshots: dict, ttl: int = 60):
    """æ‰¹é‡ç¼“å­˜è¡Œæƒ…å¿«ç…§"""
    pipe = r.pipeline()
    for symbol, data in snapshots.items():
        key = f"market:snapshot:{symbol}"
        pipe.setex(key, ttl, json.dumps(data))
    pipe.execute()
```

### ä»»åŠ¡é˜Ÿåˆ—

```python
def enqueue_data_update_task(symbol: str, data_type: str, priority: int = 0):
    """å°†æ•°æ®æ›´æ–°ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—"""
    task = {
        "symbol": symbol,
        "data_type": data_type,
        "priority": priority,
        "created_at": pd.Timestamp.now().isoformat()
    }
    
    # ä½¿ç”¨æœ‰åºé›†åˆå®ç°ä¼˜å…ˆçº§é˜Ÿåˆ—
    r.zadd("data:update:queue", {json.dumps(task): priority})
    
def dequeue_data_update_task() -> dict:
    """ä»é˜Ÿåˆ—ä¸­å–å‡ºæœ€é«˜ä¼˜å…ˆçº§çš„ä»»åŠ¡"""
    # è·å–æœ€é«˜ä¼˜å…ˆçº§çš„ä»»åŠ¡
    tasks = r.zrevrange("data:update:queue", 0, 0, withscores=True)
    if tasks:
        task_json, score = tasks[0]
        r.zrem("data:update:queue", task_json)
        return json.loads(task_json)
    return None
```

### çŠ¶æ€ç¼“å­˜

```python
def cache_source_health(source_name: str, health_status: dict, ttl: int = 300):
    """ç¼“å­˜æ•°æ®æºå¥åº·çŠ¶æ€ï¼ˆTTL: 5åˆ†é’Ÿï¼‰"""
    key = f"source:health:{source_name}"
    r.setex(key, ttl, json.dumps(health_status))
    
def get_source_health(source_name: str) -> dict:
    """è·å–æ•°æ®æºå¥åº·çŠ¶æ€"""
    key = f"source:health:{source_name}"
    data = r.get(key)
    if data:
        return json.loads(data)
    return None
```

<h2 id="section-2-3-5">ğŸ“¦ 2.3.5 æ–‡ä»¶ç¼“å­˜</h2>

### ä½¿ç”¨åœºæ™¯

æ–‡ä»¶ç¼“å­˜ï¼ˆParquet/HDF5ï¼‰é€‚åˆä»¥ä¸‹åœºæ™¯ï¼š

1. **æ—©æœŸé˜¶æ®µ**ï¼šç³»ç»ŸåˆæœŸï¼Œæ•°æ®é‡è¾ƒå°
2. **æœ¬åœ°å¼€å‘**ï¼šå¼€å‘ç¯å¢ƒï¼Œä¸éœ€è¦å®Œæ•´çš„æ•°æ®åº“
3. **æ•°æ®å¤‡ä»½**ï¼šæ•°æ®å¤‡ä»½å’Œæ¢å¤
4. **ç¦»çº¿åˆ†æ**ï¼šç¦»çº¿æ•°æ®åˆ†æå’Œç ”ç©¶

### Parquetæ–‡ä»¶ç¼“å­˜

```python
import pandas as pd
import pyarrow.parquet as pq
from pathlib import Path

CACHE_DIR = Path("data/cache/parquet")

def save_to_parquet(symbol: str, data: pd.DataFrame, data_type: str = "daily"):
    """ä¿å­˜æ•°æ®åˆ°Parquetæ–‡ä»¶"""
    cache_file = CACHE_DIR / f"{symbol}_{data_type}.parquet"
    cache_file.parent.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜ä¸ºParquetæ ¼å¼ï¼ˆå‹ç¼©ï¼‰
    data.to_parquet(cache_file, compression='snappy', index=False)
    
def load_from_parquet(symbol: str, data_type: str = "daily") -> pd.DataFrame:
    """ä»Parquetæ–‡ä»¶åŠ è½½æ•°æ®"""
    cache_file = CACHE_DIR / f"{symbol}_{data_type}.parquet"
    if cache_file.exists():
        return pd.read_parquet(cache_file)
    return None
```

### HDF5æ–‡ä»¶ç¼“å­˜

```python
import pandas as pd
import h5py

CACHE_FILE = "data/cache/market_data.h5"

def save_to_hdf5(symbol: str, data: pd.DataFrame, data_type: str = "daily"):
    """ä¿å­˜æ•°æ®åˆ°HDF5æ–‡ä»¶"""
    key = f"/{symbol}/{data_type}"
    data.to_hdf(CACHE_FILE, key, mode='a', format='table', append=False)
    
def load_from_hdf5(symbol: str, data_type: str = "daily") -> pd.DataFrame:
    """ä»HDF5æ–‡ä»¶åŠ è½½æ•°æ®"""
    key = f"/{symbol}/{data_type}"
    try:
        return pd.read_hdf(CACHE_FILE, key)
    except KeyError:
        return None
```

<h2 id="section-2-3-6">ğŸ”„ 2.3.6 æ•°æ®æµè½¬</h2>

### å®Œæ•´æ•°æ®æµè½¬æµç¨‹

```
1. æ•°æ®è·å–è¯·æ±‚
   â†“
2. æ£€æŸ¥Redisç¼“å­˜ï¼ˆè¡Œæƒ…å¿«ç…§ï¼‰
   â”œâ”€ å‘½ä¸­ â†’ ç›´æ¥è¿”å›
   â””â”€ æœªå‘½ä¸­ â†’ ç»§ç»­
   â†“
3. æ£€æŸ¥æ–‡ä»¶ç¼“å­˜ï¼ˆParquet/HDF5ï¼‰
   â”œâ”€ å‘½ä¸­ â†’ è¿”å›å¹¶æ›´æ–°Redisç¼“å­˜
   â””â”€ æœªå‘½ä¸­ â†’ ç»§ç»­
   â†“
4. ä»æ•°æ®æºè·å–æ•°æ®
   â”œâ”€ æˆåŠŸ â†’ å­˜å‚¨åˆ°æ—¶åºåº“ + æ›´æ–°ç¼“å­˜
   â””â”€ å¤±è´¥ â†’ æ•…éšœåˆ‡æ¢æˆ–è¿”å›é”™è¯¯
   â†“
5. è®°å½•å®¡è®¡æ—¥å¿—ï¼ˆPostgreSQLï¼‰
   â†“
6. è¿”å›æ•°æ®
```

### å®ç°ç¤ºä¾‹

```python
class DataStorageManager:
    """æ•°æ®å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self):
        self.pg_client = PostgreSQLClient()
        self.ch_client = ClickHouseClient()
        self.redis_client = RedisClient()
        self.cache_dir = Path("data/cache/parquet")
    
    def get_data(self, symbol: str, start_date: str, end_date: str, 
                 data_type: str = "daily", use_cache: bool = True) -> pd.DataFrame:
        """è·å–æ•°æ®ï¼ˆå®Œæ•´æµç¨‹ï¼‰"""
        
        # 1. æ£€æŸ¥Redisç¼“å­˜ï¼ˆä»…å®æ—¶æ•°æ®ï¼‰
        if data_type == "snapshot" and use_cache:
            cached = self.redis_client.get_market_snapshot(symbol)
            if cached:
                return pd.DataFrame([cached])
        
        # 2. æ£€æŸ¥æ–‡ä»¶ç¼“å­˜
        if use_cache:
            cached = self.load_from_parquet(symbol, data_type)
            if cached is not None:
                # æ£€æŸ¥æ—¥æœŸèŒƒå›´
                if (cached['trade_date'].min() <= start_date and 
                    cached['trade_date'].max() >= end_date):
                    return cached
        
        # 3. ä»æ—¶åºåº“æŸ¥è¯¢
        data = self.ch_client.query_market_data(
            symbol, start_date, end_date, data_type
        )
        
        if data is not None and len(data) > 0:
            # 4. æ›´æ–°ç¼“å­˜
            if use_cache:
                self.save_to_parquet(symbol, data, data_type)
            
            # 5. è®°å½•å®¡è®¡æ—¥å¿—
            self.pg_client.log_data_fetch(
                symbol=symbol,
                data_type=data_type,
                start_date=start_date,
                end_date=end_date,
                record_count=len(data),
                status="success"
            )
            
            return data
        
        # 6. ä»æ•°æ®æºè·å–ï¼ˆå¦‚æœæ—¶åºåº“ä¹Ÿæ²¡æœ‰ï¼‰
        data = self.fetch_from_source(symbol, start_date, end_date, data_type)
        
        if data is not None and len(data) > 0:
            # 7. å­˜å‚¨åˆ°æ—¶åºåº“
            self.ch_client.store_market_data(symbol, data, data_type)
            
            # 8. æ›´æ–°ç¼“å­˜
            if use_cache:
                self.save_to_parquet(symbol, data, data_type)
            
            # 9. è®°å½•å®¡è®¡æ—¥å¿—
            self.pg_client.log_data_fetch(
                symbol=symbol,
                data_type=data_type,
                start_date=start_date,
                end_date=end_date,
                record_count=len(data),
                status="success"
            )
            
            return data
        
        return pd.DataFrame()
```

## ğŸ”— ç›¸å…³ç« èŠ‚

- **1.2 ç³»ç»Ÿæ¶æ„æ€»è§ˆ**ï¼šäº†è§£æ•°æ®æºæ¨¡å—åœ¨ç³»ç»Ÿæ¶æ„ä¸­çš„ä½ç½®
- **1.9 æ•°æ®åº“æ¶æ„è®¾è®¡**ï¼šæ·±å…¥äº†è§£ç³»ç»Ÿæ•´ä½“çš„æ•°æ®å­˜å‚¨æ¶æ„è®¾è®¡
- **2.1 æ•°æ®æºç®¡ç†**ï¼šè¯¦ç»†äº†è§£æ•°æ®æºç®¡ç†å®ç°
- **2.2 æ•°æ®è´¨é‡**ï¼šè¯¦ç»†äº†è§£æ•°æ®è´¨é‡æ£€æŸ¥æœºåˆ¶
- **2.4 MCPå·¥å…·é›†æˆ**ï¼šäº†è§£MCPå·¥å…·åœ¨æ•°æ®æºæ¨¡å—ä¸­çš„åº”ç”¨

## ğŸ’¡ å…³é”®è¦ç‚¹

1. **åˆ†å±‚/å¤šå­˜å‚¨æ¶æ„**ï¼šæ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©æœ€é€‚åˆçš„å­˜å‚¨æ–¹æ¡ˆ
2. **PostgreSQLå­˜å‚¨**ï¼šæ•°æ®æºé…ç½®ã€å…ƒæ•°æ®ã€å®¡è®¡æ—¥å¿—
3. **æ—¶åºåº“å­˜å‚¨**ï¼šè¡Œæƒ…æ•°æ®ã€å› å­æ•°æ®ã€å›æµ‹è¾“å‡º
4. **Redisç¼“å­˜**ï¼šè¡Œæƒ…å¿«ç…§ã€ä»»åŠ¡é˜Ÿåˆ—ã€çŠ¶æ€ç¼“å­˜
5. **æ–‡ä»¶ç¼“å­˜**ï¼šParquet/HDF5é€‚åˆæ—©æœŸé˜¶æ®µæˆ–å°è§„æ¨¡æ•°æ®
6. **æ•°æ®æµè½¬**ï¼šç¼“å­˜ä¼˜å…ˆ â†’ æ—¶åºåº“æŸ¥è¯¢ â†’ æ•°æ®æºè·å– â†’ å­˜å‚¨

---

*æœ€åæ›´æ–°: 2025-12-13*  
*é€‚ç”¨ç‰ˆæœ¬: v1.0.0+*

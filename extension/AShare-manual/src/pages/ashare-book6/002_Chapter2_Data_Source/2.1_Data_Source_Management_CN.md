---
title: "2.1 æ•°æ®æºç®¡ç†"
description: "æ·±å…¥è§£ææ•°æ®æºç®¡ç†æœºåˆ¶ï¼ŒåŒ…æ‹¬ç»Ÿä¸€æ¥å£è®¾è®¡ã€å¤šæ•°æ®æºæ”¯æŒã€æ™ºèƒ½é€‰æ‹©ç­–ç•¥ã€æ•…éšœè‡ªåŠ¨åˆ‡æ¢å’Œæ•°æ®å­˜å‚¨é›†æˆ"
lang: "zh-CN"
layout: "/src/layouts/HandbookLayout.astro"
currentBook: "ashare-book6"
updateDate: "2025-12-12"
---

# ğŸ“¡ 2.1 æ•°æ®æºç®¡ç†

> **æ ¸å¿ƒæ‘˜è¦ï¼š**
> 
> æœ¬èŠ‚ç³»ç»Ÿä»‹ç»TRQuantç³»ç»Ÿçš„æ•°æ®æºç®¡ç†æœºåˆ¶ï¼ŒåŒ…æ‹¬ç»Ÿä¸€æ¥å£æŠ½è±¡ã€å¤šæ•°æ®æºæ”¯æŒã€æ™ºèƒ½é€‰æ‹©ç­–ç•¥å’Œæ•…éšœè‡ªåŠ¨åˆ‡æ¢ã€‚é€šè¿‡ç†è§£æ•°æ®æºåŸºç±»æ¥å£ã€æ•°æ®æºç®¡ç†å™¨è®¾è®¡ã€æ•°æ®æºé€‰æ‹©ç®—æ³•å’Œæ•°æ®åº“é›†æˆï¼Œå¸®åŠ©å¼€å‘è€…æŒæ¡æ•°æ®æºç®¡ç†çš„æ ¸å¿ƒå®ç°ï¼Œä¸ºæ„å»ºå¯é çš„æ•°æ®è·å–ç³»ç»Ÿå¥ å®šåŸºç¡€ã€‚

## ğŸ“‹ ç« èŠ‚æ¦‚è§ˆ

<script>
function scrollToSection(sectionId) {
  const element = document.getElementById(sectionId);
  if (element) {
    const headerOffset = 100;
    const elementPosition = element.getBoundingClientRect().top;
    const offsetPosition = elementPosition + window.pageYOffset - headerOffset;
    window.scrollTo({
      top: offsetPosition,
      behavior: 'smooth'
    });
  }
}
</script>

<div class="section-overview">
  <div class="section-item" onclick="scrollToSection('section-2-1-1')">
    <h4>ğŸ—ï¸ 2.1.1 æ¥å£è®¾è®¡</h4>
    <p>æ•°æ®æºåŸºç±»æ¥å£ã€æ•°æ®æºç®¡ç†å™¨æ¥å£ã€ç»Ÿä¸€æ•°æ®æ ¼å¼</p>
  </div>
  <div class="section-item" onclick="scrollToSection('section-2-1-2')">
    <h4>ğŸ“Š 2.1.2 å¤šæ•°æ®æºæ”¯æŒ</h4>
    <p>JQDataã€AKShareã€TuShareã€Windç­‰æ•°æ®æºå®ç°</p>
  </div>
  <div class="section-item" onclick="scrollToSection('section-2-1-3')">
    <h4>ğŸ¯ 2.1.3 æ™ºèƒ½é€‰æ‹©ç­–ç•¥</h4>
    <p>æ•°æ®æºé€‰æ‹©ç®—æ³•ã€ä¼˜å…ˆçº§é…ç½®ã€å¥åº·æ£€æŸ¥æœºåˆ¶</p>
  </div>
  <div class="section-item" onclick="scrollToSection('section-2-1-4')">
    <h4>ğŸ”„ 2.1.4 æ•…éšœè‡ªåŠ¨åˆ‡æ¢</h4>
    <p>æ•…éšœæ£€æµ‹ã€è‡ªåŠ¨åˆ‡æ¢ã€è´Ÿè½½å‡è¡¡ã€çŠ¶æ€ç›‘æ§</p>
  </div>
  <div class="section-item" onclick="scrollToSection('section-2-1-5')">
    <h4>ğŸ—„ï¸ 2.1.5 æ•°æ®å­˜å‚¨é›†æˆ</h4>
    <p>PostgreSQLå…ƒæ•°æ®å­˜å‚¨ã€æ—¶åºåº“æ•°æ®å­˜å‚¨ã€ç¼“å­˜ç­–ç•¥</p>
  </div>
  <div class="section-item" onclick="scrollToSection('section-2-1-6')">
    <h4>ğŸ› ï¸ 2.1.6 MCPå·¥å…·ä½¿ç”¨</h4>
    <p>ä½¿ç”¨MCPå·¥å…·æŸ¥è¯¢æ•°æ®æºæ–‡æ¡£ã€æ”¶é›†æ•°æ®æºä¿¡æ¯</p>
  </div>
</div>

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬èŠ‚å­¦ä¹ ï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š

- **ç†è§£æ¥å£è®¾è®¡**ï¼šæŒæ¡æ•°æ®æºåŸºç±»æ¥å£å’Œç®¡ç†å™¨æ¥å£çš„è®¾è®¡åŸç†
- **ç†Ÿæ‚‰å¤šæ•°æ®æº**ï¼šäº†è§£å„æ•°æ®æºçš„ç‰¹ç‚¹ã€é€‚ç”¨åœºæ™¯å’Œå®ç°æ–¹å¼
- **æŒæ¡é€‰æ‹©ç­–ç•¥**ï¼šç†è§£æ•°æ®æºé€‰æ‹©ç®—æ³•å’Œä¼˜å…ˆçº§é…ç½®æœºåˆ¶
- **å®ç°æ•…éšœåˆ‡æ¢**ï¼šæŒæ¡æ•…éšœæ£€æµ‹å’Œè‡ªåŠ¨åˆ‡æ¢çš„å®ç°æ–¹æ³•
- **é›†æˆæ•°æ®å­˜å‚¨**ï¼šç†è§£æ•°æ®æºä¸æ•°æ®åº“çš„é›†æˆæ–¹å¼
- **ä½¿ç”¨MCPå·¥å…·**ï¼šæŒæ¡ä½¿ç”¨MCPå·¥å…·è¿›è¡Œæ•°æ®æºç›¸å…³ç ”ç©¶

<h2 id="section-2-1-1">ğŸ—ï¸ 2.1.1 æ¥å£è®¾è®¡</h2>

æ•°æ®æºæ¨¡å—é‡‡ç”¨**æ¥å£æŠ½è±¡**è®¾è®¡æ¨¡å¼ï¼Œé€šè¿‡å®šä¹‰ç»Ÿä¸€çš„æ¥å£è§„èŒƒï¼Œå®ç°å¤šæ•°æ®æºçš„ç»Ÿä¸€ç®¡ç†ã€‚

### è®¾è®¡åŸåˆ™

<div class="key-points">
  <div class="key-point">
    <h4>ğŸ”Œ ç»Ÿä¸€æ¥å£</h4>
    <p>æ‰€æœ‰æ•°æ®æºå®ç°ç»Ÿä¸€çš„æ¥å£è§„èŒƒï¼Œä¾¿äºç®¡ç†å’Œåˆ‡æ¢</p>
  </div>
  <div class="key-point">
    <h4>ğŸ”„ å¯æ‰©å±•æ€§</h4>
    <p>é€šè¿‡æ¥å£æŠ½è±¡ï¼Œæ˜“äºæ·»åŠ æ–°çš„æ•°æ®æºå®ç°</p>
  </div>
  <div class="key-point">
    <h4>ğŸ›¡ï¸ ç±»å‹å®‰å…¨</h4>
    <p>ä½¿ç”¨ç±»å‹æ³¨è§£å’ŒæŠ½è±¡åŸºç±»ï¼Œä¿è¯ç±»å‹å®‰å…¨</p>
  </div>
  <div class="key-point">
    <h4>ğŸ“Š ç»Ÿä¸€æ ¼å¼</h4>
    <p>æ‰€æœ‰æ•°æ®æºè¿”å›ç»Ÿä¸€çš„æ•°æ®æ ¼å¼ï¼ˆDataFrameï¼‰</p>
  </div>
</div>

### æ•°æ®æºåŸºç±»æ¥å£

`BaseDataSource`æ˜¯æ‰€æœ‰æ•°æ®æºå®ç°çš„åŸºç±»ï¼Œå®šä¹‰äº†ç»Ÿä¸€çš„æ•°æ®æºæ¥å£ï¼š

<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/002_Chapter2_Data_Source/2.1/code_2_1___init__.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1___init__.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
from abc import ABC, abstractmethod
from typing import List, Dict, Optional, Any
from datetime import datetime
import pandas as pd
import logging

logger = logging.getLogger(__name__)


class BaseDataSource(ABC):
    """æ•°æ®æºåŸºç±» - å®šä¹‰ç»Ÿä¸€æ¥å£"""
    
    def __init__(self, name: str):
        """
        åˆå§‹åŒ–æ•°æ®æº
        
        Args:
            name: æ•°æ®æºåç§°ï¼ˆå”¯ä¸€æ ‡è¯†ç¬¦ï¼‰
        """
        self.name = name
        self._connected = False
        self._last_error = None
        self._connection_time = None
    
    @property
    def is_connected(self) -> bool:
        """æ˜¯å¦å·²è¿æ¥"""
        return self._connected
    
    @property
    def last_error(self) -> Optional[str]:
        """æœ€åä¸€æ¬¡é”™è¯¯ä¿¡æ¯"""
        return self._last_error
    
    @abstractmethod
    def connect(self, **kwargs) -> bool:
        """
        è¿æ¥æ•°æ®æº
        
        Args:
            **kwargs: è¿æ¥å‚æ•°ï¼ˆç”¨æˆ·åã€å¯†ç ã€API Keyç­‰ï¼‰
        
        Returns:
            æ˜¯å¦è¿æ¥æˆåŠŸ
        """
        pass
    
    @abstractmethod
    def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        pass
    
    @abstractmethod
    def health_check(self) -> Dict[str, Any]:
        """
        å¥åº·æ£€æŸ¥
        
        Returns:
            {
                "status": "ok/error/timeout",
                "latency": 120,  # æ¯«ç§’
                "error": "é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰",
                "checked_at": "2024-12-12T10:00:00"
            }
        """
        pass
    
    # ============================================================
    # è¡Œæƒ…æ•°æ®æ¥å£
    # ============================================================
    
    @abstractmethod
    def get_daily_data(self, symbol: str, start_date: str, 
                       end_date: str, fields: List[str] = None) -> pd.DataFrame:
        """
        è·å–æ—¥çº¿æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ "000001.XSHE"ï¼‰
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            fields: éœ€è¦è·å–çš„å­—æ®µåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºè·å–æ‰€æœ‰å­—æ®µ
        
        Returns:
            DataFrame with columns: date, open, high, low, close, volume, amount
            å¦‚æœfieldsæŒ‡å®šï¼Œåˆ™åªè¿”å›æŒ‡å®šå­—æ®µ
        """
        pass
    
    @abstractmethod
    def get_minute_data(self, symbol: str, count: int = 240, 
                        period: str = "1m", end_date: str = None) -> pd.DataFrame:
        """
        è·å–åˆ†é’Ÿçº¿æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            count: è·å–æœ€è¿‘Næ¡æ•°æ®
            period: å‘¨æœŸï¼ˆ1m, 5m, 15m, 30m, 60mï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ŒNoneè¡¨ç¤ºå½“å‰æ—¶é—´
        
        Returns:
            DataFrame with columns: time, open, high, low, close, volume, amount
        """
        pass
    
    def get_tick_data(self, symbol: str, date: str) -> pd.DataFrame:
        """
        è·å–Tickæ•°æ®ï¼ˆå¯é€‰å®ç°ï¼‰
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸ (YYYY-MM-DD)
        
        Returns:
            DataFrame with columns: time, price, volume, amount, direction
        """
        raise NotImplementedError(f"{self.name} ä¸æ”¯æŒTickæ•°æ®")
    
    # ============================================================
    # åŸºæœ¬é¢æ•°æ®æ¥å£
    # ============================================================
    
    def get_fundamentals(self, symbol: str, date: str = None) -> Dict[str, Any]:
        """
        è·å–åŸºæœ¬é¢æ•°æ®ï¼ˆå¯é€‰å®ç°ï¼‰
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸï¼ŒNoneè¡¨ç¤ºæœ€æ–°æ•°æ®
        
        Returns:
            å­—å…¸æ ¼å¼çš„åŸºæœ¬é¢æ•°æ®
        """
        raise NotImplementedError(f"{self.name} ä¸æ”¯æŒåŸºæœ¬é¢æ•°æ®")
    
    def get_financial_statements(self, symbol: str, report_type: str = "annual") -> pd.DataFrame:
        """
        è·å–è´¢åŠ¡æŠ¥è¡¨ï¼ˆå¯é€‰å®ç°ï¼‰
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            report_type: æŠ¥å‘Šç±»å‹ï¼ˆannual, quarterlyï¼‰
 <CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/002_Chapter2_Data_Source/2.1/code_2_1___init__.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```
-->python
from typing import Dict, List, Optional
from datetime import datetime
import pandas as pd
import logging

logger = logging.getLogger(__name__)


class DataSourceManager:
    """æ•°æ®æºç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†å¤šä¸ªæ•°æ®æº"""
    
    def __init__(self, use_cache: bool = True):
        """
        åˆå§‹åŒ–æ•°æ®æºç®¡ç†å™¨
        
        Args:
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
        """
        self.sources: Dict[str, BaseDataSource] = {}
        self.priority: Dict[str, List[str]] = {
            'daily': ['jqdata', 'akshare', 'tushare'],
            'minute': ['jqdata', 'akshare'],
            'realtime': ['akshare', 'jqdata'],
            'fundamental': ['jqdata', 'tushare'],
        }
        self.cache = None  # ç¼“å­˜ç®¡ç†å™¨
        self.use_cache = use_cache
        self._connected_sources = set()
        
        # åˆå§‹åŒ–ç¼“å­˜
        if use_cache:
            from core.cache import CacheManager
            self.cache = CacheManager()
    
    def add_source(self, name: str, source: BaseDataSource):
        """
        æ·»åŠ æ•°æ®æº
        
        Args:
            name: æ•°æ®æºåç§°
            source: æ•°æ®æºå®ä¾‹
        """
        self.sources[name] = source
        logger.info(f"æ·»åŠ æ•°æ®æº: {name}")
    
    def remove_source(self, name: str):
        """
        ç§»é™¤æ•°æ®æº
        
        Args:
            name: æ•°æ®æºåç§°
        """
        if name in self.sources:
            self.sources[name].disconnect()
            del self.sources[name]
            self._connected_sources.discard(name)
            logger.info(f"ç§»é™¤æ•°æ®æº: {name}")
    
    def connect_all(self) -> Dict[str, bool]:
        """
        è¿æ¥æ‰€æœ‰æ•°æ®æº
        
        Returns:
            è¿æ¥ç»“æœå­—å…¸ {source_name: success}
        """
        results = {}
        for name, source in self.sources.items():
            try:
                if source.connect():
                    self._connected_sources.add(name)
                    results[name] = True
                    logger.info(f"æ•°æ®æº {name} è¿æ¥æˆåŠŸ")
                else:
                    results[name] = False
                    logger.warning(f"æ•°æ®æº {name} è¿æ¥å¤±è´¥")
            except Exception as e:
                results[name] = False
                logger.error(f"æ•°æ®æº {name} è¿æ¥å¼‚å¸¸: {e}")
        return results
    
    def get_data(self, symbol: str, start_date: str, end_date: str,
                 data_type: str = "daily", source: str = None) -> pd.DataFrame:
        """
        è·å–æ•°æ®ï¼ˆè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ•°æ®æºï¼‰
        
        **è®¾è®¡åŸç†**ï¼š
        - **è‡ªåŠ¨é™çº§æœºåˆ¶**ï¼šæŒ‰ä¼˜å…ˆçº§å°è¯•æ•°æ®æºï¼Œå¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ•°æ®æº
        - **ç»Ÿä¸€æ¥å£**ï¼šæ‰€æœ‰æ•°æ®æºä½¿ç”¨ç›¸åŒçš„æ¥å£ï¼Œç®€åŒ–è°ƒç”¨é€»è¾‘
        - **æ™ºèƒ½é€‰æ‹©**ï¼šæ ¹æ®æ•°æ®ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ•°æ®æºï¼ˆå¦‚æ—¥çº¿ä¼˜å…ˆJQDataï¼Œå®æ—¶æ•°æ®ä¼˜å…ˆAKShareï¼‰
        
        **ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡**ï¼š
        1. **æé«˜å¯ç”¨æ€§**ï¼šå•ä¸ªæ•°æ®æºæ•…éšœä¸å½±å“ç³»ç»Ÿè¿è¡Œï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ•°æ®æº
        2. **ä¼˜åŒ–æ•°æ®è´¨é‡**ï¼šä¼˜å…ˆä½¿ç”¨é«˜è´¨é‡æ•°æ®æºï¼ˆå¦‚JQDataï¼‰ï¼Œé™çº§æ—¶ä½¿ç”¨å…è´¹æ•°æ®æºï¼ˆå¦‚AKShareï¼‰
        3. **é™ä½æˆæœ¬**ï¼šä¼˜å…ˆä½¿ç”¨å…è´¹æ•°æ®æºï¼Œä»˜è´¹æ•°æ®æºä½œä¸ºå¤‡é€‰
        4. **ç®€åŒ–è°ƒç”¨**ï¼šè°ƒç”¨è€…æ— éœ€å…³å¿ƒæ•°æ®æºé€‰æ‹©ï¼Œç³»ç»Ÿè‡ªåŠ¨å¤„ç†
        
        **æ›¿ä»£æ–¹æ¡ˆå¯¹æ¯”**ï¼š
        - **æ–¹æ¡ˆAï¼šå›ºå®šå•ä¸€æ•°æ®æº**
          - ä¼˜ç‚¹ï¼šå®ç°ç®€å•
          - ç¼ºç‚¹ï¼šæ•°æ®æºæ•…éšœæ—¶ç³»ç»Ÿä¸å¯ç”¨ï¼Œæ— æ³•åˆ©ç”¨å¤šä¸ªæ•°æ®æºçš„ä¼˜åŠ¿
        - **æ–¹æ¡ˆBï¼šåŒæ—¶è¯·æ±‚å¤šä¸ªæ•°æ®æº**
          - ä¼˜ç‚¹ï¼šå¿«é€Ÿè·å–æ•°æ®
          - ç¼ºç‚¹ï¼šæµªè´¹èµ„æºï¼Œå¢åŠ æˆæœ¬
        - **å½“å‰æ–¹æ¡ˆï¼šæŒ‰ä¼˜å…ˆçº§è‡ªåŠ¨é™çº§**
          - ä¼˜ç‚¹ï¼šå¹³è¡¡å¯ç”¨æ€§ã€è´¨é‡å’Œæˆæœ¬
          - ç¼ºç‚¹ï¼šå®ç°ç¨å¤æ‚ï¼Œéœ€è¦ç®¡ç†ä¼˜å…ˆçº§
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            data_type: æ•°æ®ç±»å‹ï¼ˆdaily, minute, tickï¼‰
            source: æŒ‡å®šæ•°æ®æºï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™è‡ªåŠ¨é€‰æ‹©ï¼‰
        
        Returns:
            DataFrameæ ¼å¼çš„æ•°æ®
        """
        # 1. æ£€æŸ¥ç¼“å­˜
        if self.use_cache and self.cache:
            cache_key = f"{symbol}:{start_date}:{end_date}:{data_type}"
            cached_data = self.cache.get(cache_key)
            if cached_data is not None:
                logger.info(f"ä»ç¼“å­˜è·å–æ•°æ®: {cache_key}")
                return cached_data
        
        # 2. å¦‚æœæŒ‡å®šäº†æ•°æ®æºï¼Œç›´æ¥ä½¿ç”¨
        if source and source in self.sources:
            data = self._fetch_from_source(source, symbol, start_date, end_date, data_type)
            # ä¿å­˜åˆ°ç¼“å­˜
            if self.use_cache and self.cache:
                self.cache.set(cache_key, data, ttl=3600)
            return data
        
        # 3. è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ•°æ®æº
        selected_source = self.select_source(data_type)
        
        # 4. å°è¯•è·å–æ•°æ®ï¼Œå¤±è´¥åˆ™åˆ‡æ¢åˆ°å¤‡ç”¨æ•°æ®æº
        try:
            data = self._fetch_from_source(selected_source, symbol, start_date, end_date, data_type)
            # ä¿å­˜åˆ°ç¼“å­˜
            if self.use_cache and self.cache:
                self.cache.set(cache_key, data, ttl=3600)
            return data
        except Exception as e:
            logger.warning(f"æ•°æ®æº {selected_source} è·å–å¤±è´¥: {e}")
            # æ•…éšœåˆ‡æ¢
            data = self._failover_fetch(symbol, start_date, end_date, data_type, selected_source)
            # ä¿å­˜åˆ°ç¼“å­˜
            if self.use_cache and self.cache:
                self.cache.set(cache_key, data, ttl=3600)
            return data
    
    def _fetch_from_source(self, source_name: str, symbol: str, 
                          start_date: str, end_date: str, data_type: str) -> pd.DataFrame:
        """ä»æŒ‡å®šæ•°æ®æºè·å–æ•°æ®"""
        if source_name not in self.sources:
            raise ValueError(f"æ•°æ®æºä¸å­˜åœ¨: {source_name}")
        
        source = self.sources[source_name]
        
        # ç¡®ä¿æ•°æ®æºå·²è¿æ¥
        if not source.is_connected:
            if not source.connect():
                raise ConnectionError(f"æ•°æ®æº {source_name} è¿æ¥å¤±è´¥")
        
        # æ ¹æ®æ•°æ®ç±»å‹è°ƒç”¨ç›¸åº”æ–¹æ³•
        if data_type == "daily":
            return source.get_daily_data(symbol, start_date, end_date)
        elif data_type == "minute":
            return source.get_minute_data(symbol, count=240)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {data_type}")
    
    def _failover_fetch(self, symbol: str, start_date: str, end_date: str,
                        data_type: str, failed_source: str) -> pd.DataFrame:
        """æ•…éšœåˆ‡æ¢è·å–æ•°æ®"""
        candidates = self.priority.get(data_type, [])
        candidates = [s for s in candidates if s != failed_source and s in self.sources]
        
        for source_name in candidates:
            try:
                logger.info(f"å°è¯•å¤‡ç”¨æ•°æ®æº: {source_name}")
                return self._fetch_from_source(source_name, symbol, start_date, end_date, data_type)
            except Exception as e:
                logger.warning(f"å¤‡ç”¨æ•°æ®æº {source_name} ä¹Ÿå¤±è´¥: {e}")
                continue
        
        raise Exception(f"æ‰€æœ‰æ•°æ®æºéƒ½ä¸å¯ç”¨ï¼Œæ— æ³•è·å–æ•°æ®: {symbol}")
    
    def select_source(self, data_type: str, criteria: List[str] = None) -> str:
        """
        é€‰æ‹©æœ€ä¼˜æ•°æ®æº
        
        Args:
            data_type: æ•°æ®ç±»å‹
            criteria: é€‰æ‹©æ ‡å‡†ï¼ˆdata_quality, completeness, speed, costï¼‰
        
        Returns:
            é€‰ä¸­çš„æ•°æ®æºåç§°
        """
        if criteria is None:
            criteria = ["data_quality", "completeness", "speed"]
        
        candidates = self.priority.get(data_type, list(self.sources.keys()))
        
        # æŒ‰ä¼˜å…ˆçº§å’Œå¥åº·çŠ¶æ€é€‰æ‹©
        for source_name in candidates:
            if source_name in self.sources:
                source = self.sources[source_name]
                # å¥åº·æ£€æŸ¥
                health = source.health_check()
                if health["status"] == "ok":
                    return source_name
        
        # å¦‚æœæ‰€æœ‰æ•°æ®æºéƒ½ä¸å¯ç”¨ï¼Œè¿”å›ç¬¬ä¸€ä¸ª
        return candidates[0] if candidates else list(self.sources.keys())[0]
    
    def check_all_sources(self) -> Dict[str, Dict[str, Any]]:
        """æ£€æŸ¥æ‰€æœ‰æ•°æ®æºçŠ¶æ€"""
   <CodeFromFile 
  fi<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1_01.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
# DataF<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/002_Chapter2_Data_Source/2.1/code_2_1_03.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```
-->ath="code_library/002_Chapter2_Data_Source/2.1/002_Chapter2_Data_Source/2.1/code_2_1_03.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
# DataFrame columns: time, open, high, low, c<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1_02.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
# DataFrame columns: date, open, hig<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1_03.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
# DataFrame columns: time, open, high, low, close, volume, amount
# time: datetimeç±»å‹ï¼Œç´¢å¼•åˆ—
# å…¶ä»–å­—æ®µåŒæ—¥çº¿æ•°æ®
```
-->
# amount: floatç±»å‹ï¼Œæˆäº¤é¢ï¼ˆå…ƒï¼‰
```
-->ources.items():
            results[name] = source.health_check()
        return results
```

### ç»Ÿä¸€æ•°æ®æ ¼å¼

æ‰€æœ‰æ•°æ®æºè¿”å›çš„æ•°æ®éƒ½éµå¾ªç»Ÿä¸€çš„æ ¼å¼è§„èŒƒï¼š

**æ—¥çº¿æ•°æ®æ ¼å¼**ï¼š
```python
# DataFrame columns: date, open, high, low, close, volume, amount
# date: datetimeç±»å‹ï¼Œç´¢å¼•åˆ—
# open, high, low, close: floatç±»å‹ï¼Œä»·æ ¼æ•°æ®
# volume: intç±»å‹ï¼Œæˆäº¤é‡ï¼ˆæ‰‹ï¼‰
# amount: floatç±»å‹ï¼Œæˆäº¤é¢ï¼ˆå…ƒï¼‰
```

**åˆ†é’Ÿçº¿æ•°æ®æ ¼å¼**ï¼š
```python
# DataFrame columns: time, open, high, low, close, volume, amount
# time: datetimeç±»å‹ï¼Œç´¢å¼•åˆ—
# å…¶ä»–å­—æ®µåŒæ—¥çº¿æ•°æ®
```

<h2 id="section-2-1-2">ğŸ“Š 2.1.2 å¤šæ•°æ®æºæ”¯æŒ</h2>

TRQuantç³»ç»Ÿæ”¯æŒå¤šä¸ªæ•°æ®æºï¼Œæ¯ä¸ªæ•°æ®æºéƒ½æœ‰å…¶ç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯ã€‚

### æ”¯æŒçš„æ•°æ®æº

<div class="comparison-table">
  <table>
    <thead>
      <tr>
        <th>æ•°æ®æº</th<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1___init__.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
from data_sources.base_source import BaseDataSource
import jqdatasdk as jq
import pandas as pd

class JQDataSource(BaseDataSource):
    """èšå®½æ•°æ®æºå®ç°"""
    
    def __init__(self):
        super().__init__("jqdata")
        self.username = None
        self.password = None
    
    def connect(self, username: str = None, password: str = None, **kwargs) -> bool:
        """è¿æ¥JQData"""
        try:
            if username and password:
                self.username = username
                self.password = password
            else:
                # ä»é…ç½®æ–‡ä»¶è¯»å–
                from core.config import get_config
                config = get_config()
                self.username = config.get("jqdata", "username")
                self.password = config.get("jqdata", "password")
            
            jq.auth(self.username, self.password)
            self._connected = True
            self._connection_time = datetime.now()
            logger.info("JQDataè¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            self._connected = False
            self._last_error = str(e)
            logger.error(f"JQDataè¿æ¥å¤±è´¥: {e}")
            return False
    
    def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self._connected:
            jq.logout()
            self._connected = False
            logger.info("JQDataå·²æ–­å¼€")
    
    def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        if not self._connected:
            return {"status": "error", "latency": None, "error": "æœªè¿æ¥"}
        
        try:
            start_time = datetime.now()
            # æµ‹è¯•æŸ¥è¯¢
            jq.get_price("000001.XSHE", count=1, end_date=datetime.now().strftime("%Y-%m-%d"))
            latency = (datetime.now() - start_time).total_seconds() * 1000
            
            return {
                "status": "ok",
                "latency": int(latency),
                "error": None,
                "checked_at": datetime.now().isoformat()
            }
        except Exception as e:
            return {
                "status": "error",
                "latency": None,
                "error": str(e),
                "checked_at": datetime.now().isoformat()
            }
    
    def get_daily_data(self, symbol: str, start_date: str, 
                       end_date: str, fields: List[str] = None) -> pd.DataFrame:
        """è·å–æ—¥çº¿æ•°æ®"""
        if not self._connected:
            raise ConnectionError("JQDataæœªè¿æ¥")
        
        # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼
        jq_symbol = self._convert_symbol(symbol)
        
        # è·å–æ•°æ®
        data = jq.get_price(
            jq_symbol,
            start_date=start_date,
            end_date=end_date,
            frequency='daily',
            fields=fields or ['open', 'high', 'low', 'close', 'volume', 'money']
        )
        
        # é‡å‘½ååˆ—
        data.rename(columns={'money': 'amount'}, inplace=True)
        data.index.name = 'date'
        
        return data
    
<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/002_Chapter2_Data_Source/2.1/code_2_1___init__.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```
-->q_symbol = self._convert_symbol(symbol)
        
        # è·å–æ•°æ®
        data = jq.get_price(
            jq_symbol,
            start_date=start_date,
            end_date=end_date,
            frequency='daily',
            fields=fields or ['open', 'high', 'low', 'close', 'volume', 'money']
        )
        
        # é‡å‘½ååˆ—
        data.rename(columns={'money': 'amount'}, inplace=True)
        data.index.name = 'date'
        
        return data
    
<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/002_Chapter2_Data_Source/2.1/code_2_1___init__.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
import akshare as ak
import pandas as pd

class AKShareSource(BaseDataSource):
    """AKShareæ•°æ®æºå®ç°"""
    
    def __init__(self):
        super().__init__("akshare")
    
    def connect(self, **kwargs) -> bool:
        """AKShareæ— éœ€è¿æ¥ï¼Œç›´æ¥è¿”å›True"""
        self._connected = True
        return True
    
    def disconnect(self):
        """AKShareæ— éœ€æ–­å¼€"""
        self._connected = False
    
    def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        tr<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1_05.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
# æ•°æ®æºä¼˜å…ˆçº§é…ç½®
priority_config = {
    'daily': ['jqdata', 'akshare', 'tushare'],      # æ—¥çº¿æ•°æ®ä¼˜å…ˆçº§
    'minute': ['jqdata', 'akshare'],                # åˆ†é’Ÿæ•°æ®ä¼˜å…ˆçº§
    'realtime': ['akshare', 'jqdata'],              # å®æ—¶æ•°æ®ä¼˜å…ˆçº§
    'fundamental': ['jqdata', 'tushare'],          # åŸºæœ¬é¢æ•°æ®ä¼˜å…ˆçº§
    'factor': ['jqdata'],                          # å› å­æ•°æ®ä¼˜å…ˆçº§
}
```
-->           "checked_at": datetime.now().isoformat()
            }
        except Exception as e:
            return {
                "status": "error",
                "latency": None,
                "error": str(e),
                "checked_at": datetime.now().isoformat()
    <CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/002_Chapter2_Data_Source/2.1/code_2_1_06.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
# æ•°æ®æºä¼˜å…ˆçº§é…ç½®
priority_config = {
    'daily': ['jqdata', 'akshare', 'tushare'],      # æ—¥çº¿æ•°æ®ä¼˜å…ˆçº§
    'minute': ['jqdata', 'akshare'],                # åˆ†é’Ÿæ•°æ®ä¼˜å…ˆçº§
    'realtime': ['akshare', 'jqdata'],              # å®æ—¶æ•°æ®ä¼˜å…ˆçº§
    'fundamental': ['jqdata', 'tushare'],          # åŸºæœ¬é¢æ•°æ®ä¼˜å…ˆçº§
    'factor': ['jqdata'],                          # å› å­æ•°æ®ä¼˜å…ˆçº§
}
```
-->daily",
            start_date=start_da<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1_select_source.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
def select_source(self, data_type: str, criteria: List[str] = None) -> str:
    """é€‰æ‹©æœ€ä¼˜æ•°æ®æº"""
    if criteria is None:
        criteria = ["data_quality", "completeness", "speed"]
    
    candidates = self.priority.get(data_type, list(self.sources.keys()))
    
    # è¯„åˆ†ç³»ç»Ÿ
    scores = {}
    for source_name in candidates:
        if source_name not in self.sources:
            continue
        
        source = self.sources[source_name]
        score = 0
        
        # å¥åº·æ£€æŸ¥
        health = source.health_check()
        if health["status"] != "ok":
            continue  # è·³è¿‡ä¸å¥åº·çš„æ•°æ®æº
        
        # æ ¹æ®æ ‡å‡†è¯„åˆ†
        if "speed" in criteria:
            # é€Ÿåº¦è¯„åˆ†ï¼šå»¶è¿Ÿè¶Šä½åˆ†æ•°è¶Šé«˜
            latency = health.get("latency", 1000)
            speed_score = max(0, 100 - latency / 10)
            score += speed_score * 0.3
        
        if "data_quality" in criteria:
            # æ•°æ®è´¨é‡è¯„åˆ†ï¼ˆåŸºäºå†å²ç»Ÿè®¡ï¼‰
            quality_score = self._get_quality_score(source_name)
            score += quality_score * 0.4
        
        if "completeness" in criteria:
            # å®Œæ•´æ€§è¯„åˆ†ï¼ˆåŸºäºå†å²ç»Ÿè®¡ï¼‰
            completeness_score = self._get_completeness_score(source_name, data_type)
            score += completeness_score * 0.3
        
        scores[source_name] = score
    
    # é€‰æ‹©åˆ†æ•°æœ€é«˜çš„æ•°æ®æº
    if sc<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/002_Chapter2_Data_Source/2.1/code_2_1_health_check_all.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```
-->ealth_check()
        if health["status"] != "ok":
            continue  # è·³è¿‡ä¸å¥åº·çš„æ•°æ®æº
        
        # æ ¹æ®æ ‡å‡†è¯„åˆ†
        if "speed" in criteria:
            # é€Ÿåº¦è¯„åˆ†ï¼šå»¶è¿Ÿè¶Šä½åˆ†æ•°è¶Šé«˜
            latency = health.get("latency", 1000)
            speed_score = max(0, 100 - latency / 10)
            score += speed_score * 0.3
        
        if "data_quality" in criteria:
            # æ•°æ®è´¨é‡è¯„åˆ†ï¼ˆåŸºäºå†å²ç»Ÿè®¡ï¼‰
            quality_score = self._get_quality_score(source_name)
            score += quality_score * 0<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1__failover_fetch.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
def _failover_fetch(self, symbol: str, start_date: str, end_date: str,
                    data_type: str, failed_source: str) -> pd.DataFrame:
    """æ•…éšœåˆ‡æ¢è·å–æ•°æ®"""
    # 1. è·å–å¤‡ç”¨æ•°æ®æºåˆ—è¡¨
    candidates = self.priority.get(data_type, [])
    
    # 2. æ’é™¤å¤±è´¥çš„æ•°æ®æº
    candidates = [s for s in candidates if s != failed_source and s in self.sources]
    
    # 3. è®°å½•æ•…éšœ
    logger.warning(f"æ•°æ®æº {failed_source} æ•…éšœï¼Œå°è¯•å¤‡ç”¨æ•°æ®æº: {candidates}")
    self._record_failure(failed_source, symbol, data_type)
    
    # 4. å°è¯•å¤‡ç”¨æ•°æ®æº
    for source_name in candidates:
        try:
            logger.info(f"å°è¯•å¤‡ç”¨æ•°æ®æº: {source_name}")
            data = self._fetch_from_source(source_name, symbol, start_date, end_date, data_type)
            
            # è®°å½•æˆåŠŸåˆ‡æ¢
            self._record_failover(failed_source, source_name, symbol, data_type)
            return data
        except Exception a<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/002_Chapter2_Data_Source/2.1/code_2_1_get_data_with_load_balance.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```
-->e="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
def _failover_fetch(self, symbol: str, start_date: str, end_date: str,
                    data_type: str, failed_source: str) -> pd.DataFrame:
    """æ•…éšœåˆ‡æ¢è·å–æ•°æ®"""
    # 1. è·å–å¤‡ç”¨æ•°æ®æºåˆ—è¡¨
    candidates = self.priority.get(data_type, [])
    
    # 2. æ’é™¤å¤±è´¥çš„æ•°æ®æº
    candidates = [s for s in candidates if s != failed_source and s in self.sources]
    
    # 3. è®°å½•æ•…éšœ
    logger.warning(f"æ•°æ®æº {failed_source} æ•…éšœï¼Œå°è¯•å¤‡ç”¨æ•°æ®æº: {candidates}")
    self._record_failure(failed_source, symbol, data_type)
    
    # 4. å°è¯•å¤‡ç”¨æ•°æ®æº
    for source_name in candidates:
        try:
            logger.info(f"å°è¯•å¤‡ç”¨æ•°æ®æº: {source_name}")
            data = self._fetch_from_source(source_name, symbol, start_date, end_date, data_typ<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1_save_data_source_config.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
from core.db import get_db_connection
import json

def save_data_source_config(name: str, source_type: str, config: dict):
    """ä¿å­˜æ•°æ®æºé…ç½®åˆ°PostgreSQL"""
    conn = get_db_connection()
    with conn.cursor() as cur:
        cur.execute("""
            INSERT INTO data_source_configs (name, source_type, config, status)
            VALUES (%s, %s, %s, 'active')
            ON CONFLICT (name) DO UPDATE
            SET source_type = EXCLUDED.source_type,
                config = EXCLUDED.config,
                updated_at = CURRENT_TIMESTAMP
        """, (name, source_type, json.dumps(config)))
    conn.commit()

def get_data_source_config(name: str) -> dict:
    """ä»PostgreSQLè·å–æ•°æ®æºé…ç½®"""
    conn = get_db_connection()
    with conn.cursor() as cur:
        cur.execute("""
            SELECT name, source_type, config, status
            FROM data_source_configs
            WHERE name = %s
        """, (name,))
        row = cur.fetchone()
        if row:
            return {
                "name": row[0<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/002_Chapter2_Data_Source/2.1/code_2_1_store_market_data_to_timeseries.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```
-->source_config.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
from core.db import get_db_connection
import json

def save_data_source_config(name: str, source_type: str, config: dict):
    """ä¿å­˜æ•°æ®æºé…ç½®åˆ°PostgreSQL"""
    conn = get_db_connection()
    with conn.cursor() as cur:
        cur.execute("""
            INSERT INTO data_source_configs (name, source_type, config, status)
            VALUES (%s, %s, %s, 'active')
            ON CONFLICT (name) DO UPDATE
            SET source_type = EXCLUDED.source_type,
                config = EXCLUDED.config,
                updated_at = CURRENT_TIMESTAMP
     <CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1_get_data_with_cache.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
def get_data_with_cache(symbol: str, start_date: str, end_date: str, 
                        data_type: str = "daily") -> pd.DataFrame:
    """å¸¦ç¼“å­˜çš„æ•°æ®è·å–"""
    cache_key = f"market:{symbol}:{start_date}:{end_date}:{data_type}"
    
    # 1. æ£€æŸ¥Redisç¼“å­˜ï¼ˆL1ç¼“å­˜ï¼‰
    if self.cache:
        cached = <CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1_store_market_data_to_timeseries.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
def store_market_data_to_timeseries(symbol: str, data: pd.DataFrame, 
                                    source: str = "jqdata"):
    """å­˜å‚¨è¡Œæƒ…æ•°æ®åˆ°æ—¶åºæ•°æ®åº“"""
    from core.timeseries_db import get_timeseries_db
    
    ts_db = get_timeseries_db()
    
    # å‡†å¤‡æ•°æ®
    records = []
    for date, row in data.iterrows():
        records.append({
            "symbol": symbol,
            "trade_date": date,
            "open": float(row["open"]),
            "high": float(row["high"]),
            "low": float(row["low"]),
            "close": float(row["close"]),
            "volume": int(row["volume"]),
            "amount": float(row["amount"]),
            "source": source,
            "created_at": datetime.now()
        })
    
    # æ‰¹é‡æ’å…¥
    ts_db.insert_batch("market_data_daily", records)
```
--> language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```
-->: float(row["low"]),
            "close": float(row["close"]),
            "volume": int(row["v<CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1_10.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
# 1. çˆ¬å–æ•°æ®æºæ–‡æ¡£ç½‘ç«™
data_collector.crawl_web(
    url="https://www.joinquant.com/help/api/help",
    max_depth=2,
    output_dir="data/collected/jqdata_docs"
)

# 2. ä¸‹è½½æ•°æ®æºä½¿ç”¨æ‰‹å†Œ
data_collector.download_pdf(
    url="https://example.com/jqdata_manual.pdf",
    output_dir="data/collected/manuals"
)

# 3. æ”¶é›†å­¦æœ¯è®ºæ–‡
data_collector.collect_academic(
    database="arxiv",
    query="financial data source quality assessment",
    max_results=10,
    output_dir="data/collected/papers"
)
```
-->sç¼“å­˜ï¼ˆL1ç¼“å­˜ï¼‰
    if self.cache:
        cached = self.cache.get(cache_key)
        if cached is not None:
            logger.info(f"ä»Redisç¼“å­˜è·å–: {cache_key}")
            return cached
    
    # 2. æ£€æŸ¥Parquetæ–‡ä»¶ç¼“å­˜ï¼ˆL2ç¼“å­˜ï¼‰
    parquet_path = f"cache/{symbol}_{start_date}_{end_date}.parquet"
    if os.path.exists(parquet_path):
        data = pd.read_parquet(parquet_path)
        # æ›´æ–°Redisç¼“å­˜
        if self.cache:
            self.cache.set(cache_key, data, ttl=3600)
        logger.info(f"ä»Parquetç¼“å­˜è·å–: {parquet_path}")
        return data
    
    # 3. ä»æ•°æ®æºè·å–
    data = self.get_data(symbol, start_date, end_date, data_type)
    
    # 4. ä¿å­˜åˆ°ç¼“å­˜
    data.to_parquet(parquet_path, compression='snappy')
  <CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1_get_data_with_cache.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
def get_data_with_cache(symbol: str, start_date: str, end_date: str, 
                        data_type: str = "daily") -> pd.DataFrame:
    """å¸¦ç¼“å­˜çš„æ•°æ®è·å–"""
    cache_key = f"market:{symbol}:{start_date}:{end_date}:{data_type}"
    
    # 1. æ£€æŸ¥Redisç¼“å­˜ï¼ˆL1ç¼“å­˜ï¼‰
    if self.cache:
        cached = self.cache.get(cache_key)
        if cached is not None:
            logger.info(f"ä»Redisç¼“å­˜è·å–: {cache_key}")
            return cached
    
    # 2. æ£€æŸ¥Parquetæ–‡ä»¶ç¼“å­˜ï¼ˆL2ç¼“å­˜ï¼‰
    parquet_path = f"cache/{symbol}_{start_date}_{end_date}.parquet"
    if os.path.exists(parquet_path):
        data = pd.read_parquet(parquet_path)
        # æ›´æ–°Redisç¼“å­˜
        if self.cache:
            self.cache.set(cache_key, data, ttl=3600)
        logger.info(f"ä»Parquetç¼“å­˜è·å–: {parquet_path}")
        return data
    
    # 3. ä»æ•°æ®æºè·å–
    data = self.get_data(symbol, start_date, end_date, data_type)
    
    # 4. ä¿å­˜åˆ°ç¼“å­˜
    data.to_parquet(parquet_path, compression='snappy')
    if self.cache:
        self.cache.set(cache_key, data, ttl=3600)
    <CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1_13.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
# åœ¨Cursorä¸­è°ƒç”¨MCPå·¥å…·
# æŸ¥è¯¢æ•°æ®æºç®¡ç†ç›¸å…³æ–‡æ¡£
results = kb.query(
    query="æ•°æ®æºç®¡ç†æ¥å£è®¾è®¡ BaseDataSource",
    scope="both",  <CodeFromFile 
  filePath="code_library/002_Chapter2_Data_Source/2.1/code_2_1_14.py"
  language="python"
  showDesignPrinciples="true"
/>

<!-- åŸå§‹ä»£ç ï¼ˆä¿ç•™ä½œä¸ºå¤‡ä»½ï¼‰ï¼š
```python
# 1. çˆ¬å–æ•°æ®æºæ–‡æ¡£ç½‘ç«™
data_collector.crawl_web(
    url="https://www.joinquant.com/help/api/help",
    max_depth=2,
    output_dir="data/collected/jqdata_docs"
)

# 2. ä¸‹è½½æ•°æ®æºä½¿ç”¨æ‰‹å†Œ
data_collector.download_pdf(
    url="https://example.com/jqdata_manual.pdf",
    output_dir="data/collected/manuals"
)

# 3. æ”¶é›†å­¦æœ¯è®ºæ–‡
data_collector.collect_academic(
    database="arxiv",
    query="financial data source quality assessment",
    max_results=10,
    output_dir="data/collected/papers"
)
```
-->pen": float(row["open"]),
            "high": float(row["high"]),
            "low": float(row["low"]),
            "close": float(row["close"]),
            "volume": int(row["volume"]),
            "amount": float(row["amount"]),
            "source": source,
            "created_at": datetime.now()
        })
    
    # æ‰¹é‡æ’å…¥
    ts_db.insert_batch("market_data_daily", records)
```

### ç¼“å­˜ç­–ç•¥

ç³»ç»Ÿé‡‡ç”¨å¤šçº§ç¼“å­˜ç­–ç•¥ï¼Œæé«˜æ•°æ®è·å–æ•ˆç‡ï¼š

```python
def get_data_with_cache(symbol: str, start_date: str, end_date: str, 
                        data_type: str = "daily") -> pd.DataFrame:
    """å¸¦ç¼“å­˜çš„æ•°æ®è·å–"""
    cache_key = f"market:{symbol}:{start_date}:{end_date}:{data_type}"
    
    # 1. æ£€æŸ¥Redisç¼“å­˜ï¼ˆL1ç¼“å­˜ï¼‰
    if self.cache:
        cached = self.cache.get(cache_key)
        if cached is not None:
            logger.info(f"ä»Redisç¼“å­˜è·å–: {cache_key}")
            return cached
    
    # 2. æ£€æŸ¥Parquetæ–‡ä»¶ç¼“å­˜ï¼ˆL2ç¼“å­˜ï¼‰
    parquet_path = f"cache/{symbol}_{start_date}_{end_date}.parquet"
    if os.path.exists(parquet_path):
        data = pd.read_parquet(parquet_path)
        # æ›´æ–°Redisç¼“å­˜
        if self.cache:
            self.cache.set(cache_key, data, ttl=3600)
        logger.info(f"ä»Parquetç¼“å­˜è·å–: {parquet_path}")
        return data
    
    # 3. ä»æ•°æ®æºè·å–
    data = self.get_data(symbol, start_date, end_date, data_type)
    
    # 4. ä¿å­˜åˆ°ç¼“å­˜
    data.to_parquet(parquet_path, compression='snappy')
    if self.cache:
        self.cache.set(cache_key, data, ttl=3600)
    
    return data
```

è¯¦ç»†è®¾è®¡è¯·å‚è€ƒ **1.9 æ•°æ®åº“æ¶æ„è®¾è®¡** ç« èŠ‚ã€‚

<h2 id="section-2-1-6">ğŸ› ï¸ 2.1.6 MCPå·¥å…·ä½¿ç”¨</h2>

åœ¨å¼€å‘æ•°æ®æºç®¡ç†åŠŸèƒ½æ—¶ï¼Œå¯ä»¥ä½¿ç”¨MCPå·¥å…·è¿›è¡Œæ·±å…¥ç ”ç©¶å’ŒæŠ€æœ¯è°ƒç ”ã€‚

### æŸ¥è¯¢æ•°æ®æºç›¸å…³æ–‡æ¡£

ä½¿ç”¨`kb.query`æŸ¥è¯¢æ•°æ®æºç›¸å…³çš„æ–‡æ¡£å’Œä»£ç ï¼š

```python
# åœ¨Cursorä¸­è°ƒç”¨MCPå·¥å…·
# æŸ¥è¯¢æ•°æ®æºç®¡ç†ç›¸å…³æ–‡æ¡£
results = kb.query(
    query="æ•°æ®æºç®¡ç†æ¥å£è®¾è®¡ BaseDataSource",
    scope="both",  # manual + engineering
    top_k=5
)

# æŸ¥è¯¢ç»“æœåŒ…å«ï¼š
# - å¼€å‘æ‰‹å†Œä¸­çš„ç›¸å…³ç« èŠ‚
# - ä»£ç åº“ä¸­çš„BaseDataSourceå®ç°
# - æ•°æ®æºç®¡ç†å™¨çš„ä½¿ç”¨ç¤ºä¾‹
```

### æ”¶é›†æ•°æ®æºæŠ€æœ¯èµ„æ–™

ä½¿ç”¨`data_collector`æ”¶é›†æ•°æ®æºç›¸å…³çš„æŠ€æœ¯èµ„æ–™ï¼š

```python
# 1. çˆ¬å–æ•°æ®æºæ–‡æ¡£ç½‘ç«™
data_collector.crawl_web(
    url="https://www.joinquant.com/help/api/help",
    max_depth=2,
    output_dir="data/collected/jqdata_docs"
)

# 2. ä¸‹è½½æ•°æ®æºä½¿ç”¨æ‰‹å†Œ
data_collector.download_pdf(
    url="https://example.com/jqdata_manual.pdf",
    output_dir="data/collected/manuals"
)

# 3. æ”¶é›†å­¦æœ¯è®ºæ–‡
data_collector.collect_academic(
    database="arxiv",
    query="financial data source quality assessment",
    max_results=10,
    output_dir="data/collected/papers"
)
```

### ä½¿ç”¨MCPå·¥å…·è¿›è¡Œç ”ç©¶

å½“é‡åˆ°æ•°æ®æºç›¸å…³é—®é¢˜æ—¶ï¼Œéµå¾ª"ä¸ç¡®å®šæ—¶ï¼Œå…ˆç ”ç©¶å†å®ç°"çš„å¼€å‘æ–¹æ³•è®ºï¼š

1. **æŸ¥è¯¢çŸ¥è¯†åº“**ï¼šä½¿ç”¨`kb.query`æŸ¥æ‰¾ç›¸å…³æ–‡æ¡£å’Œä»£ç 
2. **æ”¶é›†ä¿¡æ¯**ï¼šä½¿ç”¨`data_collector`æ”¶é›†å¤–éƒ¨èµ„æ–™
3. **åˆ†æé—®é¢˜**ï¼šç»“åˆæ”¶é›†çš„ä¿¡æ¯åˆ†æé—®é¢˜
4. **å®ç°æ–¹æ¡ˆ**ï¼šåŸºäºç ”ç©¶ç»“æœå®ç°è§£å†³æ–¹æ¡ˆ

è¯¦ç»†æ–¹æ³•è¯·å‚è€ƒ **10.11 å¼€å‘æµç¨‹æ–¹æ³•è®º** ç« èŠ‚ã€‚

## ğŸ”— ç›¸å…³ç« èŠ‚

- **ç¬¬äºŒç«  æ•°æ®æºæ¨¡å—**ï¼šäº†è§£æ•°æ®æºæ¨¡å—çš„æ•´ä½“è®¾è®¡
- **2.2 æ•°æ®è´¨é‡**ï¼šäº†è§£æ•°æ®è´¨é‡æ£€æŸ¥æœºåˆ¶
- **1.9 æ•°æ®åº“æ¶æ„è®¾è®¡**ï¼šæ·±å…¥äº†è§£æ•°æ®å­˜å‚¨æ¶æ„è®¾è®¡
- **ç¬¬ä¸‰ç«  å¸‚åœºåˆ†æ**ï¼šäº†è§£å¦‚ä½•ä½¿ç”¨æ•°æ®æºæ¨¡å—æä¾›çš„æ•°æ®
- **10.7 MCP Serverå¼€å‘æŒ‡å—**ï¼šæŒæ¡MCPå·¥å…·å¼€å‘æ–¹æ³•
- **10.11 å¼€å‘æµç¨‹æ–¹æ³•è®º**ï¼šæŒæ¡ä½¿ç”¨MCPå·¥å…·è¿›è¡Œç ”ç©¶çš„æ–¹æ³•

## ğŸ’¡ å…³é”®è¦ç‚¹

1. **ç»Ÿä¸€æ¥å£æŠ½è±¡**ï¼šé€šè¿‡`BaseDataSource`åŸºç±»å®šä¹‰ç»Ÿä¸€çš„æ•°æ®æºæ¥å£
2. **å¤šæ•°æ®æºæ”¯æŒ**ï¼šæ”¯æŒJQDataã€AKShareã€TuShareã€Windç­‰å¤šä¸ªæ•°æ®æº
3. **æ™ºèƒ½é€‰æ‹©ç­–ç•¥**ï¼šæ ¹æ®æ•°æ®è´¨é‡ã€å®Œæ•´æ€§ã€é€Ÿåº¦ç­‰ç»´åº¦æ™ºèƒ½é€‰æ‹©æœ€ä¼˜æ•°æ®æº
4. **æ•…éšœè‡ªåŠ¨åˆ‡æ¢**ï¼šå½“ä¸»æ•°æ®æºä¸å¯ç”¨æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ•°æ®æº
5. **æ•°æ®å­˜å‚¨é›†æˆ**ï¼šä¸PostgreSQLã€æ—¶åºåº“ã€Redisæ·±åº¦é›†æˆ
6. **MCPå·¥å…·æ”¯æŒ**ï¼šæ”¯æŒä½¿ç”¨MCPå·¥å…·è¿›è¡Œæ•°æ®æºç›¸å…³ç ”ç©¶

## ğŸ”® æ€»ç»“ä¸å±•æœ›

<div class="summary-outlook">
  <h3>æœ¬èŠ‚å›é¡¾</h3>
  <p>æœ¬èŠ‚ç³»ç»Ÿä»‹ç»äº†æ•°æ®æºç®¡ç†æœºåˆ¶ï¼ŒåŒ…æ‹¬ç»Ÿä¸€æ¥å£æŠ½è±¡ã€å¤šæ•°æ®æºæ”¯æŒã€æ™ºèƒ½é€‰æ‹©ç­–ç•¥å’Œæ•…éšœè‡ªåŠ¨åˆ‡æ¢ã€‚é€šè¿‡ç†è§£æ•°æ®æºåŸºç±»æ¥å£ã€æ•°æ®æºç®¡ç†å™¨è®¾è®¡ã€æ•°æ®æºé€‰æ‹©ç®—æ³•å’Œæ•°æ®åº“é›†æˆï¼Œå¸®åŠ©å¼€å‘è€…æŒæ¡æ•°æ®æºç®¡ç†çš„æ ¸å¿ƒå®ç°ï¼Œä¸ºæ„å»ºå¯é çš„æ•°æ®è·å–ç³»ç»Ÿå¥ å®šåŸºç¡€ã€‚</p>
  
  <h3>ä¸‹èŠ‚é¢„å‘Š</h3>
  <p>æŒæ¡äº†æ•°æ®æºç®¡ç†æœºåˆ¶åï¼Œä¸‹ä¸€èŠ‚å°†ä»‹ç»æ•°æ®è´¨é‡æ£€æŸ¥ï¼ŒåŒ…æ‹¬æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ã€å‡†ç¡®æ€§éªŒè¯ã€å¼‚å¸¸æ£€æµ‹ä¸æ•°æ®æ¸…æ´—æ–¹æ³•ã€‚é€šè¿‡ç†è§£æ•°æ®è´¨é‡ä¿è¯æœºåˆ¶ï¼Œå¸®åŠ©å¼€å‘è€…ç¡®ä¿åç»­æ­¥éª¤ä½¿ç”¨çš„æ•°æ®è´¨é‡ã€‚</p>
  
  <a href="/ashare-book6/002_Chapter2_Data_Source/2.2_Data_Quality_CN" class="next-section">
    ç»§ç»­å­¦ä¹ ï¼š2.2 æ•°æ®è´¨é‡ â†’
  </a>
</div>

> **é€‚ç”¨ç‰ˆæœ¬**: v1.0.0+  
> **æœ€åæ›´æ–°**: 2025-12-12
<!-- Code updated: 2025-12-14T01:33:29.275Z -->
